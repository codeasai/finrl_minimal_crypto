# sac.py - SAC (Soft Actor-Critic) Agent for Cryptocurrency Trading
import sys
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import os
import yfinance as yf
import torch
import pickle
import random
import string

# Stable Baselines3 imports à¹‚à¸”à¸¢à¸•à¸£à¸‡
import gymnasium as gym
from stable_baselines3 import SAC
from stable_baselines3.common.env_checker import check_env
from stable_baselines3.common.vec_env import DummyVecEnv

# Import config
from config import *

class CryptoTradingEnv(gym.Env):
    """
    Custom Cryptocurrency Trading Environment à¸ªà¸³à¸«à¸£à¸±à¸š SAC
    """
    
    def __init__(self, df, initial_amount=100000, transaction_cost_pct=0.001, max_holdings=100):
        super(CryptoTradingEnv, self).__init__()
        
        self.df = df.reset_index(drop=True)
        self.initial_amount = initial_amount
        self.transaction_cost_pct = transaction_cost_pct
        self.max_holdings = max_holdings
        
        # Current state
        self.current_step = 0
        self.cash = initial_amount
        self.holdings = 0
        self.total_value = initial_amount
        
        # Action space: continuous between -1 and 1
        # -1 = sell all, 0 = hold, 1 = buy all
        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)
        
        # Observation space: technical indicators + portfolio info
        self.n_features = len(INDICATORS) + 3  # indicators + cash, holdings, total_value
        self.observation_space = gym.spaces.Box(
            low=-np.inf, high=np.inf, shape=(self.n_features,), dtype=np.float32
        )
        
        print(f"Environment initialized: {len(self.df)} timesteps, {self.n_features} features")
        
    def reset(self, seed=None, options=None):
        super().reset(seed=seed, options=options)
        
        self.current_step = 20  # à¹€à¸£à¸´à¹ˆà¸¡à¸ˆà¸²à¸à¸§à¸±à¸™à¸—à¸µà¹ˆ 20 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸¡à¸µ technical indicators
        self.cash = self.initial_amount
        self.holdings = 0
        self.total_value = self.initial_amount
        
        return self._get_observation(), {}
    
    def _get_observation(self):
        # Get current market data
        current_data = self.df.iloc[self.current_step]
        
        # Technical indicators
        indicators = [current_data[indicator] for indicator in INDICATORS]
        
        # Portfolio information (normalized)
        portfolio_info = [
            self.cash / self.initial_amount,  # normalized cash
            self.holdings / self.max_holdings,  # normalized holdings
            self.total_value / self.initial_amount  # normalized total value
        ]
        
        obs = np.array(indicators + portfolio_info, dtype=np.float32)
        
        # Replace NaN with 0
        obs = np.nan_to_num(obs, nan=0.0, posinf=1.0, neginf=-1.0)
        
        return obs
    
    def step(self, action):
        if self.current_step >= len(self.df) - 1:
            return self._get_observation(), 0, True, True, {}
        
        current_price = self.df.iloc[self.current_step]['close']
        next_step = self.current_step + 1
        next_price = self.df.iloc[next_step]['close']
        
        # Execute action
        action_value = action[0]
        
        if action_value > 0.1:  # Buy
            buy_amount = min(self.cash * action_value, self.cash)
            shares_to_buy = buy_amount / current_price
            transaction_cost = buy_amount * self.transaction_cost_pct
            
            if buy_amount > transaction_cost:
                self.holdings += shares_to_buy
                self.cash -= buy_amount + transaction_cost
                
        elif action_value < -0.1:  # Sell
            sell_ratio = abs(action_value)
            shares_to_sell = self.holdings * sell_ratio
            sell_amount = shares_to_sell * current_price
            transaction_cost = sell_amount * self.transaction_cost_pct
            
            if shares_to_sell > 0:
                self.holdings -= shares_to_sell
                self.cash += sell_amount - transaction_cost
        
        # Move to next step
        self.current_step = next_step
        
        # Calculate reward (portfolio return)
        old_total_value = self.total_value
        self.total_value = self.cash + self.holdings * next_price
        
        # Reward is the percentage change in portfolio value
        reward = (self.total_value - old_total_value) / old_total_value
        
        # Add penalty for holding cash (encourage trading)
        cash_penalty = -0.0001 * (self.cash / self.total_value)
        reward += cash_penalty
        
        # Check if done
        done = self.current_step >= len(self.df) - 1
        
        return self._get_observation(), reward, done, False, {
            'total_value': self.total_value,
            'cash': self.cash,
            'holdings': self.holdings,
            'price': next_price
        }

def setup_device():
    """
    à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¸°à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ GPU/CPU
    """
    print("\nðŸ” à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ GPU/CPU")
    print("-" * 50)
    
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"âœ… à¸žà¸š GPU: {torch.cuda.get_device_name(0)}")
        print(f"ðŸ“Š à¸ˆà¸³à¸™à¸§à¸™ GPU: {torch.cuda.device_count()}")
        print(f"ðŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        device = torch.device("cpu")
        print("â„¹ï¸ à¹„à¸¡à¹ˆà¸žà¸š GPU à¹ƒà¸Šà¹‰ CPU à¹à¸—à¸™")
    
    return device

def load_existing_data():
    """
    à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ data
    """
    print("\nðŸ“‚ à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ...")
    print("-" * 50)
    
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹„à¸Ÿà¸¥à¹Œà¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ data
    data_files = []
    for file in os.listdir(DATA_DIR):
        if file.endswith('.csv'):
            data_files.append(file)
    
    print(f"ðŸ“ à¸žà¸šà¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥: {data_files}")
    
    # à¹ƒà¸Šà¹‰à¹„à¸Ÿà¸¥à¹Œ BTC-USD à¸à¹ˆà¸­à¸™
    btc_file = os.path.join(DATA_DIR, "BTC_USD-1d-20230601-20250609.csv")
    
    if os.path.exists(btc_file):
        print(f"ðŸ“Š à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ BTC-USD à¸ˆà¸²à¸ {btc_file}")
        df = pd.read_csv(btc_file)
        
        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¸°à¹à¸›à¸¥à¸‡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ
        if 'Unnamed: 0' in df.columns:
            df['timestamp'] = pd.to_datetime(df['Unnamed: 0'])
        elif 'Date' in df.columns:
            df['timestamp'] = pd.to_datetime(df['Date'])
        elif 'date' in df.columns:
            df['timestamp'] = pd.to_datetime(df['date'])
        
        # à¹à¸›à¸¥à¸‡à¸Šà¸·à¹ˆà¸­à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ
        column_mapping = {
            'Open': 'open',
            'High': 'high', 
            'Low': 'low',
            'Close': 'close',
            'Volume': 'volume'
        }
        df = df.rename(columns=column_mapping)
        
        # à¹€à¸žà¸´à¹ˆà¸¡à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ tic
        df['tic'] = 'BTC-USD'
        
        print(f"âœ… à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¹€à¸£à¹‡à¸ˆ: {len(df)} à¹à¸–à¸§")
        print(f"ðŸ“… à¸Šà¹ˆà¸§à¸‡à¸§à¸±à¸™à¸—à¸µà¹ˆ: {df['timestamp'].min()} à¸–à¸¶à¸‡ {df['timestamp'].max()}")
        print(f"ðŸ“Š à¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œ: {list(df.columns)}")
        
        return df
    else:
        raise FileNotFoundError(f"à¹„à¸¡à¹ˆà¸žà¸šà¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ BTC-USD à¸—à¸µà¹ˆ {btc_file}")

def add_technical_indicators(df):
    """
    à¹€à¸žà¸´à¹ˆà¸¡ technical indicators
    """
    print("\nðŸ“ˆ à¹€à¸žà¸´à¹ˆà¸¡ Technical Indicators...")
    print("-" * 50)
    
    df = df.copy()
    
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™
    required_columns = ['open', 'high', 'low', 'close', 'volume', 'tic', 'timestamp']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"à¹„à¸¡à¹ˆà¸žà¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¸ˆà¸³à¹€à¸›à¹‡à¸™: {', '.join(missing_columns)}")
    
    # 1. Moving Averages
    df['sma_20'] = df.groupby('tic')['close'].transform(lambda x: x.rolling(window=20).mean())
    df['ema_20'] = df.groupby('tic')['close'].transform(lambda x: x.ewm(span=20, adjust=False).mean())
    
    # 2. RSI (Relative Strength Index)
    def calculate_rsi(series):
        delta = series.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        return 100 - (100 / (1 + rs))
    
    df['rsi_14'] = df.groupby('tic')['close'].transform(calculate_rsi)
    
    # 3. MACD
    def calculate_macd(group):
        ema_12 = group['close'].ewm(span=12, adjust=False).mean()
        ema_26 = group['close'].ewm(span=26, adjust=False).mean()
        macd_line = ema_12 - ema_26
        signal_line = macd_line.ewm(span=9, adjust=False).mean()
        histogram = macd_line - signal_line
        return pd.DataFrame({
            'macd': macd_line,
            'macd_signal': signal_line,
            'macd_hist': histogram
        }, index=group.index)
    
    macd_data = df.groupby('tic').apply(calculate_macd).reset_index(level=0, drop=True)
    df = df.join(macd_data)
    
    # 4. Bollinger Bands
    def calculate_bollinger_bands(group):
        sma_20 = group['close'].rolling(window=20).mean()
        std_20 = group['close'].rolling(window=20).std()
        return pd.DataFrame({
            'bb_middle': sma_20,
            'bb_upper': sma_20 + (2 * std_20),
            'bb_lower': sma_20 - (2 * std_20),
            'bb_std': std_20
        }, index=group.index)
    
    bb_data = df.groupby('tic').apply(calculate_bollinger_bands).reset_index(level=0, drop=True)
    df = df.join(bb_data)
    
    # 5. Volume Indicators
    df['volume_sma_20'] = df.groupby('tic')['volume'].transform(lambda x: x.rolling(window=20).mean())
    df['volume_ratio'] = df['volume'] / df['volume_sma_20']
    
    # à¸¥à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ NaN à¸­à¸­à¸
    df = df.dropna()
    
    print(f"âœ… à¹€à¸žà¸´à¹ˆà¸¡ Technical Indicators à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
    print(f"ðŸ“Š à¸ˆà¸³à¸™à¸§à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸±à¸‡à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥: {len(df)} à¹à¸–à¸§")
    print(f"ðŸ“ˆ Indicators à¸—à¸µà¹ˆà¹€à¸žà¸´à¹ˆà¸¡: {INDICATORS}")
    
    return df

def create_environment(df):
    """
    à¸ªà¸£à¹‰à¸²à¸‡ Trading Environment à¸ªà¸³à¸«à¸£à¸±à¸š SAC
    """
    print("\nðŸ—ï¸ à¸ªà¸£à¹‰à¸²à¸‡ Trading Environment...")
    print("-" * 50)
    
    # à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ train à¹à¸¥à¸° test (80:20)
    split_index = int(len(df) * 0.8)
    train_df = df[:split_index].copy()
    test_df = df[split_index:].copy()
    
    print(f"ðŸ“Š à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Training: {len(train_df)} à¹à¸–à¸§")
    print(f"ðŸ“Š à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ Testing: {len(test_df)} à¹à¸–à¸§")
    
    # à¸ªà¸£à¹‰à¸²à¸‡ Environment à¸ªà¸³à¸«à¸£à¸±à¸š Training
    train_env = CryptoTradingEnv(
        df=train_df,
        initial_amount=INITIAL_AMOUNT,
        transaction_cost_pct=TRANSACTION_COST_PCT,
        max_holdings=HMAX
    )
    
    # à¸ªà¸£à¹‰à¸²à¸‡ Environment à¸ªà¸³à¸«à¸£à¸±à¸š Testing
    test_env = CryptoTradingEnv(
        df=test_df,
        initial_amount=INITIAL_AMOUNT,
        transaction_cost_pct=TRANSACTION_COST_PCT,
        max_holdings=HMAX
    )
    
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š environment
    check_env(train_env)
    print("âœ… à¸ªà¸£à¹‰à¸²à¸‡ Environment à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
    
    return train_env, test_env, train_df, test_df

def train_sac_agent(train_env):
    """
    à¸à¸¶à¸ SAC Agent
    """
    print("\nðŸ¤– à¹€à¸£à¸´à¹ˆà¸¡à¸à¸¶à¸ SAC Agent...")
    print("-" * 50)
    
    # Wrap environment
    vec_env = DummyVecEnv([lambda: train_env])
    
    # à¸ªà¸£à¹‰à¸²à¸‡ SAC model
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    model = SAC(
        "MlpPolicy",
        vec_env,
        learning_rate=0.0003,
        buffer_size=100000,
        learning_starts=10000,
        batch_size=256,
        tau=0.005,
        gamma=0.99,
        train_freq=1,
        gradient_steps=1,
        target_update_interval=1,
        verbose=1,
        seed=312,
        device=device
    )
    
    print(f"ðŸ“Š SAC Model à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸³à¹€à¸£à¹‡à¸ˆ (device: {device})")
    print(f"ðŸš€ à¹€à¸£à¸´à¹ˆà¸¡à¸à¸²à¸£à¸à¸¶à¸...")
    
    # à¸à¸¶à¸ model
    model.learn(total_timesteps=50000, progress_bar=False)
    
    print("âœ… à¸à¸¶à¸ SAC Agent à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
    
    return model

def save_sac_agent(trained_model, train_df, test_df):
    """
    à¸šà¸±à¸™à¸—à¸¶à¸ SAC Agent à¹à¸¥à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡
    """
    print("\nðŸ’¾ à¸šà¸±à¸™à¸—à¸¶à¸ SAC Agent...")
    print("-" * 50)
    
    # à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸‹à¹‰à¸³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    random_suffix = ''.join(random.choices(string.ascii_uppercase + string.digits, k=6))
    model_name = f"sac_agent_{timestamp}_{random_suffix}"
    
    # à¸šà¸±à¸™à¸—à¸¶à¸ trained model (.zip)
    model_zip_path = os.path.join("agents", "sac", f"{model_name}.zip")
    trained_model.save(model_zip_path)
    print(f"âœ… à¸šà¸±à¸™à¸—à¸¶à¸ model: {model_zip_path}")
    
    # à¸šà¸±à¸™à¸—à¸¶à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡ (.pkl)
    agent_info = {
        'model_name': model_name,
        'algorithm': 'SAC',
        'created_date': datetime.now().isoformat(),
        'crypto_symbols': CRYPTO_SYMBOLS,
        'indicators': INDICATORS,
        'initial_amount': INITIAL_AMOUNT,
        'transaction_cost_pct': TRANSACTION_COST_PCT,
        'hmax': HMAX,
        'train_data_shape': train_df.shape,
        'test_data_shape': test_df.shape,
        'train_date_range': {
            'start': str(train_df['timestamp'].min()),
            'end': str(train_df['timestamp'].max())
        },
        'test_date_range': {
            'start': str(test_df['timestamp'].min()),
            'end': str(test_df['timestamp'].max())
        }
    }
    
    agent_info_path = os.path.join("agents", "sac", f"{model_name}_info.pkl")
    with open(agent_info_path, 'wb') as f:
        pickle.dump(agent_info, f)
    print(f"âœ… à¸šà¸±à¸™à¸—à¸¶à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ agent: {agent_info_path}")
    
    # à¹à¸ªà¸”à¸‡à¸ªà¸£à¸¸à¸›
    print(f"\nðŸ“‹ à¸ªà¸£à¸¸à¸›à¸à¸²à¸£à¸šà¸±à¸™à¸—à¸¶à¸ SAC Agent:")
    print(f"ðŸ”¤ à¸Šà¸·à¹ˆà¸­ Model: {model_name}")
    print(f"ðŸ“ à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ: agents/sac/")
    print(f"ðŸ“¦ à¹„à¸Ÿà¸¥à¹Œ Model: {model_name}.zip")
    print(f"ðŸ“„ à¹„à¸Ÿà¸¥à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥: {model_name}_info.pkl")
    
    return model_name, agent_info

def test_sac_agent(trained_model, test_env):
    """
    à¸—à¸”à¸ªà¸­à¸š SAC Agent
    """
    print("\nðŸ§ª à¸—à¸”à¸ªà¸­à¸š SAC Agent...")
    print("-" * 50)
    
    try:
        obs, _ = test_env.reset()
        account_values = []
        actions_taken = []
        
        for step in range(len(test_env.df) - 21):  # -21 à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸«à¸¥à¸·à¸­à¸žà¸­à¸ªà¸³à¸«à¸£à¸±à¸š indicators
            action, _ = trained_model.predict(obs, deterministic=True)
            obs, reward, done, truncated, info = test_env.step(action)
            
            account_values.append(info['total_value'])
            actions_taken.append(action[0])
            
            if done or truncated:
                break
        
        print("âœ… à¸—à¸”à¸ªà¸­à¸š SAC Agent à¸ªà¸³à¹€à¸£à¹‡à¸ˆ")
        print(f"ðŸ“Š à¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š: {len(account_values)} à¸§à¸±à¸™")
        
        # à¹à¸ªà¸”à¸‡à¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸šà¸ªà¸±à¹‰à¸™à¹†
        if account_values:
            initial_value = INITIAL_AMOUNT
            final_value = account_values[-1]
            total_return = (final_value - initial_value) / initial_value * 100
            
            print(f"ðŸ’° à¹€à¸‡à¸´à¸™à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™: ${initial_value:,.2f}")
            print(f"ðŸ’° à¹€à¸‡à¸´à¸™à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢: ${final_value:,.2f}")
            print(f"ðŸ“ˆ à¸œà¸¥à¸•à¸­à¸šà¹à¸—à¸™à¸£à¸§à¸¡: {total_return:.2f}%")
        
        return account_values, actions_taken
        
    except Exception as e:
        print(f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š: {str(e)}")
        return None, None

def main():
    """
    à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸«à¸¥à¸±à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸£à¸±à¸™ SAC Agent
    """
    print("ðŸš€ SAC (Soft Actor-Critic) Cryptocurrency Trading Agent")
    print("=" * 60)
    
    try:
        # 1. Setup device
        device = setup_device()
        
        # 2. à¹‚à¸«à¸¥à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
        df = load_existing_data()
        
        # 3. à¹€à¸žà¸´à¹ˆà¸¡ technical indicators
        df = add_technical_indicators(df)
        
        # 4. à¸ªà¸£à¹‰à¸²à¸‡ environment
        train_env, test_env, train_df, test_df = create_environment(df)
        
        # 5. à¸à¸¶à¸ SAC agent
        trained_model = train_sac_agent(train_env)
        
        # 6. à¸šà¸±à¸™à¸—à¸¶à¸ agent
        model_name, agent_info = save_sac_agent(trained_model, train_df, test_df)
        
        # 7. à¸—à¸”à¸ªà¸­à¸š agent
        account_values, actions_taken = test_sac_agent(trained_model, test_env)
        
        print("\nðŸŽ‰ à¸ªà¸³à¹€à¸£à¹‡à¸ˆ! SAC Agent à¸–à¸¹à¸à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¸šà¸±à¸™à¸—à¸¶à¸à¹à¸¥à¹‰à¸§")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”: {str(e)}")
        print("ðŸ” à¸à¸£à¸¸à¸“à¸²à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹à¸¥à¸°à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆà¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡")
        sys.exit(1)

if __name__ == "__main__":
    main() 