{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Agent (Agent Evaluation & Improvement)\n",
    "## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á RL Agent ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Crypto Trading\n",
    "\n",
    "### ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:\n",
    "- ‡πÇ‡∏´‡∏•‡∏î Trained Model\n",
    "- ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ö‡∏ô Test Data\n",
    "- ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Baseline (Buy & Hold)\n",
    "- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Trading Patterns\n",
    "- ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Model ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Live Trading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Import Libraries ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from stable_baselines3 import PPO, A2C, DDPG, SAC\n",
    "\n",
    "# FinRL imports\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "# Import config\n",
    "from config import *\n",
    "\n",
    "# Setup directories\n",
    "PROCESSED_DIR = \"processed_data\"\n",
    "MODEL_DIR = \"models\"\n",
    "AGENT_DIR = \"agents\"\n",
    "EVALUATION_DIR = \"evaluation\"\n",
    "REPORTS_DIR = \"reports\"\n",
    "\n",
    "for dir_name in [EVALUATION_DIR, REPORTS_DIR]:\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "print(\"üìÅ Setup directories completed\")\n",
    "print(f\"üìä Starting Agent Evaluation Process\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: ‡πÇ‡∏´‡∏•‡∏î Models ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_setup():\n",
    "    \"\"\"\n",
    "    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "    \"\"\"\n",
    "    print(\"üìÇ Loading evaluation setup...\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "    try:\n",
    "        pickle_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.pkl\")\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        print(f\"‚úÖ Loaded processed data\")\n",
    "    except:\n",
    "        csv_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.csv\")\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        print(f\"‚úÖ Loaded processed data from CSV\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î environment config\n",
    "    env_config_file = os.path.join(AGENT_DIR, \"environment_config.pkl\")\n",
    "    with open(env_config_file, 'rb') as f:\n",
    "        env_config = pickle.load(f)\n",
    "    print(f\"‚úÖ Loaded environment config\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î training results\n",
    "    training_files = [f for f in os.listdir(MODEL_DIR) if f.startswith('training_info_') and f.endswith('.pkl')]\n",
    "    \n",
    "    trained_models = {}\n",
    "    for training_file in training_files:\n",
    "        model_name = training_file.replace('training_info_', '').replace('.pkl', '')\n",
    "        \n",
    "        with open(os.path.join(MODEL_DIR, training_file), 'rb') as f:\n",
    "            training_info = pickle.load(f)\n",
    "        \n",
    "        # ‡πÇ‡∏´‡∏•‡∏î trained model\n",
    "        model_path = training_info['model_path']\n",
    "        if os.path.exists(model_path + '.zip'):\n",
    "            model_type = training_info['model_name'].split('_')[0].upper()\n",
    "            \n",
    "            if model_type == 'PPO':\n",
    "                model = PPO.load(model_path)\n",
    "            elif model_type == 'A2C':\n",
    "                model = A2C.load(model_path)\n",
    "            elif model_type == 'DDPG':\n",
    "                model = DDPG.load(model_path)\n",
    "            elif model_type == 'SAC':\n",
    "                model = SAC.load(model_path)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Unknown model type: {model_type}\")\n",
    "                continue\n",
    "            \n",
    "            trained_models[model_name] = {\n",
    "                'model': model,\n",
    "                'training_info': training_info,\n",
    "                'model_type': model_type\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Loaded {model_type} model: {model_name}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Model file not found: {model_path}\")\n",
    "    \n",
    "    if not trained_models:\n",
    "        raise ValueError(\"No trained models found!\")\n",
    "    \n",
    "    return df, env_config, trained_models\n",
    "\n",
    "def recreate_test_environment(df, env_config):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "    \"\"\"\n",
    "    print(\"üèõÔ∏è Creating test environment...\")\n",
    "    \n",
    "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°\n",
    "    total_len = len(df)\n",
    "    train_size = int(total_len * 0.7)\n",
    "    val_size = int(total_len * 0.15)\n",
    "    \n",
    "    test_df = df.iloc[train_size + val_size:].reset_index(drop=True)\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "    test_df['date'] = test_df['timestamp'].dt.date\n",
    "    test_df.sort_values(['date', 'tic'], inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment\n",
    "    env_kwargs = env_config['env_kwargs']\n",
    "    test_env = StockTradingEnv(df=test_df, **env_kwargs)\n",
    "    \n",
    "    print(f\"‚úÖ Test environment created\")\n",
    "    print(f\"üìä Test data: {len(test_df)} rows\")\n",
    "    print(f\"üìÖ Date range: {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "    \n",
    "    return test_env, test_df\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ models\n",
    "df, env_config, trained_models = load_evaluation_setup()\n",
    "test_env, test_df = recreate_test_environment(df, env_config)\n",
    "\n",
    "print(f\"\\nüìä Evaluation setup completed:\")\n",
    "print(f\"  Available models: {list(trained_models.keys())}\")\n",
    "print(f\"  Test data points: {len(test_df)}\")\n",
    "print(f\"  Symbols: {test_df['tic'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• Models ‡∏ö‡∏ô Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(model_info, test_env, test_df, model_name):\n",
    "    \"\"\"\n",
    "    ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á model ‡∏ö‡∏ô test data\n",
    "    \"\"\"\n",
    "    print(f\"üìä Evaluating {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # ‡∏£‡∏±‡∏ô prediction\n",
    "        account_value, actions = DRLAgent.DRL_prediction(\n",
    "            model=model_info['model'],\n",
    "            environment=test_env\n",
    "        )\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì performance metrics\n",
    "        initial_value = INITIAL_AMOUNT\n",
    "        final_value = account_value['account_value'].iloc[-1]\n",
    "        total_return = (final_value - initial_value) / initial_value * 100\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Sharpe ratio\n",
    "        returns = account_value['account_value'].pct_change().dropna()\n",
    "        sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Maximum Drawdown\n",
    "        running_max = account_value['account_value'].expanding().max()\n",
    "        drawdown = (account_value['account_value'] - running_max) / running_max\n",
    "        max_drawdown = drawdown.min() * 100\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Volatility\n",
    "        volatility = returns.std() * np.sqrt(252) * 100\n",
    "        \n",
    "        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô trades\n",
    "        total_trades = len(actions[actions != 0]) if len(actions) > 0 else 0\n",
    "        \n",
    "        results = {\n",
    "            'model_name': model_name,\n",
    "            'model_type': model_info['model_type'],\n",
    "            'initial_value': initial_value,\n",
    "            'final_value': final_value,\n",
    "            'total_return': total_return,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'volatility': volatility,\n",
    "            'total_trades': total_trades,\n",
    "            'account_values': account_value,\n",
    "            'actions': actions,\n",
    "            'daily_returns': returns\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} evaluation completed\")\n",
    "        print(f\"  Total Return: {total_return:.2f}%\")\n",
    "        print(f\"  Sharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "        print(f\"  Max Drawdown: {max_drawdown:.2f}%\")\n",
    "        print(f\"  Volatility: {volatility:.2f}%\")\n",
    "        print(f\"  Total Trades: {total_trades}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error evaluating {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def calculate_buy_hold_baseline(test_df, symbols):\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Buy & Hold baseline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "    \"\"\"\n",
    "    print(\"üìà Calculating Buy & Hold baseline...\")\n",
    "    \n",
    "    baseline_results = {}\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        symbol_data = test_df[test_df['tic'] == symbol].copy()\n",
    "        \n",
    "        if len(symbol_data) > 0:\n",
    "            # ‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì return ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á\n",
    "            initial_price = symbol_data['close'].iloc[0]\n",
    "            final_price = symbol_data['close'].iloc[-1]\n",
    "            \n",
    "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì return ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ normalized\n",
    "            price_change = (final_price - initial_price) / abs(initial_price) if initial_price != 0 else 0\n",
    "            \n",
    "            # ‡∏à‡∏≥‡∏•‡∏≠‡∏á portfolio value\n",
    "            portfolio_value = INITIAL_AMOUNT * (1 + price_change)\n",
    "            total_return = price_change * 100\n",
    "            \n",
    "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics ‡∏≠‡∏∑‡πà‡∏ô‡πÜ\n",
    "            returns = symbol_data['close'].pct_change().dropna()\n",
    "            sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "            volatility = returns.std() * np.sqrt(252) * 100\n",
    "            \n",
    "            # Maximum Drawdown\n",
    "            cumulative_returns = (1 + returns).cumprod()\n",
    "            running_max = cumulative_returns.expanding().max()\n",
    "            drawdown = (cumulative_returns - running_max) / running_max\n",
    "            max_drawdown = drawdown.min() * 100\n",
    "            \n",
    "            baseline_results[symbol] = {\n",
    "                'total_return': total_return,\n",
    "                'final_value': portfolio_value,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'max_drawdown': max_drawdown,\n",
    "                'volatility': volatility\n",
    "            }\n",
    "            \n",
    "            print(f\"  {symbol}: {total_return:.2f}% return\")\n",
    "    \n",
    "    return baseline_results\n",
    "\n",
    "# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ó‡∏∏‡∏Å models\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name, model_info in trained_models.items():\n",
    "    results = evaluate_model_performance(model_info, test_env, test_df, model_name)\n",
    "    if results:\n",
    "        evaluation_results[model_name] = results\n",
    "\n",
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì baseline\n",
    "symbols = test_df['tic'].unique()\n",
    "baseline_results = calculate_buy_hold_baseline(test_df, symbols)\n",
    "\n",
    "print(f\"\\nüìä Evaluation completed for {len(evaluation_results)} models\")\n",
    "print(f\"üìà Baseline calculated for {len(baseline_results)} symbols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_comparison():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å models\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating performance comparison...\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "    comparison_data = []\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• RL models\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': results['model_type'],\n",
    "            'Strategy': f\"RL-{results['model_type']}\",\n",
    "            'Total Return (%)': results['total_return'],\n",
    "            'Final Value ($)': results['final_value'],\n",
    "            'Sharpe Ratio': results['sharpe_ratio'],\n",
    "            'Max Drawdown (%)': results['max_drawdown'],\n",
    "            'Volatility (%)': results['volatility'],\n",
    "            'Total Trades': results['total_trades']\n",
    "        })\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Baseline strategies\n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': f\"Buy&Hold\",\n",
    "            'Strategy': f\"B&H-{symbol}\",\n",
    "            'Total Return (%)': baseline['total_return'],\n",
    "            'Final Value ($)': baseline['final_value'],\n",
    "            'Sharpe Ratio': baseline['sharpe_ratio'],\n",
    "            'Max Drawdown (%)': baseline['max_drawdown'],\n",
    "            'Volatility (%)': baseline['volatility'],\n",
    "            'Total Trades': 1  # Buy once and hold\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    comparison_df = comparison_df.sort_values('Total Return (%)', ascending=False)\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "def plot_performance_analysis(evaluation_results, baseline_results):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå performance\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating performance analysis plots...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Portfolio Values Over Time\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        account_values = results['account_values']['account_value']\n",
    "        axes[0, 0].plot(account_values.values, label=f\"{results['model_type']}\", linewidth=2)\n",
    "    \n",
    "    axes[0, 0].axhline(y=INITIAL_AMOUNT, color='red', linestyle='--', alpha=0.7, label='Initial Value')\n",
    "    axes[0, 0].set_title('Portfolio Value Over Time')\n",
    "    axes[0, 0].set_ylabel('Portfolio Value ($)')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Total Returns Comparison\n",
    "    model_names = []\n",
    "    model_returns = []\n",
    "    colors = []\n",
    "    \n",
    "    # RL models\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        model_names.append(results['model_type'])\n",
    "        model_returns.append(results['total_return'])\n",
    "        colors.append('skyblue')\n",
    "    \n",
    "    # Baseline\n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        model_names.append(f\"B&H-{symbol}\")\n",
    "        model_returns.append(baseline['total_return'])\n",
    "        colors.append('lightcoral')\n",
    "    \n",
    "    bars = axes[0, 1].bar(range(len(model_names)), model_returns, color=colors, alpha=0.7)\n",
    "    axes[0, 1].set_title('Total Returns Comparison')\n",
    "    axes[0, 1].set_ylabel('Return (%)')\n",
    "    axes[0, 1].set_xticks(range(len(model_names)))\n",
    "    axes[0, 1].set_xticklabels(model_names, rotation=45)\n",
    "    axes[0, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, model_returns):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + (0.5 if height > 0 else -1.5),\n",
    "                       f'{value:.1f}%', ha='center', va='bottom' if height > 0 else 'top', fontsize=9)\n",
    "    \n",
    "    # Plot 3: Sharpe Ratio Comparison\n",
    "    sharpe_ratios = []\n",
    "    \n",
    "    for model_name, results in evaluation_results.items():\n",
    "        sharpe_ratios.append(results['sharpe_ratio'])\n",
    "    \n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        sharpe_ratios.append(baseline['sharpe_ratio'])\n",
    "    \n",
    "    bars = axes[0, 2].bar(range(len(model_names)), sharpe_ratios, color=colors, alpha=0.7)\n",
    "    axes[0, 2].set_title('Sharpe Ratio Comparison')\n",
    "    axes[0, 2].set_ylabel('Sharpe Ratio')\n",
    "    axes[0, 2].set_xticks(range(len(model_names)))\n",
    "    axes[0, 2].set_xticklabels(model_names, rotation=45)\n",
    "    axes[0, 2].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, sharpe_ratios):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 2].text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                       f'{value:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Plot 4: Maximum Drawdown Comparison\n",
    "    max_drawdowns = []\n",
    "    \n",
    "    for model_name, results in evaluation_results.items():\n",
    "        max_drawdowns.append(results['max_drawdown'])\n",
    "    \n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        max_drawdowns.append(baseline['max_drawdown'])\n",
    "    \n",
    "    bars = axes[1, 0].bar(range(len(model_names)), max_drawdowns, color=colors, alpha=0.7)\n",
    "    axes[1, 0].set_title('Maximum Drawdown Comparison')\n",
    "    axes[1, 0].set_ylabel('Drawdown (%)')\n",
    "    axes[1, 0].set_xticks(range(len(model_names)))\n",
    "    axes[1, 0].set_xticklabels(model_names, rotation=45)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, max_drawdowns):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height - 1,\n",
    "                       f'{value:.1f}%', ha='center', va='top', fontsize=9)\n",
    "    \n",
    "    # Plot 5: Volatility Comparison\n",
    "    volatilities = []\n",
    "    \n",
    "    for model_name, results in evaluation_results.items():\n",
    "        volatilities.append(results['volatility'])\n",
    "    \n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        volatilities.append(baseline['volatility'])\n",
    "    \n",
    "    bars = axes[1, 1].bar(range(len(model_names)), volatilities, color=colors, alpha=0.7)\n",
    "    axes[1, 1].set_title('Volatility Comparison')\n",
    "    axes[1, 1].set_ylabel('Volatility (%)')\n",
    "    axes[1, 1].set_xticks(range(len(model_names)))\n",
    "    axes[1, 1].set_xticklabels(model_names, rotation=45)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, volatilities):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                       f'{value:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Plot 6: Trading Frequency\n",
    "    trade_counts = []\n",
    "    \n",
    "    for model_name, results in evaluation_results.items():\n",
    "        trade_counts.append(results['total_trades'])\n",
    "    \n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        trade_counts.append(1)  # Buy & Hold = 1 trade\n",
    "    \n",
    "    bars = axes[1, 2].bar(range(len(model_names)), trade_counts, color=colors, alpha=0.7)\n",
    "    axes[1, 2].set_title('Trading Frequency')\n",
    "    axes[1, 2].set_ylabel('Number of Trades')\n",
    "    axes[1, 2].set_xticks(range(len(model_names)))\n",
    "    axes[1, 2].set_xticklabels(model_names, rotation=45)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, trade_counts):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 2].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                       f'{value}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "comparison_df = create_performance_comparison()\n",
    "print(\"\\nüìä Performance Comparison Table:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå\n",
    "fig = plot_performance_analysis(evaluation_results, baseline_results)\n",
    "\n",
    "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "comparison_df.to_csv(os.path.join(REPORTS_DIR, f'performance_comparison_{timestamp}.csv'), index=False)\n",
    "fig.savefig(os.path.join(REPORTS_DIR, f'performance_analysis_{timestamp}.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to {REPORTS_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
