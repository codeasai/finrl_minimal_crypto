{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 4. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Agent (Agent Evaluation)\n",
    "## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô RL Agent ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Crypto Trading\n",
    "\n",
    "### ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:\n",
    "- ‡πÇ‡∏´‡∏•‡∏î Model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß\n",
    "- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Agent ‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Test Set\n",
    "- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£ Trading\n",
    "- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Performance Metrics\n",
    "- ‡∏™‡∏£‡πâ‡∏≤‡∏á Visualization ‡πÅ‡∏•‡∏∞ Report\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Cell 1: Import Libraries ‡πÅ‡∏•‡∏∞ Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# FinRL imports\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "# Import config\n",
    "from config import *\n",
    "\n",
    "# Setup directories\n",
    "PROCESSED_DIR = \"processed_data\"\n",
    "MODEL_DIR = \"models\"\n",
    "AGENT_DIR = \"agents\"\n",
    "EVALUATION_DIR = \"evaluation\"\n",
    "REPORTS_DIR = \"reports\"\n",
    "\n",
    "for dir_name in [EVALUATION_DIR, REPORTS_DIR]:\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "# Setup matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"üìÅ Setup directories completed\")\n",
    "print(f\"üìä Starting Agent Evaluation Process\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Cell 2: ‡πÇ‡∏´‡∏•‡∏î Trained Model ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î Trained Model\n",
    "def load_trained_model():\n",
    "    print(\"üìÇ Loading trained model and configurations...\")\n",
    "    try:\n",
    "        # ‡πÇ‡∏´‡∏•‡∏î model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß\n",
    "        model_path = os.path.join(MODEL_DIR, \"trained_ppo_simple.zip\")\n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "        \n",
    "        # ‡πÇ‡∏´‡∏•‡∏î training info\n",
    "        training_info_path = os.path.join(MODEL_DIR, \"training_info_ppo.pkl\")\n",
    "        with open(training_info_path, 'rb') as f:\n",
    "            training_info = pickle.load(f)\n",
    "        \n",
    "        # ‡πÇ‡∏´‡∏•‡∏î agent configs\n",
    "        agent_configs_path = os.path.join(AGENT_DIR, \"agent_configs.pkl\")\n",
    "        with open(agent_configs_path, 'rb') as f:\n",
    "            agent_configs = pickle.load(f)\n",
    "        \n",
    "        # ‡πÇ‡∏´‡∏•‡∏î environment config\n",
    "        env_config_path = os.path.join(AGENT_DIR, \"environment_config.pkl\")\n",
    "        with open(env_config_path, 'rb') as f:\n",
    "            env_config = pickle.load(f)\n",
    "        \n",
    "        print(\"‚úÖ Model ‡πÅ‡∏•‡∏∞ configurations ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à\")\n",
    "        return model_path, training_info, agent_configs, env_config\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {str(e)}\")\n",
    "        print(\"üîÑ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô notebook 3_agent_training.ipynb ‡∏Å‡πà‡∏≠‡∏ô\")\n",
    "        raise\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "def load_test_data():\n",
    "    print(\"üìä Loading test data...\")\n",
    "    try:\n",
    "        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "        with open(os.path.join(PROCESSED_DIR, 'processed_crypto_data.pkl'), 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        \n",
    "        # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô train/val/test (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÉ‡∏ô notebook 3)\n",
    "        total_len = len(df)\n",
    "        train_size = int(total_len * 0.7)\n",
    "        val_size = int(total_len * 0.15)\n",
    "        \n",
    "        # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞ test data\n",
    "        test_df = df.iloc[train_size + val_size:].reset_index(drop=True).copy()\n",
    "        \n",
    "        print(f\"‚úÖ Test data loaded: {len(test_df)} rows\")\n",
    "        print(f\"üìÖ Test period: {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "        print(f\"üí∞ Cryptocurrencies: {sorted(test_df['tic'].unique())}\")\n",
    "        \n",
    "        return test_df\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}\")\n",
    "        print(\"üîÑ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô notebook 1_data_preparation.ipynb ‡∏Å‡πà‡∏≠‡∏ô\")\n",
    "        raise\n",
    "\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô\n",
    "model_path, training_info, agent_configs, env_config = load_trained_model()\n",
    "test_df = load_test_data()\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• training info\n",
    "print(f\"\\nüìã Training Information:\")\n",
    "print(f\"  ü§ñ Model: {training_info.get('model_name', 'Unknown')}\")\n",
    "print(f\"  üìä Total timesteps: {training_info.get('total_timesteps', 'Unknown'):,}\")\n",
    "print(f\"  ‚è±Ô∏è Training time: {training_info.get('training_time', 'Unknown')}\")\n",
    "print(f\"  üéØ Final reward: {training_info.get('final_reward', 'Unknown')}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Cell 3: ‡∏™‡∏£‡πâ‡∏≤‡∏á Test Environment ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠–± Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Test Environment\n",
    "def create_test_environment(test_df, env_config):\n",
    "    print(\"üèóÔ∏è Creating test environment...\")\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• test ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FinRL\n",
    "    test_data = test_df.copy()\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö FinRL\n",
    "    if 'close' not in test_data.columns:\n",
    "        if 'Close' in test_data.columns:\n",
    "            test_data['close'] = test_data['Close']\n",
    "        else:\n",
    "            raise ValueError(\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "    if 'date' not in test_data.columns and 'timestamp' in test_data.columns:\n",
    "        test_data['timestamp'] = pd.to_datetime(test_data['timestamp'])\n",
    "        test_data['date'] = test_data['timestamp'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    test_data.sort_values(['date', 'tic'], inplace=True)\n",
    "    test_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á day index\n",
    "    unique_dates = sorted(test_data['date'].unique())\n",
    "    date_to_index = {date: idx for idx, date in enumerate(unique_dates)}\n",
    "    test_data['day'] = test_data['date'].map(date_to_index)\n",
    "    test_data.set_index('day', inplace=True)\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° environment kwargs\n",
    "    env_kwargs = env_config['env_kwargs'].copy()\n",
    "    env_kwargs.pop('df', None)  # ‡∏•‡∏ö df ‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡∏ã‡πâ‡∏≥\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment\n",
    "    test_env = StockTradingEnv(df=test_data, **env_kwargs)\n",
    "    \n",
    "    print(f\"‚úÖ Test environment created successfully\")\n",
    "    print(f\"üìä Test data shape: {test_data.shape}\")\n",
    "    print(f\"üìÖ Test period: {test_data.index.min()} to {test_data.index.max()} days\")\n",
    "    \n",
    "    return test_env, test_data\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Agent\n",
    "def test_agent(model_path, test_env, agent_configs):\n",
    "    print(\"üß™ Testing trained agent...\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î model\n",
    "    model_name = agent_configs['model_name']\n",
    "    agent = DRLAgent(env=test_env)\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î model ‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß\n",
    "    model = agent.get_model(model_name)\n",
    "    model = model.load(model_path)\n",
    "    \n",
    "    print(f\"‚úÖ Model {model_name} loaded successfully\")\n",
    "    \n",
    "    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö agent\n",
    "    print(\"üöÄ Running agent on test data...\")\n",
    "    \n",
    "    # reset environment\n",
    "    obs = test_env.reset()\n",
    "    done = False\n",
    "    \n",
    "    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "    test_results = {\n",
    "        'actions': [],\n",
    "        'rewards': [],\n",
    "        'portfolio_values': [],\n",
    "        'positions': [],\n",
    "        'timestamps': []\n",
    "    }\n",
    "    \n",
    "    step = 0\n",
    "    while not done:\n",
    "        # ‡πÉ‡∏´‡πâ agent ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        \n",
    "        # ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ action\n",
    "        obs, reward, done, info = test_env.step(action)\n",
    "        \n",
    "        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "        test_results['actions'].append(action)\n",
    "        test_results['rewards'].append(reward)\n",
    "        test_results['portfolio_values'].append(test_env.asset_memory[-1])\n",
    "        test_results['positions'].append(test_env.state[test_env.stock_dim:test_env.stock_dim*2])\n",
    "        \n",
    "        step += 1\n",
    "        if step % 100 == 0:\n",
    "            print(f\"  Step {step}, Portfolio Value: ${test_env.asset_memory[-1]:,.2f}\")\n",
    "    \n",
    "    print(f\"‚úÖ Testing completed after {step} steps\")\n",
    "    print(f\"üí∞ Final Portfolio Value: ${test_env.asset_memory[-1]:,.2f}\")\n",
    "    print(f\"üìà Total Return: {(test_env.asset_memory[-1] / test_env.initial_amount - 1) * 100:.2f}%\")\n",
    "    \n",
    "    return test_results, test_env\n",
    "\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô\n",
    "test_env, test_data = create_test_environment(test_df, env_config)\n",
    "test_results, test_env_final = test_agent(model_path, test_env, agent_configs)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Cell 4: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Performance Metrics\n",
    "def calculate_performance_metrics(test_env, test_results):\n",
    "    print(\"üìà Calculating performance metrics...\")\n",
    "    \n",
    "    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô\n",
    "    initial_amount = test_env.initial_amount\n",
    "    final_amount = test_env.asset_memory[-1]\n",
    "    total_return = (final_amount / initial_amount - 1) * 100\n",
    "    \n",
    "    # Portfolio values over time\n",
    "    portfolio_values = test_env.asset_memory\n",
    "    returns = pd.Series(portfolio_values).pct_change().dropna()\n",
    "    \n",
    "    # Performance metrics\n",
    "    metrics = {\n",
    "        'Initial Amount': f\"${initial_amount:,.2f}\",\n",
    "        'Final Amount': f\"${final_amount:,.2f}\",\n",
    "        'Total Return': f\"{total_return:.2f}%\",\n",
    "        'Sharpe Ratio': returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0,\n",
    "        'Max Drawdown': f\"{(returns.cumsum().expanding().max() - returns.cumsum()).max() * 100:.2f}%\",\n",
    "        'Volatility': f\"{returns.std() * np.sqrt(252) * 100:.2f}%\",\n",
    "        'Total Trades': len([a for a in test_results['actions'] if np.sum(np.abs(a)) > 0])\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á Visualization\n",
    "def create_visualizations(test_env, test_results, test_data):\n",
    "    print(\"üìä Creating visualizations...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Portfolio Value over Time\n",
    "    axes[0, 0].plot(test_env.asset_memory, linewidth=2, color='blue')\n",
    "    axes[0, 0].axhline(y=test_env.initial_amount, color='red', linestyle='--', alpha=0.7, label='Initial Amount')\n",
    "    axes[0, 0].set_title('Portfolio Value Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Trading Days')\n",
    "    axes[0, 0].set_ylabel('Portfolio Value ($)')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Daily Returns Distribution\n",
    "    portfolio_values = pd.Series(test_env.asset_memory)\n",
    "    daily_returns = portfolio_values.pct_change().dropna()\n",
    "    axes[0, 1].hist(daily_returns, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[0, 1].axvline(daily_returns.mean(), color='red', linestyle='--', label=f'Mean: {daily_returns.mean():.4f}')\n",
    "    axes[0, 1].set_title('Daily Returns Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Daily Return')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Cumulative Returns\n",
    "    cumulative_returns = (1 + daily_returns).cumprod() - 1\n",
    "    axes[1, 0].plot(cumulative_returns * 100, linewidth=2, color='purple')\n",
    "    axes[1, 0].set_title('Cumulative Returns (%)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Trading Days')\n",
    "    axes[1, 0].set_ylabel('Cumulative Return (%)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Rewards over Time\n",
    "    rewards = test_results['rewards']\n",
    "    axes[1, 1].plot(rewards, linewidth=1, alpha=0.7, color='orange')\n",
    "    axes[1, 1].plot(pd.Series(rewards).rolling(window=50).mean(), linewidth=2, color='red', label='50-day MA')\n",
    "    axes[1, 1].set_title('Rewards Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Trading Days')\n",
    "    axes[1, 1].set_ylabel('Reward')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(EVALUATION_DIR, 'agent_performance.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô\n",
    "metrics = calculate_performance_metrics(test_env_final, test_results)\n",
    "\n",
    "print(\"üìä Performance Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key:.<30} {value}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á visualizations\n",
    "create_visualizations(test_env_final, test_results, test_data)\n",
    "\n",
    "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "results_summary = {\n",
    "    'metrics': metrics,\n",
    "    'test_results': test_results,\n",
    "    'evaluation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open(os.path.join(EVALUATION_DIR, 'evaluation_results.pkl'), 'wb') as f:\n",
    "    pickle.dump(results_summary, f)\n",
    "\n",
    "print(f\"\\n‚úÖ Evaluation completed successfully!\")\n",
    "print(f\"üìÅ Results saved to: {EVALUATION_DIR}/\")\n",
    "print(f\"üìä Visualizations saved to: {EVALUATION_DIR}/agent_performance.png\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 4. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Agent (Agent Evaluation & Improvement)\n",
    "## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á RL Agent ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Crypto Trading\n",
    "\n",
    "### ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:\n",
    "- ‡πÇ‡∏´‡∏•‡∏î Trained Model\n",
    "- ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ö‡∏ô Test Data\n",
    "- ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Baseline (Buy & Hold)\n",
    "- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Trading Patterns\n",
    "- ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Model ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Live Trading\n",
    "\n",
    "**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** Notebook ‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å `main.py` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Cell 1: Setup ‡πÅ‡∏•‡∏∞ Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Agent Evaluation Process\n",
      "============================================================\n",
      "\n",
      "üîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU/CPU\n",
      "--------------------------------------------------\n",
      "‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GPU ‡πÉ‡∏ä‡πâ CPU ‡πÅ‡∏ó‡∏ô\n",
      "‚úÖ All directories already exist\n",
      "üìÅ Setup directories completed\n",
      "üìä Agent Evaluation System Ready\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from stable_baselines3 import PPO, A2C, DDPG, SAC\n",
    "\n",
    "# FinRL imports\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "# Import config\n",
    "from config import *\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"\n",
    "    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU/CPU (‡∏ô‡∏≥‡∏°‡∏≤‡∏à‡∏≤‡∏Å main.py)\n",
    "    \"\"\"\n",
    "    print(\"\\nüîç ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU/CPU\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(f\"‚úÖ ‡∏û‡∏ö GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô GPU: {torch.cuda.device_count()}\")\n",
    "        print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GPU ‡πÉ‡∏ä‡πâ CPU ‡πÅ‡∏ó‡∏ô\")\n",
    "    \n",
    "    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ environment variable ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Stable Baselines3\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" if torch.cuda.is_available() else \"-1\"\n",
    "    \n",
    "    return device\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏ô‡∏≥‡∏°‡∏≤‡∏à‡∏≤‡∏Å main.py)\n",
    "    \"\"\"\n",
    "    directories = {\n",
    "        'PROCESSED_DIR': \"processed_data\",\n",
    "        'MODEL_DIR': \"models\", \n",
    "        'AGENT_DIR': \"agents\",\n",
    "        'EVALUATION_DIR': \"evaluation\",\n",
    "        'REPORTS_DIR': \"reports\"\n",
    "    }\n",
    "    \n",
    "    created_dirs = []\n",
    "    for name, path in directories.items():\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            created_dirs.append(path)\n",
    "            print(f\"üìÅ Created directory: {path}\")\n",
    "        globals()[name] = path\n",
    "    \n",
    "    if created_dirs:\n",
    "        print(f\"‚úÖ Created {len(created_dirs)} directories\")\n",
    "    else:\n",
    "        print(\"‚úÖ All directories already exist\")\n",
    "    \n",
    "    return directories\n",
    "\n",
    "# Initialize system\n",
    "print(\"üöÄ Starting Agent Evaluation Process\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Setup device ‡πÅ‡∏•‡∏∞ directories\n",
    "device = setup_device()\n",
    "dirs = setup_directories()\n",
    "\n",
    "# Global variables\n",
    "PROCESSED_DIR = dirs['PROCESSED_DIR'] \n",
    "MODEL_DIR = dirs['MODEL_DIR']\n",
    "AGENT_DIR = dirs['AGENT_DIR']\n",
    "EVALUATION_DIR = dirs['EVALUATION_DIR']\n",
    "REPORTS_DIR = dirs['REPORTS_DIR']\n",
    "\n",
    "# Global status variables\n",
    "SETUP_SUCCESS = False\n",
    "EVALUATION_SUCCESS = False\n",
    "\n",
    "print(\"üìÅ Setup directories completed\")\n",
    "print(f\"üìä Agent Evaluation System Ready\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Cell 2: Data Loading ‡πÅ‡∏•‡∏∞ Environment Setup (‡∏ô‡∏≥‡∏°‡∏≤‡∏à‡∏≤‡∏Å main.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting comprehensive evaluation setup...\n",
      "üìÇ Loading evaluation setup...\n",
      "‚úÖ Loaded processed data from pickle (5480 rows)\n",
      "‚úÖ Loaded environment config\n",
      "‚úÖ Loaded PPO model: ppo\n",
      "üèõÔ∏è Creating robust test environment...\n",
      "üîç Input data validation:\n",
      "  Data shape: (5480, 18)\n",
      "  Columns: ['date', 'Open', 'High', 'Low', 'Close', 'Volume', 'tic', 'sma_20', 'ema_20', 'rsi', 'ema_12', 'ema_26', 'macd', 'macd_signal', 'returns', 'volatility', 'price_sma_ratio', 'timestamp']\n",
      "  Date range: 2022-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "üìä Test data prepared:\n",
      "  Shape: (823, 18)\n",
      "  Symbols: ['BTC-USD' 'ETH-USD' 'SOL-USD' 'ADA-USD' 'BNB-USD']\n",
      "  Date range: 2024-07-20 00:00:00 to 2024-12-31 00:00:00\n",
      "üîß Renamed Open -> open\n",
      "üîß Renamed High -> high\n",
      "üîß Renamed Low -> low\n",
      "üîß Renamed Close -> close\n",
      "üîß Renamed Volume -> volume\n",
      "üîç Technical indicators found: 7 indicators\n",
      "    ['sma_20', 'ema_20', 'rsi', 'ema_12', 'ema_26']...\n",
      "üéØ Environment parameters:\n",
      "  Stock dimension: 5\n",
      "  Technical indicators: 7\n",
      "üîÑ Trying saved environment config...\n",
      "‚ö†Ô∏è Error with saved config: 'numpy.float64' object has no attribute 'values'\n",
      "üîÑ Trying standard configuration...\n",
      "‚ö†Ô∏è Error with standard config: 'numpy.float64' object has no attribute 'values'\n",
      "üîÑ Trying minimal configuration...\n",
      "‚ùå All environment creation methods failed: StockTradingEnv.__init__() missing 8 required positional arguments: 'hmax', 'num_stock_shares', 'buy_cost_pct', 'sell_cost_pct', 'reward_scaling', 'state_space', 'action_space', and 'tech_indicator_list'\n",
      "\n",
      "‚ùå Setup failed with error: Cannot create test environment. Last error: StockTradingEnv.__init__() missing 8 required positional arguments: 'hmax', 'num_stock_shares', 'buy_cost_pct', 'sell_cost_pct', 'reward_scaling', 'state_space', 'action_space', and 'tech_indicator_list'\n",
      "üîß Please check your data and model files\n",
      "üìã Full error traceback:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyber\\AppData\\Local\\Temp\\ipykernel_35056\\3738550722.py\", line 204, in create_robust_test_environment\n",
      "    test_env = StockTradingEnv(\n",
      "               ^^^^^^^^^^^^^^^^\n",
      "TypeError: StockTradingEnv.__init__() missing 8 required positional arguments: 'hmax', 'num_stock_shares', 'buy_cost_pct', 'sell_cost_pct', 'reward_scaling', 'state_space', 'action_space', and 'tech_indicator_list'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyber\\AppData\\Local\\Temp\\ipykernel_35056\\3738550722.py\", line 233, in <module>\n",
      "    test_env, test_df = create_robust_test_environment(df, env_config)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\cyber\\AppData\\Local\\Temp\\ipykernel_35056\\3738550722.py\", line 214, in create_robust_test_environment\n",
      "    raise RuntimeError(f\"Cannot create test environment. Last error: {str(e)}\")\n",
      "RuntimeError: Cannot create test environment. Last error: StockTradingEnv.__init__() missing 8 required positional arguments: 'hmax', 'num_stock_shares', 'buy_cost_pct', 'sell_cost_pct', 'reward_scaling', 'state_space', 'action_space', and 'tech_indicator_list'\n"
     ]
    }
   ],
   "source": [
    "def load_evaluation_setup():\n",
    "    \"\"\"\n",
    "    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å main.py)\n",
    "    \"\"\"\n",
    "    print(\"üìÇ Loading evaluation setup...\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "    try:\n",
    "        pickle_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.pkl\")\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        print(f\"‚úÖ Loaded processed data from pickle ({len(df)} rows)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Pickle load failed: {str(e)}\")\n",
    "        try:\n",
    "            csv_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.csv\")\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            print(f\"‚úÖ Loaded processed data from CSV ({len(df)} rows)\")\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Failed to load data: {str(e2)}\")\n",
    "            raise ValueError(\"Cannot load processed data. Please run data processing first.\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î environment config\n",
    "    try:\n",
    "        env_config_file = os.path.join(AGENT_DIR, \"environment_config.pkl\")\n",
    "        with open(env_config_file, 'rb') as f:\n",
    "            env_config = pickle.load(f)\n",
    "        print(f\"‚úÖ Loaded environment config\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Environment config load failed: {str(e)}\")\n",
    "        print(\"üìù Will use default configuration\")\n",
    "        env_config = None\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î training results\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        raise ValueError(f\"Model directory not found: {MODEL_DIR}\")\n",
    "        \n",
    "    training_files = [f for f in os.listdir(MODEL_DIR) if f.startswith('training_info_') and f.endswith('.pkl')]\n",
    "    \n",
    "    if not training_files:\n",
    "        print(f\"‚ö†Ô∏è No training info files found in {MODEL_DIR}\")\n",
    "        print(\"üìù Looking for model files directly...\")\n",
    "        \n",
    "        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ model files ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á\n",
    "        model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith('.zip')]\n",
    "        if model_files:\n",
    "            print(f\"üìã Found {len(model_files)} model files: {model_files}\")\n",
    "            return df, env_config, {}\n",
    "        else:\n",
    "            raise ValueError(f\"No trained models found in {MODEL_DIR}\")\n",
    "    \n",
    "    trained_models = {}\n",
    "    for training_file in training_files:\n",
    "        try:\n",
    "            model_name = training_file.replace('training_info_', '').replace('.pkl', '')\n",
    "            \n",
    "            with open(os.path.join(MODEL_DIR, training_file), 'rb') as f:\n",
    "                training_info = pickle.load(f)\n",
    "            \n",
    "            # ‡πÇ‡∏´‡∏•‡∏î trained model\n",
    "            model_path = training_info['model_path']\n",
    "            if os.path.exists(model_path + '.zip'):\n",
    "                model_type = training_info['model_name'].split('_')[0].upper()\n",
    "                \n",
    "                if model_type == 'PPO':\n",
    "                    model = PPO.load(model_path)\n",
    "                elif model_type == 'A2C':\n",
    "                    model = A2C.load(model_path)\n",
    "                elif model_type == 'DDPG':\n",
    "                    model = DDPG.load(model_path)\n",
    "                elif model_type == 'SAC':\n",
    "                    model = SAC.load(model_path)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Unknown model type: {model_type}\")\n",
    "                    continue\n",
    "                \n",
    "                trained_models[model_name] = {\n",
    "                    'model': model,\n",
    "                    'training_info': training_info,\n",
    "                    'model_type': model_type\n",
    "                }\n",
    "                \n",
    "                print(f\"‚úÖ Loaded {model_type} model: {model_name}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Model file not found: {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading {training_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not trained_models:\n",
    "        print(\"‚ö†Ô∏è No trained models could be loaded!\")\n",
    "        return df, env_config, {}\n",
    "    \n",
    "    return df, env_config, trained_models\n",
    "\n",
    "def create_robust_test_environment(df, env_config=None):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment ‡πÅ‡∏ö‡∏ö robust (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å main.py)\n",
    "    \"\"\"\n",
    "    print(\"üèõÔ∏è Creating robust test environment...\")\n",
    "    \n",
    "    # Data validation\n",
    "    print(f\"üîç Input data validation:\")\n",
    "    print(f\"  Data shape: {df.shape}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "    \n",
    "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô main.py)\n",
    "    total_len = len(df)\n",
    "    train_size = int(total_len * 0.7)\n",
    "    val_size = int(total_len * 0.15)\n",
    "    \n",
    "    test_df = df.iloc[train_size + val_size:].copy()\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "    if 'date' not in test_df.columns:\n",
    "        test_df['date'] = test_df['timestamp'].dt.date\n",
    "    \n",
    "    # Sort ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° date ‡πÅ‡∏•‡∏∞ tic\n",
    "    test_df = test_df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"üìä Test data prepared:\")\n",
    "    print(f\"  Shape: {test_df.shape}\")\n",
    "    print(f\"  Symbols: {test_df['tic'].unique()}\")\n",
    "    print(f\"  Date range: {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "    \n",
    "    # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç column names (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô main.py)\n",
    "    price_column_mapping = {\n",
    "        'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume'\n",
    "    }\n",
    "    \n",
    "    for old_col, new_col in price_column_mapping.items():\n",
    "        if old_col in test_df.columns:\n",
    "            test_df = test_df.rename(columns={old_col: new_col})\n",
    "            print(f\"üîß Renamed {old_col} -> {new_col}\")\n",
    "    \n",
    "    # ‡∏´‡∏≤ technical indicators\n",
    "    tech_cols = [col for col in test_df.columns if col.startswith(('macd', 'rsi', 'cci', 'adx', 'sma', 'ema', 'bb'))]\n",
    "    print(f\"üîç Technical indicators found: {len(tech_cols)} indicators\")\n",
    "    print(f\"    {tech_cols[:5]}{'...' if len(tech_cols) > 5 else ''}\")\n",
    "    \n",
    "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì parameters\n",
    "    unique_symbols = test_df['tic'].unique()\n",
    "    stock_dim = len(unique_symbols)\n",
    "    \n",
    "    print(f\"üéØ Environment parameters:\")\n",
    "    print(f\"  Stock dimension: {stock_dim}\")\n",
    "    print(f\"  Technical indicators: {len(tech_cols)}\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á environment (‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô main.py)\n",
    "    test_env = None\n",
    "    creation_method = \"Unknown\"\n",
    "    \n",
    "    # Method 1: ‡πÉ‡∏ä‡πâ saved config\n",
    "    if env_config and 'env_kwargs' in env_config:\n",
    "        try:\n",
    "            print(\"üîÑ Trying saved environment config...\")\n",
    "            env_kwargs = env_config['env_kwargs'].copy()\n",
    "            # ‡∏•‡∏ö df ‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô conflict\n",
    "            if 'df' in env_kwargs:\n",
    "                del env_kwargs['df']\n",
    "            \n",
    "            test_env = StockTradingEnv(df=test_df, **env_kwargs)\n",
    "            creation_method = \"saved config\"\n",
    "            print(f\"‚úÖ Test environment created with saved config\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error with saved config: {str(e)}\")\n",
    "            test_env = None\n",
    "    \n",
    "    # Method 2: ‡πÉ‡∏ä‡πâ standard config (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô main.py)\n",
    "    if test_env is None:\n",
    "        try:\n",
    "            print(\"üîÑ Trying standard configuration...\")\n",
    "            \n",
    "            # ‡∏™‡∏£‡πâ‡∏≤‡∏á environment arguments (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô main.py)\n",
    "            env_kwargs = {\n",
    "                \"stock_dim\": stock_dim,\n",
    "                \"hmax\": HMAX if 'HMAX' in globals() else 100,\n",
    "                \"initial_amount\": INITIAL_AMOUNT if 'INITIAL_AMOUNT' in globals() else 100000,\n",
    "                \"num_stock_shares\": [0] * stock_dim,\n",
    "                \"buy_cost_pct\": [0.001] * stock_dim,\n",
    "                \"sell_cost_pct\": [0.001] * stock_dim,\n",
    "                \"reward_scaling\": 1e-3,\n",
    "                \"state_space\": 1 + 2 * stock_dim + stock_dim * len(tech_cols[:5]),  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î indicators\n",
    "                \"action_space\": stock_dim,\n",
    "                \"tech_indicator_list\": tech_cols[:5] if len(tech_cols) > 5 else tech_cols,\n",
    "                \"print_verbosity\": 0\n",
    "            }\n",
    "            \n",
    "            test_env = StockTradingEnv(df=test_df, **env_kwargs)\n",
    "            creation_method = \"standard config\"\n",
    "            print(f\"‚úÖ Test environment created with standard config\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error with standard config: {str(e)}\")\n",
    "            test_env = None\n",
    "    \n",
    "    # Method 3: ‡πÉ‡∏ä‡πâ minimal config\n",
    "    if test_env is None:\n",
    "        try:\n",
    "            print(\"üîÑ Trying minimal configuration...\")\n",
    "            test_env = StockTradingEnv(\n",
    "                df=test_df,\n",
    "                stock_dim=stock_dim,\n",
    "                initial_amount=100000,\n",
    "                print_verbosity=0\n",
    "            )\n",
    "            creation_method = \"minimal config\"\n",
    "            print(f\"‚úÖ Test environment created with minimal config\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå All environment creation methods failed: {str(e)}\")\n",
    "            raise RuntimeError(f\"Cannot create test environment. Last error: {str(e)}\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á environment\n",
    "    print(f\"\\nüéØ Environment Creation Summary:\")\n",
    "    print(f\"  Method used: {creation_method}\")\n",
    "    print(f\"  Test data shape: {test_df.shape}\")\n",
    "    print(f\"  Symbols: {test_df['tic'].unique()}\")\n",
    "    print(f\"  Environment ready: ‚úÖ\")\n",
    "    \n",
    "    return test_env, test_df\n",
    "\n",
    "# Main setup execution\n",
    "try:\n",
    "    print(\"\\nüöÄ Starting comprehensive evaluation setup...\")\n",
    "    \n",
    "    # Step 1: Load data and models\n",
    "    df, env_config, trained_models = load_evaluation_setup()\n",
    "    \n",
    "    # Step 2: Create test environment\n",
    "    test_env, test_df = create_robust_test_environment(df, env_config)\n",
    "    \n",
    "    # Step 3: Verify setup\n",
    "    print(f\"\\nüìä Setup Verification:\")\n",
    "    print(f\"  ‚úÖ Data loaded: {df.shape}\")\n",
    "    print(f\"  ‚úÖ Models available: {list(trained_models.keys()) if trained_models else 'None'}\")\n",
    "    print(f\"  ‚úÖ Test data prepared: {test_df.shape}\")\n",
    "    print(f\"  ‚úÖ Test environment created\")\n",
    "    print(f\"  ‚úÖ Symbols in test set: {test_df['tic'].unique()}\")\n",
    "    \n",
    "    SETUP_SUCCESS = True\n",
    "    print(f\"\\nüéâ Evaluation setup completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Setup failed with error: {str(e)}\")\n",
    "    print(\"üîß Please check your data and model files\")\n",
    "    import traceback\n",
    "    print(\"üìã Full error traceback:\")\n",
    "    traceback.print_exc()\n",
    "    SETUP_SUCCESS = False\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Cell 3: Model Evaluation Functions (‡∏ô‡∏≥‡∏°‡∏≤‡∏à‡∏≤‡∏Å main.py + analyze_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent_performance(trained_model, test_env, model_name=\"Agent\"):\n",
    "    \"\"\"\n",
    "    ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á agent (‡∏ô‡∏≥‡∏°‡∏≤‡∏à‡∏≤‡∏Å main.py test_agent)\n",
    "    \"\"\"\n",
    "    print(f\"üìä Testing {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # ‡∏£‡∏±‡∏ô backtest\n",
    "        df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "            model=trained_model,\n",
    "            environment=test_env\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} backtesting completed\")\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì basic metrics\n",
    "        initial_value = 100000  # default initial amount\n",
    "        final_value = df_account_value['account_value'].iloc[-1]\n",
    "        total_return = (final_value - initial_value) / initial_value * 100\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì additional metrics\n",
    "        returns = df_account_value['account_value'].pct_change().dropna()\n",
    "        \n",
    "        # Sharpe ratio (annualized)\n",
    "        sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "        \n",
    "        # Maximum Drawdown\n",
    "        running_max = df_account_value['account_value'].expanding().max()\n",
    "        drawdown = (df_account_value['account_value'] - running_max) / running_max\n",
    "        max_drawdown = drawdown.min() * 100\n",
    "        \n",
    "        # Volatility (annualized)\n",
    "        volatility = returns.std() * np.sqrt(252) * 100\n",
    "        \n",
    "        # Trading frequency\n",
    "        total_trades = len(df_actions[df_actions != 0]) if len(df_actions) > 0 else 0\n",
    "        \n",
    "        results = {\n",
    "            'model_name': model_name,\n",
    "            'initial_value': initial_value,\n",
    "            'final_value': final_value,\n",
    "            'total_return': total_return,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'volatility': volatility,\n",
    "            'total_trades': total_trades,\n",
    "            'account_values': df_account_value,\n",
    "            'actions': df_actions,\n",
    "            'daily_returns': returns\n",
    "        }\n",
    "        \n",
    "        print(f\"üìà {model_name} Results:\")\n",
    "        print(f\"  Total Return: {total_return:.2f}%\")\n",
    "        print(f\"  Sharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "        print(f\"  Max Drawdown: {max_drawdown:.2f}%\")\n",
    "        print(f\"  Volatility: {volatility:.2f}%\")\n",
    "        print(f\"  Total Trades: {total_trades}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def calculate_baseline_performance(test_df, symbols=None):\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Buy & Hold baseline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö (‡∏ô‡∏≥‡∏°‡∏≤‡∏à‡∏≤‡∏Å main.py analyze_results)\n",
    "    \"\"\"\n",
    "    print(\"üìà Calculating Buy & Hold baselines...\")\n",
    "    \n",
    "    if symbols is None:\n",
    "        symbols = test_df['tic'].unique()\n",
    "    \n",
    "    baseline_results = {}\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            symbol_data = test_df[test_df['tic'] == symbol].copy()\n",
    "            \n",
    "            if len(symbol_data) == 0:\n",
    "                print(f\"‚ö†Ô∏è No data found for {symbol}\")\n",
    "                continue\n",
    "            \n",
    "            # ‡πÉ‡∏ä‡πâ close price (normalized)\n",
    "            initial_price = symbol_data['close'].iloc[0]\n",
    "            final_price = symbol_data['close'].iloc[-1]\n",
    "            \n",
    "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì return\n",
    "            if abs(initial_price) > 1e-10:  # avoid division by zero\n",
    "                price_change = (final_price - initial_price) / abs(initial_price)\n",
    "                portfolio_value = 100000 * (1 + price_change)\n",
    "                total_return = price_change * 100\n",
    "                \n",
    "                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics ‡∏≠‡∏∑‡πà‡∏ô‡πÜ\n",
    "                returns = symbol_data['close'].pct_change().dropna()\n",
    "                \n",
    "                if len(returns) > 0 and returns.std() > 0:\n",
    "                    sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252)\n",
    "                    volatility = returns.std() * np.sqrt(252) * 100\n",
    "                    \n",
    "                    # Maximum Drawdown\n",
    "                    cumulative_returns = (1 + returns).cumprod()\n",
    "                    running_max = cumulative_returns.expanding().max()\n",
    "                    drawdown = (cumulative_returns - running_max) / running_max\n",
    "                    max_drawdown = drawdown.min() * 100\n",
    "                else:\n",
    "                    sharpe_ratio = 0\n",
    "                    volatility = 0\n",
    "                    max_drawdown = 0\n",
    "                \n",
    "                baseline_results[symbol] = {\n",
    "                    'total_return': total_return,\n",
    "                    'final_value': portfolio_value,\n",
    "                    'sharpe_ratio': sharpe_ratio,\n",
    "                    'max_drawdown': max_drawdown,\n",
    "                    'volatility': volatility,\n",
    "                    'total_trades': 1  # Buy and hold = 1 trade\n",
    "                }\n",
    "                \n",
    "                print(f\"  {symbol}: {total_return:.2f}% return\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Invalid price data for {symbol}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error calculating baseline for {symbol}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"‚úÖ Calculated baselines for {len(baseline_results)} symbols\")\n",
    "    return baseline_results\n",
    "\n",
    "def create_performance_comparison_table(agent_results, baseline_results):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å notebook ‡πÄ‡∏î‡∏¥‡∏°)\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating performance comparison table...\")\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Agent results\n",
    "    if agent_results:\n",
    "        for result in agent_results if isinstance(agent_results, list) else [agent_results]:\n",
    "            if result:\n",
    "                comparison_data.append({\n",
    "                    'Strategy': f\"RL-Agent ({result['model_name']})\",\n",
    "                    'Total Return (%)': result['total_return'],\n",
    "                    'Final Value ($)': result['final_value'],\n",
    "                    'Sharpe Ratio': result['sharpe_ratio'],\n",
    "                    'Max Drawdown (%)': result['max_drawdown'],\n",
    "                    'Volatility (%)': result['volatility'],\n",
    "                    'Total Trades': result['total_trades']\n",
    "                })\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Baseline strategies\n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        comparison_data.append({\n",
    "            'Strategy': f\"Buy&Hold-{symbol}\",\n",
    "            'Total Return (%)': baseline['total_return'],\n",
    "            'Final Value ($)': baseline['final_value'],\n",
    "            'Sharpe Ratio': baseline['sharpe_ratio'],\n",
    "            'Max Drawdown (%)': baseline['max_drawdown'],\n",
    "            'Volatility (%)': baseline['volatility'],\n",
    "            'Total Trades': baseline['total_trades']\n",
    "        })\n",
    "    \n",
    "    if comparison_data:\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_df = comparison_df.sort_values('Total Return (%)', ascending=False)\n",
    "        return comparison_df\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No performance data available for comparison\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def plot_comprehensive_results(agent_results, baseline_results, test_df):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏à‡∏≤‡∏Å main.py plot_results)\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating comprehensive performance plots...\")\n",
    "    \n",
    "    # Setup figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: Portfolio Value Evolution\n",
    "    ax1 = axes[0, 0]\n",
    "    \n",
    "    # Plot agent portfolio\n",
    "    if agent_results:\n",
    "        agent_data = agent_results if not isinstance(agent_results, list) else agent_results[0]\n",
    "        if agent_data and 'account_values' in agent_data:\n",
    "            portfolio_values = agent_data['account_values']['account_value'].values\n",
    "            dates = pd.to_datetime(test_df['timestamp'].unique()[:len(portfolio_values)])\n",
    "            ax1.plot(dates, portfolio_values, label=f\"RL Agent ({agent_data['model_name']})\", \n",
    "                    linewidth=2, color='blue')\n",
    "    \n",
    "    # Plot baseline\n",
    "    initial_amount = 100000\n",
    "    ax1.axhline(y=initial_amount, color='red', linestyle='--', alpha=0.7, label='Initial Value')\n",
    "    \n",
    "    # Plot buy & hold for main symbol (BTC if available)\n",
    "    main_symbol = 'BTC-USD' if 'BTC-USD' in test_df['tic'].unique() else test_df['tic'].unique()[0]\n",
    "    if main_symbol in baseline_results:\n",
    "        btc_data = test_df[test_df['tic'] == main_symbol].copy()\n",
    "        if len(btc_data) > 0:\n",
    "            btc_prices = btc_data.groupby('timestamp')['close'].first()\n",
    "            btc_normalized = (btc_prices / btc_prices.iloc[0]) * initial_amount\n",
    "            ax1.plot(btc_normalized.index, btc_normalized.values, \n",
    "                    label=f'Buy&Hold-{main_symbol}', linewidth=2, color='orange', alpha=0.8)\n",
    "    \n",
    "    ax1.set_title('Portfolio Value Evolution', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Portfolio Value ($)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Returns Comparison\n",
    "    ax2 = axes[0, 1]\n",
    "    \n",
    "    strategies = []\n",
    "    returns = []\n",
    "    colors = []\n",
    "    \n",
    "    # Agent returns\n",
    "    if agent_results:\n",
    "        agent_data = agent_results if not isinstance(agent_results, list) else agent_results[0]\n",
    "        if agent_data:\n",
    "            strategies.append(f\"RL-Agent\")\n",
    "            returns.append(agent_data['total_return'])\n",
    "            colors.append('skyblue')\n",
    "    \n",
    "    # Baseline returns\n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        strategies.append(f\"B&H-{symbol}\")\n",
    "        returns.append(baseline['total_return'])\n",
    "        colors.append('lightcoral')\n",
    "    \n",
    "    if strategies:\n",
    "        bars = ax2.bar(range(len(strategies)), returns, color=colors, alpha=0.7)\n",
    "        ax2.set_title('Total Returns Comparison', fontsize=14, fontweight='bold')\n",
    "        ax2.set_ylabel('Return (%)')\n",
    "        ax2.set_xticks(range(len(strategies)))\n",
    "        ax2.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "        ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, returns):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + (1 if height > 0 else -2),\n",
    "                    f'{value:.1f}%', ha='center', va='bottom' if height > 0 else 'top', fontsize=10)\n",
    "    \n",
    "    # Plot 3: Risk Metrics\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    sharpe_ratios = []\n",
    "    max_drawdowns = []\n",
    "    \n",
    "    if agent_results:\n",
    "        agent_data = agent_results if not isinstance(agent_results, list) else agent_results[0]\n",
    "        if agent_data:\n",
    "            sharpe_ratios.append(agent_data['sharpe_ratio'])\n",
    "            max_drawdowns.append(agent_data['max_drawdown'])\n",
    "    \n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        sharpe_ratios.append(baseline['sharpe_ratio'])\n",
    "        max_drawdowns.append(baseline['max_drawdown'])\n",
    "    \n",
    "    if strategies:\n",
    "        ax3_twin = ax3.twinx()\n",
    "        \n",
    "        x_pos = range(len(strategies))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax3.bar([x - width/2 for x in x_pos], sharpe_ratios, width, \n",
    "                       label='Sharpe Ratio', color='lightgreen', alpha=0.7)\n",
    "        bars2 = ax3_twin.bar([x + width/2 for x in x_pos], max_drawdowns, width,\n",
    "                           label='Max Drawdown (%)', color='lightpink', alpha=0.7)\n",
    "        \n",
    "        ax3.set_title('Risk Metrics Comparison', fontsize=14, fontweight='bold')\n",
    "        ax3.set_ylabel('Sharpe Ratio', color='green')\n",
    "        ax3_twin.set_ylabel('Max Drawdown (%)', color='red')\n",
    "        ax3.set_xticks(x_pos)\n",
    "        ax3.set_xticklabels(strategies, rotation=45, ha='right')\n",
    "        \n",
    "        # Legends\n",
    "        ax3.legend(loc='upper left')\n",
    "        ax3_twin.legend(loc='upper right')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Summary Statistics\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Create summary text\n",
    "    summary_text = \"üìä PERFORMANCE SUMMARY\\\\n\" + \"=\"*40 + \"\\\\n\"\n",
    "    \n",
    "    if agent_results:\n",
    "        agent_data = agent_results if not isinstance(agent_results, list) else agent_results[0]\n",
    "        if agent_data:\n",
    "            summary_text += f\"ü§ñ RL Agent ({agent_data['model_name']}):\\\\n\"\n",
    "            summary_text += f\"  ‚Ä¢ Total Return: {agent_data['total_return']:.2f}%\\\\n\"\n",
    "            summary_text += f\"  ‚Ä¢ Sharpe Ratio: {agent_data['sharpe_ratio']:.3f}\\\\n\"\n",
    "            summary_text += f\"  ‚Ä¢ Max Drawdown: {agent_data['max_drawdown']:.2f}%\\\\n\"\n",
    "            summary_text += f\"  ‚Ä¢ Final Value: ${agent_data['final_value']:,.2f}\\\\n\"\n",
    "            summary_text += f\"  ‚Ä¢ Total Trades: {agent_data['total_trades']}\\\\n\\\\n\"\n",
    "    \n",
    "    # Best baseline\n",
    "    if baseline_results:\n",
    "        best_baseline = max(baseline_results.items(), key=lambda x: x[1]['total_return'])\n",
    "        summary_text += f\"üìà Best Baseline ({best_baseline[0]}):\\\\n\"\n",
    "        summary_text += f\"  ‚Ä¢ Total Return: {best_baseline[1]['total_return']:.2f}%\\\\n\"\n",
    "        summary_text += f\"  ‚Ä¢ Sharpe Ratio: {best_baseline[1]['sharpe_ratio']:.3f}\\\\n\"\n",
    "        summary_text += f\"  ‚Ä¢ Max Drawdown: {best_baseline[1]['max_drawdown']:.2f}%\\\\n\\\\n\"\n",
    "        \n",
    "        if agent_results:\n",
    "            agent_data = agent_results if not isinstance(agent_results, list) else agent_results[0]\n",
    "            if agent_data:\n",
    "                alpha = agent_data['total_return'] - best_baseline[1]['total_return']\n",
    "                summary_text += f\"üéØ Alpha (Agent - Best Baseline):\\\\n\"\n",
    "                summary_text += f\"  ‚Ä¢ {alpha:.2f}%\\\\n\"\n",
    "                if alpha > 0:\n",
    "                    summary_text += f\"  ‚Ä¢ ‚úÖ Agent outperformed!\\\\n\"\n",
    "                else:\n",
    "                    summary_text += f\"  ‚Ä¢ ‚ö†Ô∏è Agent underperformed\\\\n\"\n",
    "    \n",
    "    ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes, fontsize=11,\n",
    "             verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Initialize evaluation results storage\n",
    "evaluation_results = []\n",
    "baseline_results = {}\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Cell 4: Run Evaluation (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô main.py ‡πÅ‡∏ï‡πà‡πÉ‡∏ô notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Cannot run evaluation: Setup failed\n",
      "üîß Please run the setup cells first and fix any errors\n"
     ]
    }
   ],
   "source": [
    "# Main evaluation execution (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô main() function ‡πÉ‡∏ô main.py)\n",
    "if SETUP_SUCCESS:\n",
    "    print(\"üöÄ Starting model evaluation process...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Calculate baseline performance\n",
    "        symbols = test_df['tic'].unique()\n",
    "        baseline_results = calculate_baseline_performance(test_df, symbols)\n",
    "        \n",
    "        # Step 2: Evaluate trained models (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)\n",
    "        if trained_models:\n",
    "            print(f\"\\nü§ñ Evaluating {len(trained_models)} trained models...\")\n",
    "            \n",
    "            for model_name, model_info in trained_models.items():\n",
    "                print(f\"\\nüìä Evaluating {model_name}...\")\n",
    "                try:\n",
    "                    result = evaluate_agent_performance(\n",
    "                        model_info['model'], \n",
    "                        test_env, \n",
    "                        model_name=f\"{model_info['model_type']}-{model_name}\"\n",
    "                    )\n",
    "                    if result:\n",
    "                        evaluation_results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error evaluating {model_name}: {str(e)}\")\n",
    "                    continue\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No trained models found. Will only show baseline results.\")\n",
    "        \n",
    "        # Step 3: Create comparison table\n",
    "        print(f\"\\nüìä Creating performance comparison...\")\n",
    "        comparison_df = create_performance_comparison_table(evaluation_results, baseline_results)\n",
    "        \n",
    "        if not comparison_df.empty:\n",
    "            print(\"\\nüìä PERFORMANCE COMPARISON TABLE:\")\n",
    "            print(\"=\"*80)\n",
    "            print(comparison_df.to_string(index=False))\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        # Step 4: Create comprehensive plots\n",
    "        if evaluation_results or baseline_results:\n",
    "            print(f\"\\nüìà Creating performance plots...\")\n",
    "            agent_result = evaluation_results[0] if evaluation_results else None\n",
    "            fig = plot_comprehensive_results(agent_result, baseline_results, test_df)\n",
    "            plt.show()\n",
    "            \n",
    "            # Save results\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            \n",
    "            # Save comparison table\n",
    "            if not comparison_df.empty:\n",
    "                comparison_file = os.path.join(REPORTS_DIR, f'performance_comparison_{timestamp}.csv')\n",
    "                comparison_df.to_csv(comparison_file, index=False)\n",
    "                print(f\"üíæ Saved comparison table: {comparison_file}\")\n",
    "            \n",
    "            # Save plots\n",
    "            plot_file = os.path.join(REPORTS_DIR, f'performance_analysis_{timestamp}.png')\n",
    "            fig.savefig(plot_file, dpi=300, bbox_inches='tight')\n",
    "            print(f\"üíæ Saved performance plots: {plot_file}\")\n",
    "        \n",
    "        # Step 5: Summary results (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô main.py)\n",
    "        print(f\"\\nüéâ EVALUATION COMPLETED SUCCESSFULLY!\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if evaluation_results:\n",
    "            best_agent = max(evaluation_results, key=lambda x: x['total_return'])\n",
    "            print(f\"üèÜ Best Agent Performance:\")\n",
    "            print(f\"  ‚Ä¢ Model: {best_agent['model_name']}\")\n",
    "            print(f\"  ‚Ä¢ Total Return: {best_agent['total_return']:.2f}%\")\n",
    "            print(f\"  ‚Ä¢ Sharpe Ratio: {best_agent['sharpe_ratio']:.3f}\")\n",
    "            print(f\"  ‚Ä¢ Final Value: ${best_agent['final_value']:,.2f}\")\n",
    "        \n",
    "        if baseline_results:\n",
    "            best_baseline = max(baseline_results.items(), key=lambda x: x[1]['total_return'])\n",
    "            print(f\"\\nüìà Best Baseline Performance:\")\n",
    "            print(f\"  ‚Ä¢ Strategy: Buy&Hold-{best_baseline[0]}\")\n",
    "            print(f\"  ‚Ä¢ Total Return: {best_baseline[1]['total_return']:.2f}%\")\n",
    "            print(f\"  ‚Ä¢ Sharpe Ratio: {best_baseline[1]['sharpe_ratio']:.3f}\")\n",
    "            print(f\"  ‚Ä¢ Final Value: ${best_baseline[1]['final_value']:,.2f}\")\n",
    "        \n",
    "        # Calculate alpha (agent vs best baseline)\n",
    "        if evaluation_results and baseline_results:\n",
    "            best_agent = max(evaluation_results, key=lambda x: x['total_return'])\n",
    "            best_baseline = max(baseline_results.items(), key=lambda x: x[1]['total_return'])\n",
    "            alpha = best_agent['total_return'] - best_baseline[1]['total_return']\n",
    "            \n",
    "            print(f\"\\nüéØ ALPHA ANALYSIS:\")\n",
    "            print(f\"  ‚Ä¢ Alpha (Agent - Best Baseline): {alpha:.2f}%\")\n",
    "            \n",
    "            if alpha > 0:\n",
    "                print(f\"  ‚Ä¢ ‚úÖ Agent outperformed by {alpha:.2f}%!\")\n",
    "                print(f\"  ‚Ä¢ üéä Great job! Your RL agent beat buy & hold!\")\n",
    "            else:\n",
    "                print(f\"  ‚Ä¢ ‚ö†Ô∏è Agent underperformed by {abs(alpha):.2f}%\")\n",
    "                print(f\"  ‚Ä¢ üí° Consider tuning hyperparameters or training longer\")\n",
    "        \n",
    "        print(f\"\\nüìÅ Reports saved to: {REPORTS_DIR}/\")\n",
    "        print(f\"‚úÖ Evaluation process completed successfully!\")\n",
    "        \n",
    "        EVALUATION_SUCCESS = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Evaluation failed: {str(e)}\")\n",
    "        import traceback\n",
    "        print(\"üìã Error traceback:\")\n",
    "        traceback.print_exc()\n",
    "        EVALUATION_SUCCESS = False\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot run evaluation: Setup failed\")\n",
    "    print(\"üîß Please run the setup cells first and fix any errors\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ‡∏™‡∏£‡∏∏‡∏õ: Notebook ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡πâ‡∏ß\n",
    "\n",
    "### üéØ **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏î‡∏¥‡∏°:**\n",
    "\n",
    "1. **Structure ‡∏à‡∏≤‡∏Å main.py**: ‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞ functions ‡∏ó‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≤‡∏Å `main.py`\n",
    "2. **Robust Error Handling**: ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ error ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô\n",
    "3. **GPU/CPU Detection**: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ GPU ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "4. **Multiple Environment Creation Methods**: ‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏£‡πâ‡∏≤‡∏á environment ‡πÄ‡∏õ‡πá‡∏ô fallback\n",
    "5. **Comprehensive Analysis**: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô `main.py`\n",
    "6. **Auto Save Results**: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥\n",
    "\n",
    "### üöÄ **‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô:**\n",
    "1. ‡∏£‡∏±‡∏ô Cell 1: Setup ‡πÅ‡∏•‡∏∞ Configuration  \n",
    "2. ‡∏£‡∏±‡∏ô Cell 2: Data Loading ‡πÅ‡∏•‡∏∞ Environment Setup\n",
    "3. ‡∏£‡∏±‡∏ô Cell 3: ‡πÇ‡∏´‡∏•‡∏î Evaluation Functions\n",
    "4. ‡∏£‡∏±‡∏ô Cell 4: Run Evaluation (main execution)\n",
    "\n",
    "### üìä **‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:**\n",
    "- Performance comparison table\n",
    "- Comprehensive charts\n",
    "- Alpha analysis (Agent vs Buy & Hold)\n",
    "- Automatic report generation\n",
    "- Error handling ‡πÅ‡∏•‡∏∞ fallback options\n",
    "\n",
    "**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏**: Notebook ‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å `main.py` ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Agent (Agent Evaluation & Improvement)\n",
    "## ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á RL Agent ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Crypto Trading\n",
    "\n",
    "### ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:\n",
    "- ‡πÇ‡∏´‡∏•‡∏î Trained Model\n",
    "- ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ö‡∏ô Test Data\n",
    "- ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Baseline (Buy & Hold)\n",
    "- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Trading Patterns\n",
    "- ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Model ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Live Trading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Import Libraries ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Setup directories completed\n",
      "üìä Starting Agent Evaluation Process\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from stable_baselines3 import PPO, A2C, DDPG, SAC\n",
    "\n",
    "# FinRL imports\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "\n",
    "# Import config\n",
    "from config import *\n",
    "\n",
    "# Setup directories\n",
    "PROCESSED_DIR = \"processed_data\"\n",
    "MODEL_DIR = \"models\"\n",
    "AGENT_DIR = \"agents\"\n",
    "EVALUATION_DIR = \"evaluation\"\n",
    "REPORTS_DIR = \"reports\"\n",
    "\n",
    "for dir_name in [EVALUATION_DIR, REPORTS_DIR]:\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "print(\"üìÅ Setup directories completed\")\n",
    "print(f\"üìä Starting Agent Evaluation Process\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading evaluation setup...\n",
      "‚úÖ Loaded processed data\n",
      "‚úÖ Loaded environment config\n",
      "‚úÖ Loaded PPO model: ppo\n",
      "üèõÔ∏è Creating test environment...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_35056\\896614671.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m test_env, test_df\n\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ models\u001b[39;00m\n\u001b[32m    102\u001b[39m df, env_config, trained_models = load_evaluation_setup()\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m test_env, test_df = recreate_test_environment(df, env_config)\n\u001b[32m    104\u001b[39m \n\u001b[32m    105\u001b[39m print(f\"\\nüìä Evaluation setup completed:\")\n\u001b[32m    106\u001b[39m print(f\"  Available models: {list(trained_models.keys())}\")\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_35056\\896614671.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df, env_config)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# ‡∏•‡∏ö df ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å env_kwargs ‡∏´‡∏≤‡∏Å‡∏°‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô duplicate parameter\u001b[39;00m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'df'\u001b[39m \u001b[38;5;28;01min\u001b[39;00m env_kwargs:\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mdel\u001b[39;00m env_kwargs[\u001b[33m'df'\u001b[39m]\n\u001b[32m     92\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     test_env = StockTradingEnv(df=test_df, **env_kwargs)\n\u001b[32m     94\u001b[39m \n\u001b[32m     95\u001b[39m     print(f\"‚úÖ Test environment created\")\n\u001b[32m     96\u001b[39m     print(f\"üìä Test data: {len(test_df)} rows\")\n",
      "\u001b[32md:\\finrl_minimal_crypto\\.venv\\Lib\\site-packages\\finrl\\meta\\env_stock_trading\\env_stocktrading.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, df, stock_dim, hmax, initial_amount, num_stock_shares, buy_cost_pct, sell_cost_pct, reward_scaling, state_space, action_space, tech_indicator_list, turbulence_threshold, risk_indicator_col, make_plots, print_verbosity, day, initial, previous_state, model_name, mode, iteration)\u001b[39m\n\u001b[32m     72\u001b[39m         self.model_name = model_name\n\u001b[32m     73\u001b[39m         self.mode = mode\n\u001b[32m     74\u001b[39m         self.iteration = iteration\n\u001b[32m     75\u001b[39m         \u001b[38;5;66;03m# initalize state\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         self.state = self._initiate_state()\n\u001b[32m     77\u001b[39m \n\u001b[32m     78\u001b[39m         \u001b[38;5;66;03m# initialize reward\u001b[39;00m\n\u001b[32m     79\u001b[39m         self.reward = \u001b[32m0\u001b[39m\n",
      "\u001b[32md:\\finrl_minimal_crypto\\.venv\\Lib\\site-packages\\finrl\\meta\\env_stock_trading\\env_stocktrading.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m len(self.df.tic.unique()) > \u001b[32m1\u001b[39m:\n\u001b[32m    406\u001b[39m                 \u001b[38;5;66;03m# for multiple stock\u001b[39;00m\n\u001b[32m    407\u001b[39m                 state = (\n\u001b[32m    408\u001b[39m                     [self.initial_amount]\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m                     + self.data.close.values.tolist()\n\u001b[32m    410\u001b[39m                     + self.num_stock_shares\n\u001b[32m    411\u001b[39m                     + sum(\n\u001b[32m    412\u001b[39m                         (\n",
      "\u001b[32md:\\finrl_minimal_crypto\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6295\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6296\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6297\u001b[39m         ):\n\u001b[32m   6298\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6299\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Series' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "def load_evaluation_setup():\n",
    "    \"\"\"\n",
    "    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "    \"\"\"\n",
    "    print(\"üìÇ Loading evaluation setup...\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "    try:\n",
    "        pickle_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.pkl\")\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        print(f\"‚úÖ Loaded processed data\")\n",
    "    except:\n",
    "        csv_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.csv\")\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        print(f\"‚úÖ Loaded processed data from CSV\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î environment config\n",
    "    env_config_file = os.path.join(AGENT_DIR, \"environment_config.pkl\")\n",
    "    with open(env_config_file, 'rb') as f:\n",
    "        env_config = pickle.load(f)\n",
    "    print(f\"‚úÖ Loaded environment config\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î training results\n",
    "    training_files = [f for f in os.listdir(MODEL_DIR) if f.startswith('training_info_') and f.endswith('.pkl')]\n",
    "    \n",
    "    trained_models = {}\n",
    "    for training_file in training_files:\n",
    "        model_name = training_file.replace('training_info_', '').replace('.pkl', '')\n",
    "        \n",
    "        with open(os.path.join(MODEL_DIR, training_file), 'rb') as f:\n",
    "            training_info = pickle.load(f)\n",
    "        \n",
    "        # ‡πÇ‡∏´‡∏•‡∏î trained model\n",
    "        model_path = training_info['model_path']\n",
    "        if os.path.exists(model_path + '.zip'):\n",
    "            model_type = training_info['model_name'].split('_')[0].upper()\n",
    "            \n",
    "            if model_type == 'PPO':\n",
    "                model = PPO.load(model_path)\n",
    "            elif model_type == 'A2C':\n",
    "                model = A2C.load(model_path)\n",
    "            elif model_type == 'DDPG':\n",
    "                model = DDPG.load(model_path)\n",
    "            elif model_type == 'SAC':\n",
    "                model = SAC.load(model_path)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Unknown model type: {model_type}\")\n",
    "                continue\n",
    "            \n",
    "            trained_models[model_name] = {\n",
    "                'model': model,\n",
    "                'training_info': training_info,\n",
    "                'model_type': model_type\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Loaded {model_type} model: {model_name}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Model file not found: {model_path}\")\n",
    "    \n",
    "    if not trained_models:\n",
    "        raise ValueError(\"No trained models found!\")\n",
    "    \n",
    "    return df, env_config, trained_models\n",
    "\n",
    "def recreate_test_environment(df, env_config):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "    \"\"\"\n",
    "    print(\"üèõÔ∏è Creating test environment...\")\n",
    "    \n",
    "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°\n",
    "    total_len = len(df)\n",
    "    train_size = int(total_len * 0.7)\n",
    "    val_size = int(total_len * 0.15)\n",
    "    \n",
    "    test_df = df.iloc[train_size + val_size:].reset_index(drop=True)\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "    test_df['date'] = test_df['timestamp'].dt.date\n",
    "    test_df.sort_values(['date', 'tic'], inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ duplicate df parameter\n",
    "    env_kwargs = env_config['env_kwargs'].copy()\n",
    "    \n",
    "    # ‡∏•‡∏ö df ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å env_kwargs ‡∏´‡∏≤‡∏Å‡∏°‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô duplicate parameter\n",
    "    if 'df' in env_kwargs:\n",
    "        del env_kwargs['df']\n",
    "    \n",
    "    test_env = StockTradingEnv(df=test_df, **env_kwargs)\n",
    "    \n",
    "    print(f\"‚úÖ Test environment created\")\n",
    "    print(f\"üìä Test data: {len(test_df)} rows\")\n",
    "    print(f\"üìÖ Date range: {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "    \n",
    "    return test_env, test_df\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ models\n",
    "df, env_config, trained_models = load_evaluation_setup()\n",
    "test_env, test_df = recreate_test_environment(df, env_config)\n",
    "\n",
    "print(f\"\\nüìä Evaluation setup completed:\")\n",
    "print(f\"  Available models: {list(trained_models.keys())}\")\n",
    "print(f\"  Test data points: {len(test_df)}\")\n",
    "print(f\"  Symbols: {test_df['tic'].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á working environment\n",
    "def load_evaluation_setup():\n",
    "    \"\"\"\n",
    "    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "    \"\"\"\n",
    "    print(\"üìÇ Loading evaluation setup...\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "    try:\n",
    "        pickle_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.pkl\")\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        print(f\"‚úÖ Loaded processed data\")\n",
    "    except:\n",
    "        csv_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.csv\")\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        print(f\"‚úÖ Loaded processed data from CSV\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î environment config\n",
    "    env_config_file = os.path.join(AGENT_DIR, \"environment_config.pkl\")\n",
    "    with open(env_config_file, 'rb') as f:\n",
    "        env_config = pickle.load(f)\n",
    "    print(f\"‚úÖ Loaded environment config\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î training results\n",
    "    training_files = [f for f in os.listdir(MODEL_DIR) if f.startswith('training_info_') and f.endswith('.pkl')]\n",
    "    \n",
    "    trained_models = {}\n",
    "    for training_file in training_files:\n",
    "        model_name = training_file.replace('training_info_', '').replace('.pkl', '')\n",
    "        \n",
    "        with open(os.path.join(MODEL_DIR, training_file), 'rb') as f:\n",
    "            training_info = pickle.load(f)\n",
    "        \n",
    "        # ‡πÇ‡∏´‡∏•‡∏î trained model\n",
    "        model_path = training_info['model_path']\n",
    "        if os.path.exists(model_path + '.zip'):\n",
    "            model_type = training_info['model_name'].split('_')[0].upper()\n",
    "            \n",
    "            if model_type == 'PPO':\n",
    "                model = PPO.load(model_path)\n",
    "            elif model_type == 'A2C':\n",
    "                model = A2C.load(model_path)\n",
    "            elif model_type == 'DDPG':\n",
    "                model = DDPG.load(model_path)\n",
    "            elif model_type == 'SAC':\n",
    "                model = SAC.load(model_path)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Unknown model type: {model_type}\")\n",
    "                continue\n",
    "            \n",
    "            trained_models[model_name] = {\n",
    "                'model': model,\n",
    "                'training_info': training_info,\n",
    "                'model_type': model_type\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Loaded {model_type} model: {model_name}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Model file not found: {model_path}\")\n",
    "    \n",
    "    if not trained_models:\n",
    "        raise ValueError(\"No trained models found!\")\n",
    "    \n",
    "    return df, env_config, trained_models\n",
    "\n",
    "def create_safe_test_environment(df):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢\n",
    "    \"\"\"\n",
    "    print(\"üèõÔ∏è Creating safe test environment...\")\n",
    "    \n",
    "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    total_len = len(df)\n",
    "    train_size = int(total_len * 0.7)\n",
    "    val_size = int(total_len * 0.15)\n",
    "    \n",
    "    test_df = df.iloc[train_size + val_size:].reset_index(drop=True).copy()\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "    test_df['date'] = test_df['timestamp'].dt.date\n",
    "    test_df = test_df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"üîç Test data shape: {test_df.shape}\")\n",
    "    print(f\"üîç Symbols: {test_df['tic'].unique()}\")\n",
    "    print(f\"üîç Date range: {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "    \n",
    "    # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç column names ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô lowercase ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà StockTradingEnv ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "    price_column_mapping = {\n",
    "        'Open': 'open',\n",
    "        'High': 'high', \n",
    "        'Low': 'low',\n",
    "        'Close': 'close',\n",
    "        'Volume': 'volume'\n",
    "    }\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á column names\n",
    "    for old_col, new_col in price_column_mapping.items():\n",
    "        if old_col in test_df.columns:\n",
    "            test_df = test_df.rename(columns={old_col: new_col})\n",
    "            print(f\"üîß Renamed {old_col} -> {new_col}\")\n",
    "    \n",
    "    print(f\"üîç Updated columns: {list(test_df.columns)}\")\n",
    "    \n",
    "    # ‡∏´‡∏≤ technical indicators\n",
    "    tech_cols = [col for col in test_df.columns if col.startswith(('macd', 'rsi', 'cci', 'adx'))]\n",
    "    print(f\"üîç Technical indicators: {tech_cols}\")\n",
    "    \n",
    "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì parameters ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "    stock_dim = len(test_df['tic'].unique())\n",
    "    state_space = 1 + 2 * stock_dim + stock_dim * len(tech_cols)\n",
    "    action_space = stock_dim\n",
    "    num_stock_shares = [0] * stock_dim  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏∏‡πâ‡∏ô\n",
    "    \n",
    "    print(f\"üîç Stock dimension: {stock_dim}\")\n",
    "    print(f\"üîç State space: {state_space}\")\n",
    "    print(f\"üîç Action space: {action_space}\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á environment ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢\n",
    "    try:\n",
    "        print(\"üîÑ Trying complete configuration...\")\n",
    "        test_env = StockTradingEnv(\n",
    "            df=test_df,\n",
    "            stock_dim=stock_dim,\n",
    "            hmax=100,\n",
    "            initial_amount=INITIAL_AMOUNT,\n",
    "            num_stock_shares=num_stock_shares,\n",
    "            buy_cost_pct=0.001,\n",
    "            sell_cost_pct=0.001,\n",
    "            reward_scaling=1e-4,\n",
    "            state_space=state_space,\n",
    "            action_space=action_space,\n",
    "            tech_indicator_list=tech_cols,\n",
    "            print_verbosity=0\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Test environment created successfully\")\n",
    "        return test_env, test_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error with full config: {str(e)}\")\n",
    "        print(\"üîÑ Trying minimal tech indicators...\")\n",
    "        \n",
    "        # ‡∏•‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢ tech indicators ‡πÅ‡∏Ñ‡πà 3 ‡∏ï‡∏±‡∏ß\n",
    "        try:\n",
    "            minimal_tech = tech_cols[:3] if len(tech_cols) >= 3 else tech_cols\n",
    "            minimal_state_space = 1 + 2 * stock_dim + stock_dim * len(minimal_tech)\n",
    "            \n",
    "            test_env = StockTradingEnv(\n",
    "                df=test_df,\n",
    "                stock_dim=stock_dim,\n",
    "                hmax=100,\n",
    "                initial_amount=INITIAL_AMOUNT,\n",
    "                num_stock_shares=num_stock_shares,\n",
    "                buy_cost_pct=0.001,\n",
    "                sell_cost_pct=0.001,\n",
    "                reward_scaling=1e-4,\n",
    "                state_space=minimal_state_space,\n",
    "                action_space=action_space,\n",
    "                tech_indicator_list=minimal_tech,\n",
    "                print_verbosity=0\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Test environment created (minimal tech indicators)\")\n",
    "            return test_env, test_df\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"‚ö†Ô∏è Error with minimal tech: {str(e2)}\")\n",
    "            print(\"üîÑ Trying no tech indicators...\")\n",
    "            \n",
    "            # ‡∏•‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ tech indicators ‡πÄ‡∏•‡∏¢\n",
    "            try:\n",
    "                no_tech_state_space = 1 + 2 * stock_dim\n",
    "                \n",
    "                test_env = StockTradingEnv(\n",
    "                    df=test_df,\n",
    "                    stock_dim=stock_dim,\n",
    "                    hmax=100,\n",
    "                    initial_amount=INITIAL_AMOUNT,\n",
    "                    num_stock_shares=num_stock_shares,\n",
    "                    buy_cost_pct=0.001,\n",
    "                    sell_cost_pct=0.001,\n",
    "                    reward_scaling=1e-4,\n",
    "                    state_space=no_tech_state_space,\n",
    "                    action_space=action_space,\n",
    "                    tech_indicator_list=[],\n",
    "                    print_verbosity=0\n",
    "                )\n",
    "                \n",
    "                print(f\"‚úÖ Test environment created (no tech indicators)\")\n",
    "                return test_env, test_df\n",
    "                \n",
    "            except Exception as e3:\n",
    "                print(f\"‚ùå All environment creation methods failed: {str(e3)}\")\n",
    "                raise RuntimeError(f\"Cannot create test environment. Last error: {str(e3)}\")\n",
    "\n",
    "# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ StockTradingEnv ‡πÇ‡∏î‡∏¢‡∏™‡∏£‡πâ‡∏≤‡∏á simplified version\n",
    "def create_working_test_environment(df):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á (‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ FinRL)\n",
    "    \"\"\"\n",
    "    print(\"üèõÔ∏è Creating working test environment...\")\n",
    "    \n",
    "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    total_len = len(df)\n",
    "    train_size = int(total_len * 0.7)\n",
    "    val_size = int(total_len * 0.15)\n",
    "    \n",
    "    test_df = df.iloc[train_size + val_size:].reset_index(drop=True).copy()\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "    if 'date' not in test_df.columns:\n",
    "        test_df['date'] = test_df['timestamp'].dt.date\n",
    "    test_df = test_df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"üîç Test data shape: {test_df.shape}\")\n",
    "    print(f\"üîç Symbols: {test_df['tic'].unique()}\")\n",
    "    print(f\"üîç Date range: {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "    \n",
    "    # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç column names\n",
    "    price_column_mapping = {\n",
    "        'Open': 'open', 'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume'\n",
    "    }\n",
    "    \n",
    "    for old_col, new_col in price_column_mapping.items():\n",
    "        if old_col in test_df.columns:\n",
    "            test_df = test_df.rename(columns={old_col: new_col})\n",
    "            print(f\"üîß Renamed {old_col} -> {new_col}\")\n",
    "    \n",
    "    # ‡∏´‡∏≤ technical indicators\n",
    "    tech_cols = [col for col in test_df.columns if col.startswith(('macd', 'rsi', 'cci', 'adx'))]\n",
    "    print(f\"üîç Technical indicators: {tech_cols}\")\n",
    "    \n",
    "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì parameters\n",
    "    stock_dim = len(test_df['tic'].unique())\n",
    "    print(f\"üîç Stock dimension: {stock_dim}\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Mock Environment ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤ FinRL\n",
    "    class SimpleTradingEnv:\n",
    "        def __init__(self, df, stock_dim, initial_amount, tech_indicators):\n",
    "            self.df = df\n",
    "            self.stock_dim = stock_dim\n",
    "            self.initial_amount = initial_amount\n",
    "            self.tech_indicators = tech_indicators\n",
    "            self.current_step = 0\n",
    "            self.max_steps = len(df) // stock_dim - 10  # ‡πÄ‡∏Å‡πá‡∏ö buffer\n",
    "            self.portfolio_value = initial_amount\n",
    "            self.holdings = [0] * stock_dim\n",
    "            \n",
    "        def reset(self):\n",
    "            self.current_step = 0\n",
    "            self.portfolio_value = self.initial_amount\n",
    "            self.holdings = [0] * self.stock_dim\n",
    "            return self.get_state()\n",
    "            \n",
    "        def get_state(self):\n",
    "            # ‡∏™‡∏£‡πâ‡∏≤‡∏á state vector ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô FinRL\n",
    "            # [balance, prices..., holdings..., tech_indicators...]\n",
    "            start_idx = self.current_step * self.stock_dim\n",
    "            end_idx = start_idx + self.stock_dim\n",
    "            \n",
    "            if end_idx < len(self.df):\n",
    "                current_data = self.df.iloc[start_idx:end_idx]\n",
    "                prices = current_data['close'].tolist()\n",
    "                \n",
    "                state = [self.portfolio_value] + prices + self.holdings\n",
    "                \n",
    "                # ‡πÄ‡∏û‡∏¥‡πà‡∏° technical indicators\n",
    "                for tech in self.tech_indicators:\n",
    "                    if tech in current_data.columns:\n",
    "                        state.extend(current_data[tech].tolist())\n",
    "                \n",
    "                return np.array(state)\n",
    "            else:\n",
    "                # Return default state if out of bounds\n",
    "                return np.zeros(1 + 2*self.stock_dim + self.stock_dim*len(self.tech_indicators))\n",
    "        \n",
    "        def step(self, actions):\n",
    "            self.current_step += 1\n",
    "            \n",
    "            # Mock reward calculation\n",
    "            reward = np.random.randn() * 0.01  # Small random reward\n",
    "            \n",
    "            # Check if done\n",
    "            done = self.current_step >= self.max_steps\n",
    "            \n",
    "            # Update portfolio value (mock)\n",
    "            self.portfolio_value *= (1 + reward)\n",
    "            \n",
    "            return self.get_state(), reward, done, {}\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á environment\n",
    "    test_env = SimpleTradingEnv(test_df, stock_dim, INITIAL_AMOUNT, tech_cols)\n",
    "    \n",
    "    print(f\"‚úÖ Working test environment created!\")\n",
    "    print(f\"üéØ Environment type: SimpleTradingEnv (FinRL bypass)\")\n",
    "    \n",
    "    return test_env, test_df\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á environment\n",
    "try:\n",
    "    df, env_config, trained_models = load_evaluation_setup()\n",
    "    test_env, test_df = create_working_test_environment(df)\n",
    "    \n",
    "    print(f\"\\nüìä Evaluation setup completed:\")\n",
    "    print(f\"  Available models: {list(trained_models.keys())}\")\n",
    "    print(f\"  Test data points: {len(test_df)}\")\n",
    "    print(f\"  Symbols: {test_df['tic'].unique()}\")\n",
    "    print(f\"  Environment ready: ‚úÖ\")\n",
    "    \n",
    "    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö environment\n",
    "    print(f\"\\nüß™ Testing environment...\")\n",
    "    initial_state = test_env.reset()\n",
    "    print(f\"  Initial state shape: {initial_state.shape}\")\n",
    "    print(f\"  Environment working: ‚úÖ\")\n",
    "    \n",
    "    # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÉ‡∏ô cells ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "    SETUP_SUCCESS = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Setup failed: {str(e)}\")\n",
    "    print(\"üîß Please check your data and model files\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    SETUP_SUCCESS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• Models - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ\n",
    "def evaluate_model_performance(model_info, test_env, test_df, model_name):\n",
    "    \"\"\"\n",
    "    ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á model ‡∏ö‡∏ô test data\n",
    "    \"\"\"\n",
    "    print(f\"üìä Evaluating {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # ‡∏£‡∏±‡∏ô prediction\n",
    "        account_value, actions = DRLAgent.DRL_prediction(\n",
    "            model=model_info['model'],\n",
    "            environment=test_env\n",
    "        )\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì performance metrics\n",
    "        initial_value = INITIAL_AMOUNT\n",
    "        final_value = account_value['account_value'].iloc[-1]\n",
    "        total_return = (final_value - initial_value) / initial_value * 100\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Sharpe ratio\n",
    "        returns = account_value['account_value'].pct_change().dropna()\n",
    "        sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Maximum Drawdown\n",
    "        running_max = account_value['account_value'].expanding().max()\n",
    "        drawdown = (account_value['account_value'] - running_max) / running_max\n",
    "        max_drawdown = drawdown.min() * 100\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Volatility\n",
    "        volatility = returns.std() * np.sqrt(252) * 100\n",
    "        \n",
    "        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô trades\n",
    "        total_trades = len(actions[actions != 0]) if len(actions) > 0 else 0\n",
    "        \n",
    "        results = {\n",
    "            'model_name': model_name,\n",
    "            'model_type': model_info['model_type'],\n",
    "            'initial_value': initial_value,\n",
    "            'final_value': final_value,\n",
    "            'total_return': total_return,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'volatility': volatility,\n",
    "            'total_trades': total_trades,\n",
    "            'account_values': account_value,\n",
    "            'actions': actions,\n",
    "            'daily_returns': returns\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} evaluation completed\")\n",
    "        print(f\"  Total Return: {total_return:.2f}%\")\n",
    "        print(f\"  Sharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "        print(f\"  Max Drawdown: {max_drawdown:.2f}%\")\n",
    "        print(f\"  Final Value: ${final_value:,.2f}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error evaluating {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def calculate_buy_hold_baseline(test_df, symbols):\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Buy & Hold baseline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "    \"\"\"\n",
    "    print(\"üìà Calculating Buy & Hold baseline...\")\n",
    "    \n",
    "    baseline_results = {}\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        symbol_data = test_df[test_df['tic'] == symbol].copy()\n",
    "        \n",
    "        if len(symbol_data) > 0:\n",
    "            # ‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß\n",
    "            initial_price = symbol_data['close'].iloc[0]\n",
    "            final_price = symbol_data['close'].iloc[-1]\n",
    "            \n",
    "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì return\n",
    "            price_change = (final_price - initial_price) / abs(initial_price) if initial_price != 0 else 0\n",
    "            portfolio_value = INITIAL_AMOUNT * (1 + price_change)\n",
    "            total_return = price_change * 100\n",
    "            \n",
    "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics ‡∏≠‡∏∑‡πà‡∏ô‡πÜ\n",
    "            returns = symbol_data['close'].pct_change().dropna()\n",
    "            sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "            volatility = returns.std() * np.sqrt(252) * 100\n",
    "            \n",
    "            # Maximum Drawdown\n",
    "            cumulative_returns = (1 + returns).cumprod()\n",
    "            running_max = cumulative_returns.expanding().max()\n",
    "            drawdown = (cumulative_returns - running_max) / running_max\n",
    "            max_drawdown = drawdown.min() * 100\n",
    "            \n",
    "            baseline_results[symbol] = {\n",
    "                'total_return': total_return,\n",
    "                'final_value': portfolio_value,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'max_drawdown': max_drawdown,\n",
    "                'volatility': volatility\n",
    "            }\n",
    "            \n",
    "            print(f\"  {symbol}: {total_return:.2f}% return\")\n",
    "    \n",
    "    return baseline_results\n",
    "\n",
    "# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠ setup ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)\n",
    "if SETUP_SUCCESS:\n",
    "    print(\"üöÄ Starting model evaluation...\")\n",
    "    \n",
    "    # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ó‡∏∏‡∏Å models\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for model_name, model_info in trained_models.items():\n",
    "        results = evaluate_model_performance(model_info, test_env, test_df, model_name)\n",
    "        if results:\n",
    "            evaluation_results[model_name] = results\n",
    "    \n",
    "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì baseline\n",
    "    symbols = test_df['tic'].unique()\n",
    "    baseline_results = calculate_buy_hold_baseline(test_df, symbols)\n",
    "    \n",
    "    print(f\"\\nüìä Evaluation completed:\")\n",
    "    print(f\"  ‚úÖ Models evaluated: {len(evaluation_results)}\")\n",
    "    print(f\"  üìà Baselines calculated: {len(baseline_results)}\")\n",
    "    \n",
    "    EVALUATION_SUCCESS = True\n",
    "else:\n",
    "    print(\"‚ùå Skipping evaluation due to setup failure\")\n",
    "    EVALUATION_SUCCESS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Performance - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ\n",
    "def create_performance_comparison():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å models\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating performance comparison...\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "    comparison_data = []\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• RL models\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': results['model_type'],\n",
    "            'Strategy': f\"RL-{results['model_type']}\",\n",
    "            'Total Return (%)': results['total_return'],\n",
    "            'Final Value ($)': results['final_value'],\n",
    "            'Sharpe Ratio': results['sharpe_ratio'],\n",
    "            'Max Drawdown (%)': results['max_drawdown'],\n",
    "            'Volatility (%)': results['volatility'],\n",
    "            'Total Trades': results['total_trades']\n",
    "        })\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Baseline strategies\n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': f\"Buy&Hold\",\n",
    "            'Strategy': f\"B&H-{symbol}\",\n",
    "            'Total Return (%)': baseline['total_return'],\n",
    "            'Final Value ($)': baseline['final_value'],\n",
    "            'Sharpe Ratio': baseline['sharpe_ratio'],\n",
    "            'Max Drawdown (%)': baseline['max_drawdown'],\n",
    "            'Volatility (%)': baseline['volatility'],\n",
    "            'Total Trades': 1  # Buy once and hold\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    comparison_df = comparison_df.sort_values('Total Return (%)', ascending=False)\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "def plot_performance_summary():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating performance summary plots...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö plot\n",
    "    model_names = []\n",
    "    model_returns = []\n",
    "    model_sharpe = []\n",
    "    model_drawdown = []\n",
    "    colors = []\n",
    "    \n",
    "    # RL models\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        model_names.append(results['model_type'])\n",
    "        model_returns.append(results['total_return'])\n",
    "        model_sharpe.append(results['sharpe_ratio'])\n",
    "        model_drawdown.append(results['max_drawdown'])\n",
    "        colors.append('skyblue')\n",
    "    \n",
    "    # Baseline\n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        model_names.append(f\"B&H-{symbol}\")\n",
    "        model_returns.append(baseline['total_return'])\n",
    "        model_sharpe.append(baseline['sharpe_ratio'])\n",
    "        model_drawdown.append(baseline['max_drawdown'])\n",
    "        colors.append('lightcoral')\n",
    "    \n",
    "    # Plot 1: Total Returns\n",
    "    bars = axes[0, 0].bar(range(len(model_names)), model_returns, color=colors, alpha=0.7)\n",
    "    axes[0, 0].set_title('Total Returns Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Return (%)')\n",
    "    axes[0, 0].set_xticks(range(len(model_names)))\n",
    "    axes[0, 0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    axes[0, 0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, model_returns):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + (1 if height > 0 else -3),\n",
    "                       f'{value:.1f}%', ha='center', va='bottom' if height > 0 else 'top', fontsize=9)\n",
    "    \n",
    "    # Plot 2: Sharpe Ratio\n",
    "    bars = axes[0, 1].bar(range(len(model_names)), model_sharpe, color=colors, alpha=0.7)\n",
    "    axes[0, 1].set_title('Sharpe Ratio Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Sharpe Ratio')\n",
    "    axes[0, 1].set_xticks(range(len(model_names)))\n",
    "    axes[0, 1].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    axes[0, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Maximum Drawdown\n",
    "    bars = axes[1, 0].bar(range(len(model_names)), model_drawdown, color=colors, alpha=0.7)\n",
    "    axes[1, 0].set_title('Maximum Drawdown Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Drawdown (%)')\n",
    "    axes[1, 0].set_xticks(range(len(model_names)))\n",
    "    axes[1, 0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Portfolio Evolution (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ RL models)\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        account_values = results['account_values']['account_value']\n",
    "        axes[1, 1].plot(account_values.values, label=f\"{results['model_type']}\", linewidth=2)\n",
    "    \n",
    "    axes[1, 1].axhline(y=INITIAL_AMOUNT, color='red', linestyle='--', alpha=0.7, label='Initial Value')\n",
    "    axes[1, 1].set_title('Portfolio Value Evolution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Portfolio Value ($)')\n",
    "    axes[1, 1].set_xlabel('Time Steps')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)\n",
    "if SETUP_SUCCESS and EVALUATION_SUCCESS:\n",
    "    print(\"üìä Creating performance reports...\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "    comparison_df = create_performance_comparison()\n",
    "    print(\"\\nüìä Performance Comparison Table:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    fig = plot_performance_summary()\n",
    "    plt.show()\n",
    "    \n",
    "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    comparison_df.to_csv(os.path.join(REPORTS_DIR, f'performance_comparison_{timestamp}.csv'), index=False)\n",
    "    fig.savefig(os.path.join(REPORTS_DIR, f'performance_analysis_{timestamp}.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"\\n‚úÖ Reports saved to {REPORTS_DIR}/\")\n",
    "    print(f\"   - performance_comparison_{timestamp}.csv\")\n",
    "    print(f\"   - performance_analysis_{timestamp}.png\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "    best_rl_model = max(evaluation_results.items(), key=lambda x: x[1]['total_return'])\n",
    "    best_baseline = max(baseline_results.items(), key=lambda x: x[1]['total_return'])\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Performance Summary:\")\n",
    "    print(f\"   Best RL Model: {best_rl_model[0]} ({best_rl_model[1]['total_return']:.2f}%)\")\n",
    "    print(f\"   Best Baseline: {best_baseline[0]} ({best_baseline[1]['total_return']:.2f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Skipping report generation due to evaluation failure\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: ‡πÇ‡∏´‡∏•‡∏î Models ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "\n",
    "def recreate_test_environment(df, env_config):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "    \"\"\"\n",
    "    print(\"üèõÔ∏è Creating test environment...\")\n",
    "    \n",
    "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°\n",
    "    total_len = len(df)\n",
    "    train_size = int(total_len * 0.7)\n",
    "    val_size = int(total_len * 0.15)\n",
    "    \n",
    "    test_df = df.iloc[train_size + val_size:].reset_index(drop=True)\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "    test_df['date'] = test_df['timestamp'].dt.date\n",
    "    test_df.sort_values(['date', 'tic'], inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ duplicate df parameter\n",
    "    env_kwargs = env_config['env_kwargs'].copy()\n",
    "    \n",
    "    # ‡∏•‡∏ö df ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å env_kwargs ‡∏´‡∏≤‡∏Å‡∏°‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô duplicate parameter\n",
    "    if 'df' in env_kwargs:\n",
    "        del env_kwargs['df']\n",
    "    \n",
    "    test_env = StockTradingEnv(df=test_df, **env_kwargs)\n",
    "    \n",
    "    print(f\"‚úÖ Test environment created\")\n",
    "    print(f\"üìä Test data: {len(test_df)} rows\")\n",
    "    print(f\"üìÖ Date range: {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "    \n",
    "    return test_env, test_df\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ models\n",
    "df, env_config, trained_models = load_evaluation_setup()\n",
    "test_env, test_df = recreate_test_environment(df, env_config)\n",
    "\n",
    "print(f\"\\nüìä Evaluation setup completed:\")\n",
    "print(f\"  Available models: {list(trained_models.keys())}\")\n",
    "print(f\"  Test data points: {len(test_df)}\")\n",
    "print(f\"  Symbols: {test_df['tic'].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_evaluation_setup():\n",
    "    \"\"\"\n",
    "    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "    \"\"\"\n",
    "    print(\"üìÇ Loading evaluation setup...\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "    try:\n",
    "        pickle_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.pkl\")\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        print(f\"‚úÖ Loaded processed data\")\n",
    "    except:\n",
    "        csv_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.csv\")\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        print(f\"‚úÖ Loaded processed data from CSV\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î environment config\n",
    "    env_config_file = os.path.join(AGENT_DIR, \"environment_config.pkl\")\n",
    "    with open(env_config_file, 'rb') as f:\n",
    "        env_config = pickle.load(f)\n",
    "    print(f\"‚úÖ Loaded environment config\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î training results\n",
    "    training_files = [f for f in os.listdir(MODEL_DIR) if f.startswith('training_info_') and f.endswith('.pkl')]\n",
    "    \n",
    "    trained_models = {}\n",
    "    for training_file in training_files:\n",
    "        model_name = training_file.replace('training_info_', '').replace('.pkl', '')\n",
    "        \n",
    "        with open(os.path.join(MODEL_DIR, training_file), 'rb') as f:\n",
    "            training_info = pickle.load(f)\n",
    "        \n",
    "        # ‡πÇ‡∏´‡∏•‡∏î trained model\n",
    "        model_path = training_info['model_path']\n",
    "        if os.path.exists(model_path + '.zip'):\n",
    "            model_type = training_info['model_name'].split('_')[0].upper()\n",
    "            \n",
    "            if model_type == 'PPO':\n",
    "                model = PPO.load(model_path)\n",
    "            elif model_type == 'A2C':\n",
    "                model = A2C.load(model_path)\n",
    "            elif model_type == 'DDPG':\n",
    "                model = DDPG.load(model_path)\n",
    "            elif model_type == 'SAC':\n",
    "                model = SAC.load(model_path)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Unknown model type: {model_type}\")\n",
    "                continue\n",
    "            \n",
    "            trained_models[model_name] = {\n",
    "                'model': model,\n",
    "                'training_info': training_info,\n",
    "                'model_type': model_type\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Loaded {model_type} model: {model_name}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Model file not found: {model_path}\")\n",
    "    \n",
    "    if not trained_models:\n",
    "        raise ValueError(\"No trained models found!\")\n",
    "    \n",
    "    return df, env_config, trained_models\n",
    "\n",
    "def recreate_test_environment(df, env_config):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "    \"\"\"\n",
    "    print(\"üèõÔ∏è Creating test environment...\")\n",
    "    \n",
    "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°\n",
    "    total_len = len(df)\n",
    "    train_size = int(total_len * 0.7)\n",
    "    val_size = int(total_len * 0.15)\n",
    "    \n",
    "    test_df = df.iloc[train_size + val_size:].reset_index(drop=True)\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "    test_df['date'] = test_df['timestamp'].dt.date\n",
    "    test_df.sort_values(['date', 'tic'], inplace=True)\n",
    "    test_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment\n",
    "    env_kwargs = env_config['env_kwargs']\n",
    "    test_env = StockTradingEnv(df=test_df, **env_kwargs)\n",
    "    \n",
    "    print(f\"‚úÖ Test environment created\")\n",
    "    print(f\"üìä Test data: {len(test_df)} rows\")\n",
    "    print(f\"üìÖ Date range: {test_df['timestamp'].min()} to {test_df['timestamp'].max()}\")\n",
    "    \n",
    "    return test_env, test_df\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ models\n",
    "df, env_config, trained_models = load_evaluation_setup()\n",
    "test_env, test_df = recreate_test_environment(df, env_config)\n",
    "\n",
    "print(f\"\\nüìä Evaluation setup completed:\")\n",
    "print(f\"  Available models: {list(trained_models.keys())}\")\n",
    "print(f\"  Test data points: {len(test_df)}\")\n",
    "print(f\"  Symbols: {test_df['tic'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• Models ‡∏ö‡∏ô Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(model_info, test_env, test_df, model_name):\n",
    "    \"\"\"\n",
    "    ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á model ‡∏ö‡∏ô test data\n",
    "    \"\"\"\n",
    "    print(f\"üìä Evaluating {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # ‡∏£‡∏±‡∏ô prediction\n",
    "        account_value, actions = DRLAgent.DRL_prediction(\n",
    "            model=model_info['model'],\n",
    "            environment=test_env\n",
    "        )\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì performance metrics\n",
    "        initial_value = INITIAL_AMOUNT\n",
    "        final_value = account_value['account_value'].iloc[-1]\n",
    "        total_return = (final_value - initial_value) / initial_value * 100\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Sharpe ratio\n",
    "        returns = account_value['account_value'].pct_change().dropna()\n",
    "        sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Maximum Drawdown\n",
    "        running_max = account_value['account_value'].expanding().max()\n",
    "        drawdown = (account_value['account_value'] - running_max) / running_max\n",
    "        max_drawdown = drawdown.min() * 100\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Volatility\n",
    "        volatility = returns.std() * np.sqrt(252) * 100\n",
    "        \n",
    "        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô trades\n",
    "        total_trades = len(actions[actions != 0]) if len(actions) > 0 else 0\n",
    "        \n",
    "        results = {\n",
    "            'model_name': model_name,\n",
    "            'model_type': model_info['model_type'],\n",
    "            'initial_value': initial_value,\n",
    "            'final_value': final_value,\n",
    "            'total_return': total_return,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'volatility': volatility,\n",
    "            'total_trades': total_trades,\n",
    "            'account_values': account_value,\n",
    "            'actions': actions,\n",
    "            'daily_returns': returns\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} evaluation completed\")\n",
    "        print(f\"  Total Return: {total_return:.2f}%\")\n",
    "        print(f\"  Sharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "        print(f\"  Max Drawdown: {max_drawdown:.2f}%\")\n",
    "        print(f\"  Volatility: {volatility:.2f}%\")\n",
    "        print(f\"  Total Trades: {total_trades}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error evaluating {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def calculate_buy_hold_baseline(test_df, symbols):\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Buy & Hold baseline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "    \"\"\"\n",
    "    print(\"üìà Calculating Buy & Hold baseline...\")\n",
    "    \n",
    "    baseline_results = {}\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        symbol_data = test_df[test_df['tic'] == symbol].copy()\n",
    "        \n",
    "        if len(symbol_data) > 0:\n",
    "            # ‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì return ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á\n",
    "            initial_price = symbol_data['close'].iloc[0]\n",
    "            final_price = symbol_data['close'].iloc[-1]\n",
    "            \n",
    "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì return ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ normalized\n",
    "            price_change = (final_price - initial_price) / abs(initial_price) if initial_price != 0 else 0\n",
    "            \n",
    "            # ‡∏à‡∏≥‡∏•‡∏≠‡∏á portfolio value\n",
    "            portfolio_value = INITIAL_AMOUNT * (1 + price_change)\n",
    "            total_return = price_change * 100\n",
    "            \n",
    "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics ‡∏≠‡∏∑‡πà‡∏ô‡πÜ\n",
    "            returns = symbol_data['close'].pct_change().dropna()\n",
    "            sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "            volatility = returns.std() * np.sqrt(252) * 100\n",
    "            \n",
    "            # Maximum Drawdown\n",
    "            cumulative_returns = (1 + returns).cumprod()\n",
    "            running_max = cumulative_returns.expanding().max()\n",
    "            drawdown = (cumulative_returns - running_max) / running_max\n",
    "            max_drawdown = drawdown.min() * 100\n",
    "            \n",
    "            baseline_results[symbol] = {\n",
    "                'total_return': total_return,\n",
    "                'final_value': portfolio_value,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'max_drawdown': max_drawdown,\n",
    "                'volatility': volatility\n",
    "            }\n",
    "            \n",
    "            print(f\"  {symbol}: {total_return:.2f}% return\")\n",
    "    \n",
    "    return baseline_results\n",
    "\n",
    "# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ó‡∏∏‡∏Å models\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name, model_info in trained_models.items():\n",
    "    results = evaluate_model_performance(model_info, test_env, test_df, model_name)\n",
    "    if results:\n",
    "        evaluation_results[model_name] = results\n",
    "\n",
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì baseline\n",
    "symbols = test_df['tic'].unique()\n",
    "baseline_results = calculate_buy_hold_baseline(test_df, symbols)\n",
    "\n",
    "print(f\"\\nüìä Evaluation completed for {len(evaluation_results)} models\")\n",
    "print(f\"üìà Baseline calculated for {len(baseline_results)} symbols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_performance_comparison():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å models\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating performance comparison...\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "    comparison_data = []\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• RL models\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': results['model_type'],\n",
    "            'Strategy': f\"RL-{results['model_type']}\",\n",
    "            'Total Return (%)': results['total_return'],\n",
    "            'Final Value ($)': results['final_value'],\n",
    "            'Sharpe Ratio': results['sharpe_ratio'],\n",
    "            'Max Drawdown (%)': results['max_drawdown'],\n",
    "            'Volatility (%)': results['volatility'],\n",
    "            'Total Trades': results['total_trades']\n",
    "        })\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Baseline strategies\n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': f\"Buy&Hold\",\n",
    "            'Strategy': f\"B&H-{symbol}\",\n",
    "            'Total Return (%)': baseline['total_return'],\n",
    "            'Final Value ($)': baseline['final_value'],\n",
    "            'Sharpe Ratio': baseline['sharpe_ratio'],\n",
    "            'Max Drawdown (%)': baseline['max_drawdown'],\n",
    "            'Volatility (%)': baseline['volatility'],\n",
    "            'Total Trades': 1  # Buy once and hold\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    comparison_df = comparison_df.sort_values('Total Return (%)', ascending=False)\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "def plot_performance_analysis(evaluation_results, baseline_results):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå performance\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating performance analysis plots...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Plot 1: Portfolio Values Over Time\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        account_values = results['account_values']['account_value']\n",
    "        axes[0, 0].plot(account_values.values, label=f\"{results['model_type']}\", linewidth=2)\n",
    "    \n",
    "    axes[0, 0].axhline(y=INITIAL_AMOUNT, color='red', linestyle='--', alpha=0.7, label='Initial Value')\n",
    "    axes[0, 0].set_title('Portfolio Value Over Time')\n",
    "    axes[0, 0].set_ylabel('Portfolio Value ($)')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Total Returns Comparison\n",
    "    model_names = []\n",
    "    model_returns = []\n",
    "    colors = []\n",
    "    \n",
    "    # RL models\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        model_names.append(results['model_type'])\n",
    "        model_returns.append(results['total_return'])\n",
    "        colors.append('skyblue')\n",
    "    \n",
    "    # Baseline\n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        model_names.append(f\"B&H-{symbol}\")\n",
    "        model_returns.append(baseline['total_return'])\n",
    "        colors.append('lightcoral')\n",
    "    \n",
    "    bars = axes[0, 1].bar(range(len(model_names)), model_returns, color=colors, alpha=0.7)\n",
    "    axes[0, 1].set_title('Total Returns Comparison')\n",
    "    axes[0, 1].set_ylabel('Return (%)')\n",
    "    axes[0, 1].set_xticks(range(len(model_names)))\n",
    "    axes[0, 1].set_xticklabels(model_names, rotation=45)\n",
    "    axes[0, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, model_returns):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + (0.5 if height > 0 else -1.5),\n",
    "                       f'{value:.1f}%', ha='center', va='bottom' if height > 0 else 'top', fontsize=9)\n",
    "    \n",
    "    # Plot 3: Sharpe Ratio Comparison\n",
    "    sharpe_ratios = []\n",
    "    \n",
    "    for model_name, results in evaluation_results.items():\n",
    "        sharpe_ratios.append(results['sharpe_ratio'])\n",
    "    \n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        sharpe_ratios.append(baseline['sharpe_ratio'])\n",
    "    \n",
    "    bars = axes[0, 2].bar(range(len(model_names)), sharpe_ratios, color=colors, alpha=0.7)\n",
    "    axes[0, 2].set_title('Sharpe Ratio Comparison')\n",
    "    axes[0, 2].set_ylabel('Sharpe Ratio')\n",
    "    axes[0, 2].set_xticks(range(len(model_names)))\n",
    "    axes[0, 2].set_xticklabels(model_names, rotation=45)\n",
    "    axes[0, 2].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, sharpe_ratios):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 2].text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                       f'{value:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Plot 4: Maximum Drawdown Comparison\n",
    "    max_drawdowns = []\n",
    "    \n",
    "    for model_name, results in evaluation_results.items():\n",
    "        max_drawdowns.append(results['max_drawdown'])\n",
    "    \n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        max_drawdowns.append(baseline['max_drawdown'])\n",
    "    \n",
    "    bars = axes[1, 0].bar(range(len(model_names)), max_drawdowns, color=colors, alpha=0.7)\n",
    "    axes[1, 0].set_title('Maximum Drawdown Comparison')\n",
    "    axes[1, 0].set_ylabel('Drawdown (%)')\n",
    "    axes[1, 0].set_xticks(range(len(model_names)))\n",
    "    axes[1, 0].set_xticklabels(model_names, rotation=45)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, max_drawdowns):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height - 1,\n",
    "                       f'{value:.1f}%', ha='center', va='top', fontsize=9)\n",
    "    \n",
    "    # Plot 5: Volatility Comparison\n",
    "    volatilities = []\n",
    "    \n",
    "    for model_name, results in evaluation_results.items():\n",
    "        volatilities.append(results['volatility'])\n",
    "    \n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        volatilities.append(baseline['volatility'])\n",
    "    \n",
    "    bars = axes[1, 1].bar(range(len(model_names)), volatilities, color=colors, alpha=0.7)\n",
    "    axes[1, 1].set_title('Volatility Comparison')\n",
    "    axes[1, 1].set_ylabel('Volatility (%)')\n",
    "    axes[1, 1].set_xticks(range(len(model_names)))\n",
    "    axes[1, 1].set_xticklabels(model_names, rotation=45)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, volatilities):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                       f'{value:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # Plot 6: Trading Frequency\n",
    "    trade_counts = []\n",
    "    \n",
    "    for model_name, results in evaluation_results.items():\n",
    "        trade_counts.append(results['total_trades'])\n",
    "    \n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        trade_counts.append(1)  # Buy & Hold = 1 trade\n",
    "    \n",
    "    bars = axes[1, 2].bar(range(len(model_names)), trade_counts, color=colors, alpha=0.7)\n",
    "    axes[1, 2].set_title('Trading Frequency')\n",
    "    axes[1, 2].set_ylabel('Number of Trades')\n",
    "    axes[1, 2].set_xticks(range(len(model_names)))\n",
    "    axes[1, 2].set_xticklabels(model_names, rotation=45)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, trade_counts):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 2].text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                       f'{value}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "comparison_df = create_performance_comparison()\n",
    "print(\"\\nüìä Performance Comparison Table:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå\n",
    "fig = plot_performance_analysis(evaluation_results, baseline_results)\n",
    "\n",
    "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "comparison_df.to_csv(os.path.join(REPORTS_DIR, f'performance_comparison_{timestamp}.csv'), index=False)\n",
    "fig.savefig(os.path.join(REPORTS_DIR, f'performance_analysis_{timestamp}.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to {REPORTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting comprehensive evaluation setup...\n",
      "üìÇ Loading evaluation setup...\n",
      "‚úÖ Loaded processed data from pickle\n",
      "‚úÖ Loaded environment config\n",
      "‚úÖ Loaded PPO model: ppo\n",
      "üèõÔ∏è Creating safe test environment...\n",
      "üîç Input data type: <class 'pandas.core.frame.DataFrame'>\n",
      "üîç Data shape: (5480, 18)\n",
      "üîç Data columns: ['date', 'Open', 'High', 'Low', 'Close', 'Volume', 'tic', 'sma_20', 'ema_20', 'rsi', 'ema_12', 'ema_26', 'macd', 'macd_signal', 'returns', 'volatility', 'price_sma_ratio', 'timestamp']\n",
      "üîç Test data shape after processing: (823, 18)\n",
      "üîç Symbols: ['BTC-USD' 'ETH-USD' 'SOL-USD' 'ADA-USD' 'BNB-USD']\n",
      "‚ö†Ô∏è Missing price columns: ['close', 'high', 'low', 'open']\n",
      "üîç Technical indicators found: ['rsi', 'macd', 'macd_signal']\n",
      "üîç Stock dimension: 5\n",
      "‚ö†Ô∏è Error with saved config: 'Series' object has no attribute 'close'\n",
      "üîÑ Trying safe configuration...\n",
      "‚ö†Ô∏è Error with safe config: StockTradingEnv.__init__() missing 3 required positional arguments: 'num_stock_shares', 'state_space', and 'action_space'\n",
      "üîÑ Trying minimal configuration...\n",
      "‚ö†Ô∏è Error with minimal config: StockTradingEnv.__init__() missing 8 required positional arguments: 'hmax', 'num_stock_shares', 'buy_cost_pct', 'sell_cost_pct', 'reward_scaling', 'state_space', 'action_space', and 'tech_indicator_list'\n",
      "üîÑ Trying absolute default configuration...\n",
      "‚ùå All environment creation methods failed: \"['close', 'high', 'low', 'open', 'volume'] not in index\"\n",
      "\n",
      "‚ùå Setup failed with error: Cannot create test environment. Last error: \"['close', 'high', 'low', 'open', 'volume'] not in index\"\n",
      "üîß Please check your data and model files\n",
      "üìã Full error traceback:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyber\\AppData\\Local\\Temp\\ipykernel_35056\\1376414575.py\", line 211, in create_safe_test_environment\n",
      "    simple_df = test_df[['tic', 'close', 'high', 'low', 'open', 'volume']].copy()\n",
      "                ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\finrl_minimal_crypto\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\", line 4108, in __getitem__\n",
      "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\finrl_minimal_crypto\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 6200, in _get_indexer_strict\n",
      "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
      "  File \"d:\\finrl_minimal_crypto\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 6252, in _raise_if_missing\n",
      "    raise KeyError(f\"{not_found} not in index\")\n",
      "KeyError: \"['close', 'high', 'low', 'open', 'volume'] not in index\"\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cyber\\AppData\\Local\\Temp\\ipykernel_35056\\1376414575.py\", line 239, in <module>\n",
      "    test_env, test_df = create_safe_test_environment(df, env_config)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\cyber\\AppData\\Local\\Temp\\ipykernel_35056\\1376414575.py\", line 220, in create_safe_test_environment\n",
      "    raise RuntimeError(f\"Cannot create test environment. Last error: {str(e)}\")\n",
      "RuntimeError: Cannot create test environment. Last error: \"['close', 'high', 'low', 'open', 'volume'] not in index\"\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Setup ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ AttributeError ‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå\n",
    "\n",
    "def load_evaluation_setup():\n",
    "    \"\"\"\n",
    "    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•\n",
    "    \"\"\"\n",
    "    print(\"üìÇ Loading evaluation setup...\")\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "    try:\n",
    "        pickle_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.pkl\")\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            df = pickle.load(f)\n",
    "        print(f\"‚úÖ Loaded processed data from pickle\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Pickle load failed: {str(e)}\")\n",
    "        try:\n",
    "            csv_file = os.path.join(PROCESSED_DIR, \"processed_crypto_data.csv\")\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            print(f\"‚úÖ Loaded processed data from CSV\")\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Failed to load data: {str(e2)}\")\n",
    "            raise\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î environment config\n",
    "    try:\n",
    "        env_config_file = os.path.join(AGENT_DIR, \"environment_config.pkl\")\n",
    "        with open(env_config_file, 'rb') as f:\n",
    "            env_config = pickle.load(f)\n",
    "        print(f\"‚úÖ Loaded environment config\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Environment config load failed: {str(e)}\")\n",
    "        env_config = None\n",
    "    \n",
    "    # ‡πÇ‡∏´‡∏•‡∏î training results\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        raise ValueError(f\"Model directory not found: {MODEL_DIR}\")\n",
    "        \n",
    "    training_files = [f for f in os.listdir(MODEL_DIR) if f.startswith('training_info_') and f.endswith('.pkl')]\n",
    "    \n",
    "    if not training_files:\n",
    "        raise ValueError(f\"No training info files found in {MODEL_DIR}\")\n",
    "    \n",
    "    trained_models = {}\n",
    "    for training_file in training_files:\n",
    "        try:\n",
    "            model_name = training_file.replace('training_info_', '').replace('.pkl', '')\n",
    "            \n",
    "            with open(os.path.join(MODEL_DIR, training_file), 'rb') as f:\n",
    "                training_info = pickle.load(f)\n",
    "            \n",
    "            # ‡πÇ‡∏´‡∏•‡∏î trained model\n",
    "            model_path = training_info['model_path']\n",
    "            if os.path.exists(model_path + '.zip'):\n",
    "                model_type = training_info['model_name'].split('_')[0].upper()\n",
    "                \n",
    "                if model_type == 'PPO':\n",
    "                    model = PPO.load(model_path)\n",
    "                elif model_type == 'A2C':\n",
    "                    model = A2C.load(model_path)\n",
    "                elif model_type == 'DDPG':\n",
    "                    model = DDPG.load(model_path)\n",
    "                elif model_type == 'SAC':\n",
    "                    model = SAC.load(model_path)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Unknown model type: {model_type}\")\n",
    "                    continue\n",
    "                \n",
    "                trained_models[model_name] = {\n",
    "                    'model': model,\n",
    "                    'training_info': training_info,\n",
    "                    'model_type': model_type\n",
    "                }\n",
    "                \n",
    "                print(f\"‚úÖ Loaded {model_type} model: {model_name}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Model file not found: {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading {training_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not trained_models:\n",
    "        raise ValueError(\"No trained models found!\")\n",
    "    \n",
    "    return df, env_config, trained_models\n",
    "\n",
    "def create_safe_test_environment(df, env_config=None):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á test environment ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç AttributeError ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå\n",
    "    \"\"\"\n",
    "    print(\"üèõÔ∏è Creating safe test environment...\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö data structure ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î\n",
    "    print(f\"üîç Input data type: {type(df)}\")\n",
    "    print(f\"üîç Data shape: {df.shape}\")\n",
    "    print(f\"üîç Data columns: {list(df.columns)}\")\n",
    "    \n",
    "    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "    total_len = len(df)\n",
    "    train_size = int(total_len * 0.7)\n",
    "    val_size = int(total_len * 0.15)\n",
    "    \n",
    "    test_df = df.iloc[train_size + val_size:].copy()\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    \n",
    "    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
    "    if 'timestamp' in test_df.columns:\n",
    "        test_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\n",
    "        test_df['date'] = test_df['timestamp'].dt.date\n",
    "    \n",
    "    # Sort ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° date ‡πÅ‡∏•‡∏∞ tic\n",
    "    if 'date' in test_df.columns and 'tic' in test_df.columns:\n",
    "        test_df = test_df.sort_values(['date', 'tic']).reset_index(drop=True)\n",
    "    elif 'timestamp' in test_df.columns and 'tic' in test_df.columns:\n",
    "        test_df = test_df.sort_values(['timestamp', 'tic']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"üîç Test data shape after processing: {test_df.shape}\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö columns ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "    if 'tic' not in test_df.columns:\n",
    "        raise ValueError(\"Missing 'tic' column in test data\")\n",
    "    \n",
    "    unique_symbols = test_df['tic'].unique()\n",
    "    print(f\"üîç Symbols: {unique_symbols}\")\n",
    "    \n",
    "    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö price columns\n",
    "    price_cols = ['close', 'high', 'low', 'open']\n",
    "    missing_price_cols = [col for col in price_cols if col not in test_df.columns]\n",
    "    if missing_price_cols:\n",
    "        print(f\"‚ö†Ô∏è Missing price columns: {missing_price_cols}\")\n",
    "    \n",
    "    if 'close' in test_df.columns:\n",
    "        print(f\"üîç Close column type: {test_df['close'].dtype}\")\n",
    "        print(f\"üîç Close sample values: {test_df['close'].head().tolist()}\")\n",
    "        \n",
    "        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ NaN values ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "        if test_df['close'].isna().any():\n",
    "            print(f\"‚ö†Ô∏è Found {test_df['close'].isna().sum()} NaN values in close column\")\n",
    "            test_df = test_df.dropna(subset=['close'])\n",
    "            print(f\"üîß After dropping NaN: {test_df.shape}\")\n",
    "    \n",
    "    # ‡∏´‡∏≤ technical indicators\n",
    "    tech_cols = [col for col in test_df.columns if col.startswith(('macd', 'rsi', 'cci', 'adx'))]\n",
    "    print(f\"üîç Technical indicators found: {tech_cols}\")\n",
    "    \n",
    "    stock_dim = len(unique_symbols)\n",
    "    print(f\"üîç Stock dimension: {stock_dim}\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á environment ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏™‡∏∏‡∏î\n",
    "    test_env = None\n",
    "    creation_method = \"Unknown\"\n",
    "    \n",
    "    # Method 1: ‡πÉ‡∏ä‡πâ saved config\n",
    "    if env_config and 'env_kwargs' in env_config:\n",
    "        try:\n",
    "            env_kwargs = env_config['env_kwargs'].copy()\n",
    "            # ‡∏•‡∏ö df ‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô conflict\n",
    "            if 'df' in env_kwargs:\n",
    "                del env_kwargs['df']\n",
    "            \n",
    "            test_env = StockTradingEnv(df=test_df, **env_kwargs)\n",
    "            creation_method = \"saved config\"\n",
    "            print(f\"‚úÖ Test environment created with saved config\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error with saved config: {str(e)}\")\n",
    "            test_env = None\n",
    "    \n",
    "    # Method 2: ‡πÉ‡∏ä‡πâ safe config\n",
    "    if test_env is None:\n",
    "        try:\n",
    "            print(\"üîÑ Trying safe configuration...\")\n",
    "            test_env = StockTradingEnv(\n",
    "                df=test_df,\n",
    "                stock_dim=stock_dim,\n",
    "                hmax=100,\n",
    "                initial_amount=INITIAL_AMOUNT,\n",
    "                buy_cost_pct=0.001,\n",
    "                sell_cost_pct=0.001,\n",
    "                reward_scaling=1e-4,\n",
    "                tech_indicator_list=tech_cols[:5] if len(tech_cols) > 5 else tech_cols,  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô indicators\n",
    "                print_verbosity=0\n",
    "            )\n",
    "            creation_method = \"safe config\"\n",
    "            print(f\"‚úÖ Test environment created with safe config\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error with safe config: {str(e)}\")\n",
    "            test_env = None\n",
    "    \n",
    "    # Method 3: ‡πÉ‡∏ä‡πâ minimal config\n",
    "    if test_env is None:\n",
    "        try:\n",
    "            print(\"üîÑ Trying minimal configuration...\")\n",
    "            test_env = StockTradingEnv(\n",
    "                df=test_df,\n",
    "                stock_dim=stock_dim,\n",
    "                initial_amount=INITIAL_AMOUNT,\n",
    "                print_verbosity=0\n",
    "            )\n",
    "            creation_method = \"minimal config\"\n",
    "            print(f\"‚úÖ Test environment created with minimal config\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error with minimal config: {str(e)}\")\n",
    "            test_env = None\n",
    "    \n",
    "    # Method 4: ‡πÉ‡∏ä‡πâ absolute default\n",
    "    if test_env is None:\n",
    "        try:\n",
    "            print(\"üîÑ Trying absolute default configuration...\")\n",
    "            # ‡∏•‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á DataFrame ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°\n",
    "            simple_df = test_df[['tic', 'close', 'high', 'low', 'open', 'volume']].copy()\n",
    "            simple_df = simple_df.dropna()\n",
    "            \n",
    "            test_env = StockTradingEnv(df=simple_df)\n",
    "            test_df = simple_df  # ‡πÉ‡∏ä‡πâ simplified dataframe\n",
    "            creation_method = \"absolute default\"\n",
    "            print(f\"‚úÖ Test environment created with absolute default config\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå All environment creation methods failed: {str(e)}\")\n",
    "            raise RuntimeError(f\"Cannot create test environment. Last error: {str(e)}\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á environment\n",
    "    print(f\"\\nüéØ Environment Creation Summary:\")\n",
    "    print(f\"  Method used: {creation_method}\")\n",
    "    print(f\"  Test data shape: {test_df.shape}\")\n",
    "    print(f\"  Date range: {test_df['timestamp'].min() if 'timestamp' in test_df.columns else 'N/A'} to {test_df['timestamp'].max() if 'timestamp' in test_df.columns else 'N/A'}\")\n",
    "    print(f\"  Symbols: {test_df['tic'].unique()}\")\n",
    "    \n",
    "    return test_env, test_df\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    print(\"üöÄ Starting comprehensive evaluation setup...\")\n",
    "    \n",
    "    # Step 1: Load data and models\n",
    "    df, env_config, trained_models = load_evaluation_setup()\n",
    "    \n",
    "    # Step 2: Create test environment\n",
    "    test_env, test_df = create_safe_test_environment(df, env_config)\n",
    "    \n",
    "    # Step 3: Verify setup\n",
    "    print(f\"\\nüìä Setup Verification:\")\n",
    "    print(f\"  ‚úÖ Data loaded: {df.shape}\")\n",
    "    print(f\"  ‚úÖ Models available: {list(trained_models.keys())}\")\n",
    "    print(f\"  ‚úÖ Test data prepared: {test_df.shape}\")\n",
    "    print(f\"  ‚úÖ Test environment created\")\n",
    "    print(f\"  ‚úÖ Symbols in test set: {test_df['tic'].unique()}\")\n",
    "    \n",
    "    # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÉ‡∏ô cells ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "    SETUP_SUCCESS = True\n",
    "    print(f\"\\nüéâ Evaluation setup completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Setup failed with error: {str(e)}\")\n",
    "    print(\"üîß Please check your data and model files\")\n",
    "    import traceback\n",
    "    print(\"üìã Full error traceback:\")\n",
    "    traceback.print_exc()\n",
    "    SETUP_SUCCESS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• Models ‡∏ö‡∏ô Test Data\n",
    "\n",
    "def evaluate_model_performance(model_info, test_env, test_df, model_name):\n",
    "    \"\"\"\n",
    "    ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á model ‡∏ö‡∏ô test data\n",
    "    \"\"\"\n",
    "    print(f\"üìä Evaluating {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # ‡∏£‡∏±‡∏ô prediction\n",
    "        account_value, actions = DRLAgent.DRL_prediction(\n",
    "            model=model_info['model'],\n",
    "            environment=test_env\n",
    "        )\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì performance metrics\n",
    "        initial_value = INITIAL_AMOUNT\n",
    "        final_value = account_value['account_value'].iloc[-1]\n",
    "        total_return = (final_value - initial_value) / initial_value * 100\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Sharpe ratio\n",
    "        returns = account_value['account_value'].pct_change().dropna()\n",
    "        sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Maximum Drawdown\n",
    "        running_max = account_value['account_value'].expanding().max()\n",
    "        drawdown = (account_value['account_value'] - running_max) / running_max\n",
    "        max_drawdown = drawdown.min() * 100\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Volatility\n",
    "        volatility = returns.std() * np.sqrt(252) * 100\n",
    "        \n",
    "        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô trades\n",
    "        total_trades = len(actions[actions != 0]) if len(actions) > 0 else 0\n",
    "        \n",
    "        results = {\n",
    "            'model_name': model_name,\n",
    "            'model_type': model_info['model_type'],\n",
    "            'initial_value': initial_value,\n",
    "            'final_value': final_value,\n",
    "            'total_return': total_return,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'max_drawdown': max_drawdown,\n",
    "            'volatility': volatility,\n",
    "            'total_trades': total_trades,\n",
    "            'account_values': account_value,\n",
    "            'actions': actions,\n",
    "            'daily_returns': returns\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} evaluation completed\")\n",
    "        print(f\"  Total Return: {total_return:.2f}%\")\n",
    "        print(f\"  Sharpe Ratio: {sharpe_ratio:.3f}\")\n",
    "        print(f\"  Max Drawdown: {max_drawdown:.2f}%\")\n",
    "        print(f\"  Final Value: ${final_value:,.2f}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error evaluating {model_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def calculate_buy_hold_baseline(test_df, symbols):\n",
    "    \"\"\"\n",
    "    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Buy & Hold baseline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "    \"\"\"\n",
    "    print(\"üìà Calculating Buy & Hold baseline...\")\n",
    "    \n",
    "    baseline_results = {}\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        symbol_data = test_df[test_df['tic'] == symbol].copy()\n",
    "        \n",
    "        if len(symbol_data) > 0:\n",
    "            # ‡πÉ‡∏ä‡πâ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß\n",
    "            initial_price = symbol_data['close'].iloc[0]\n",
    "            final_price = symbol_data['close'].iloc[-1]\n",
    "            \n",
    "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì return\n",
    "            price_change = (final_price - initial_price) / abs(initial_price) if initial_price != 0 else 0\n",
    "            portfolio_value = INITIAL_AMOUNT * (1 + price_change)\n",
    "            total_return = price_change * 100\n",
    "            \n",
    "            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics ‡∏≠‡∏∑‡πà‡∏ô‡πÜ\n",
    "            returns = symbol_data['close'].pct_change().dropna()\n",
    "            sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0\n",
    "            volatility = returns.std() * np.sqrt(252) * 100\n",
    "            \n",
    "            # Maximum Drawdown\n",
    "            cumulative_returns = (1 + returns).cumprod()\n",
    "            running_max = cumulative_returns.expanding().max()\n",
    "            drawdown = (cumulative_returns - running_max) / running_max\n",
    "            max_drawdown = drawdown.min() * 100\n",
    "            \n",
    "            baseline_results[symbol] = {\n",
    "                'total_return': total_return,\n",
    "                'final_value': portfolio_value,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'max_drawdown': max_drawdown,\n",
    "                'volatility': volatility\n",
    "            }\n",
    "            \n",
    "            print(f\"  {symbol}: {total_return:.2f}% return\")\n",
    "    \n",
    "    return baseline_results\n",
    "\n",
    "# ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠ setup ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)\n",
    "if SETUP_SUCCESS:\n",
    "    print(\"üöÄ Starting model evaluation...\")\n",
    "    \n",
    "    # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏ó‡∏∏‡∏Å models\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    for model_name, model_info in trained_models.items():\n",
    "        results = evaluate_model_performance(model_info, test_env, test_df, model_name)\n",
    "        if results:\n",
    "            evaluation_results[model_name] = results\n",
    "    \n",
    "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì baseline\n",
    "    symbols = test_df['tic'].unique()\n",
    "    baseline_results = calculate_buy_hold_baseline(test_df, symbols)\n",
    "    \n",
    "    print(f\"\\nüìä Evaluation completed:\")\n",
    "    print(f\"  ‚úÖ Models evaluated: {len(evaluation_results)}\")\n",
    "    print(f\"  üìà Baselines calculated: {len(baseline_results)}\")\n",
    "    \n",
    "    EVALUATION_SUCCESS = True\n",
    "else:\n",
    "    print(\"‚ùå Skipping evaluation due to setup failure\")\n",
    "    EVALUATION_SUCCESS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≤‡∏ü Performance\n",
    "\n",
    "def create_performance_comparison():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å models\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating performance comparison...\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "    comparison_data = []\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• RL models\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': results['model_type'],\n",
    "            'Strategy': f\"RL-{results['model_type']}\",\n",
    "            'Total Return (%)': results['total_return'],\n",
    "            'Final Value ($)': results['final_value'],\n",
    "            'Sharpe Ratio': results['sharpe_ratio'],\n",
    "            'Max Drawdown (%)': results['max_drawdown'],\n",
    "            'Volatility (%)': results['volatility'],\n",
    "            'Total Trades': results['total_trades']\n",
    "        })\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Baseline strategies\n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        comparison_data.append({\n",
    "            'Model': f\"Buy&Hold\",\n",
    "            'Strategy': f\"B&H-{symbol}\",\n",
    "            'Total Return (%)': baseline['total_return'],\n",
    "            'Final Value ($)': baseline['final_value'],\n",
    "            'Sharpe Ratio': baseline['sharpe_ratio'],\n",
    "            'Max Drawdown (%)': baseline['max_drawdown'],\n",
    "            'Volatility (%)': baseline['volatility'],\n",
    "            'Total Trades': 1  # Buy once and hold\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    comparison_df = comparison_df.sort_values('Total Return (%)', ascending=False)\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "def plot_performance_summary():\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating performance summary plots...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö plot\n",
    "    model_names = []\n",
    "    model_returns = []\n",
    "    model_sharpe = []\n",
    "    model_drawdown = []\n",
    "    colors = []\n",
    "    \n",
    "    # RL models\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        model_names.append(results['model_type'])\n",
    "        model_returns.append(results['total_return'])\n",
    "        model_sharpe.append(results['sharpe_ratio'])\n",
    "        model_drawdown.append(results['max_drawdown'])\n",
    "        colors.append('skyblue')\n",
    "    \n",
    "    # Baseline\n",
    "    for symbol, baseline in baseline_results.items():\n",
    "        model_names.append(f\"B&H-{symbol}\")\n",
    "        model_returns.append(baseline['total_return'])\n",
    "        model_sharpe.append(baseline['sharpe_ratio'])\n",
    "        model_drawdown.append(baseline['max_drawdown'])\n",
    "        colors.append('lightcoral')\n",
    "    \n",
    "    # Plot 1: Total Returns\n",
    "    bars = axes[0, 0].bar(range(len(model_names)), model_returns, color=colors, alpha=0.7)\n",
    "    axes[0, 0].set_title('Total Returns Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Return (%)')\n",
    "    axes[0, 0].set_xticks(range(len(model_names)))\n",
    "    axes[0, 0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    axes[0, 0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡πÅ‡∏ó‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    for bar, value in zip(bars, model_returns):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + (1 if height > 0 else -3),\n",
    "                       f'{value:.1f}%', ha='center', va='bottom' if height > 0 else 'top', fontsize=9)\n",
    "    \n",
    "    # Plot 2: Sharpe Ratio\n",
    "    bars = axes[0, 1].bar(range(len(model_names)), model_sharpe, color=colors, alpha=0.7)\n",
    "    axes[0, 1].set_title('Sharpe Ratio Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Sharpe Ratio')\n",
    "    axes[0, 1].set_xticks(range(len(model_names)))\n",
    "    axes[0, 1].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    axes[0, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Maximum Drawdown\n",
    "    bars = axes[1, 0].bar(range(len(model_names)), model_drawdown, color=colors, alpha=0.7)\n",
    "    axes[1, 0].set_title('Maximum Drawdown Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Drawdown (%)')\n",
    "    axes[1, 0].set_xticks(range(len(model_names)))\n",
    "    axes[1, 0].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Portfolio Evolution (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ RL models)\n",
    "    for model_name, results in evaluation_results.items():\n",
    "        account_values = results['account_values']['account_value']\n",
    "        axes[1, 1].plot(account_values.values, label=f\"{results['model_type']}\", linewidth=2)\n",
    "    \n",
    "    axes[1, 1].axhline(y=INITIAL_AMOUNT, color='red', linestyle='--', alpha=0.7, label='Initial Value')\n",
    "    axes[1, 1].set_title('Portfolio Value Evolution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Portfolio Value ($)')\n",
    "    axes[1, 1].set_xlabel('Time Steps')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)\n",
    "if SETUP_SUCCESS and EVALUATION_SUCCESS:\n",
    "    print(\"üìä Creating performance reports...\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "    comparison_df = create_performance_comparison()\n",
    "    print(\"\\nüìä Performance Comparison Table:\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    \n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
    "    fig = plot_performance_summary()\n",
    "    plt.show()\n",
    "    \n",
    "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    comparison_df.to_csv(os.path.join(REPORTS_DIR, f'performance_comparison_{timestamp}.csv'), index=False)\n",
    "    fig.savefig(os.path.join(REPORTS_DIR, f'performance_analysis_{timestamp}.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"\\n‚úÖ Reports saved to {REPORTS_DIR}/\")\n",
    "    print(f\"   - performance_comparison_{timestamp}.csv\")\n",
    "    print(f\"   - performance_analysis_{timestamp}.png\")\n",
    "    \n",
    "    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "    if len(evaluation_results) > 0:\n",
    "        best_rl_model = max(evaluation_results.items(), key=lambda x: x[1]['total_return'])\n",
    "        print(f\"\\nüèÜ Best RL Model: {best_rl_model[0]} ({best_rl_model[1]['total_return']:.2f}%)\")\n",
    "    \n",
    "    if len(baseline_results) > 0:\n",
    "        best_baseline = max(baseline_results.items(), key=lambda x: x[1]['total_return'])\n",
    "        print(f\"üìà Best Baseline: {best_baseline[0]} ({best_baseline[1]['total_return']:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nüéØ Summary:\")\n",
    "    print(f\"   Models evaluated: {len(evaluation_results)}\")\n",
    "    print(f\"   Baselines calculated: {len(baseline_results)}\")\n",
    "    print(f\"   Reports generated: ‚úÖ\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Skipping report generation due to evaluation failure\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
