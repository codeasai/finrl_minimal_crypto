import streamlit as st
import os
import sys
from pathlib import Path
from datetime import datetime
import pandas as pd
import random
import numpy as np
import warnings
import json
warnings.filterwarnings('ignore')

# ‡πÄ‡∏û‡∏¥‡πà‡∏° import ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU
import torch
from torch.cuda import is_available as cuda_available
from torch.cuda import device_count as cuda_device_count
from torch.cuda import get_device_name as cuda_get_device_name

# Add project root to Python path
root_path = Path(__file__).parent.parent.parent
sys.path.append(str(root_path))

from config import MODEL_DIR, MODEL_KWARGS, DATA_DIR, INITIAL_AMOUNT, TRANSACTION_COST_PCT, HMAX
from ui.pipeline.agent_manager import get_agent_info, list_agents

# FinRL imports
from finrl.meta.preprocessor.preprocessors import FeatureEngineer
from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv
from finrl.agents.stablebaselines3.models import DRLAgent
from stable_baselines3.common.vec_env import DummyVecEnv

# ‡πÄ‡∏û‡∏¥‡πà‡∏° import ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PPO
from stable_baselines3 import PPO

# Lineage 2 class names
LINEAGE2_CLASSES = [
    "Warcryer", "Overlord", "Warlord", "Gladiator", "Warlock", "Sorcerer",
    "Necromancer", "Warlord", "Gladiator", "Warlock", "Sorcerer", "Necromancer",
    "Bishop", "Prophet", "ElvenElder", "ShillienElder", "Cardinal", "Hierophant",
    "EvaSaint", "ShillienSaint", "Dominator", "Doomcryer", "GrandKhavatari",
    "FortuneSeeker", "Maestro", "Doombringer", "SoulHound", "Trickster",
    "Inspector", "Judicator", "SigelKnight", "TyrrWarrior", "OthellRogue",
    "YulArcher", "FeohWizard", "IssEnchanter", "WynnSummoner", "AeoreHealer"
]

def get_model_info(model_path
):
    """Get model information"""
    if os.path.exists(model_path):
        stats = os.stat(model_path)
        return {
            "last_modified": datetime.fromtimestamp(stats.st_mtime).strftime("%Y-%m-%d %H:%M:%S"),
            "size": f"{stats.st_size/1024:.1f} KB"
        }
    return None

def get_training_params(model_type="PPO", exchange="binance", grade="N"):
    """Get training parameters based on model type, exchange and grade"""
    base_params = {
        "PPO": {
            "learning_rate": 5e-5,
            "n_steps": 1024,
            "batch_size": 128,
            "n_epochs": 5,
            "gamma": 0.99,
            "gae_lambda": 0.95,
            "clip_range": 0.1,
            "max_grad_norm": 0.3,
            "ent_coef": 0.005,
            "vf_coef": 0.3,
            "target_kl": 0.01
        },
        "PPO (Simple)": {
            "learning_rate": 5e-5,
            "batch_size": 128,
            "n_steps": 1024,
            "gamma": 0.99,
            "gae_lambda": 0.95
        }
    }
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞ exchange
    exchange_params = {
        "binance": {
            "min_trade_amount": 0.001,
            "fee": 0.001,
            "max_leverage": 20
        },
        "bybit": {
            "min_trade_amount": 0.001,
            "fee": 0.0006,
            "max_leverage": 100
        },
        "okx": {
            "min_trade_amount": 0.001,
            "fee": 0.0008,
            "max_leverage": 125
        }
    }

    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏° GRADE ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà
    grade_params = {
        "N": {
            "steps": 5000,
            "n_steps": 256,
            "batch_size": 32,
            "n_epochs": 2,
            "learning_rate": 1e-5,
            "show_advanced": False
        },
        "D": {
            "steps": 10000,
            "n_steps": 512,
            "batch_size": 64,
            "n_epochs": 3,
            "learning_rate": 2e-5,
            "show_advanced": False
        },
        "C": {
            "steps": 20000,
            "n_steps": 768,
            "batch_size": 96,
            "n_epochs": 4,
            "learning_rate": 3e-5,
            "show_advanced": True
        },
        "B": {
            "steps": 30000,
            "n_steps": 1024,
            "batch_size": 128,
            "n_epochs": 5,
            "learning_rate": 4e-5,
            "show_advanced": True
        },
        "A": {
            "steps": 50000,
            "n_steps": 2048,
            "batch_size": 256,
            "n_epochs": 8,
            "learning_rate": 5e-5,
            "show_advanced": True
        },
        "S": {
            "steps": 100000,
            "n_steps": 4096,
            "batch_size": 512,
            "n_epochs": 10,
            "learning_rate": 1e-4,
            "show_advanced": True
        }
    }
    
    params = base_params[model_type].copy()
    params.update(exchange_params[exchange])
    params.update(grade_params[grade])
    return params

def show_continue_training_guide():
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Continue Training"""
    with st.expander("‚ÑπÔ∏è ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Continue Training", expanded=True):
        st.markdown("""
        **‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏° (Continue Training) ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:**
        1. üîÑ ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        2. üìà ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°
        3. ‚è±Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡∏Ñ‡∏±‡∏ô
        
        **‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á:**
        - ‚ö†Ô∏è ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ñ‡πà‡∏≤ Learning Rate ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏∑‡∏°‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô
        - üìä ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        - üíæ ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á checkpoint ‡∏ó‡∏∏‡∏Å‡πÜ Save Interval steps ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏π‡∏ç‡πÄ‡∏™‡∏µ‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        
        **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:**
        1. üìã ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô Evaluate ‡∏Å‡πà‡∏≠‡∏ô
        2. üéØ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≥‡∏ô‡∏ß‡∏ô steps ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°
        3. ‚öôÔ∏è ‡∏õ‡∏£‡∏±‡∏ö parameters ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å)
        4. üîÑ ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° Continue Training ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
        5. üìä ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à
        """)

def calculate_estimated_time(params):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì"""
    total_steps = params['steps']
    steps_per_update = params['n_steps']
    batch_size = params['batch_size']
    n_epochs = params['n_epochs']
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó
    num_updates = total_steps / steps_per_update
    
    # ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡πà‡∏≠‡∏£‡∏≠‡∏ö (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
    time_per_update_cpu = 150  # 2.5 ‡∏ô‡∏≤‡∏ó‡∏µ
    time_per_update_gpu = 37.5  # 0.625 ‡∏ô‡∏≤‡∏ó‡∏µ
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    total_time_cpu = num_updates * time_per_update_cpu
    total_time_gpu = num_updates * time_per_update_gpu
    
    return {
        'cpu_minutes': round(total_time_cpu / 60, 1),
        'gpu_minutes': round(total_time_gpu / 60, 1),
        'num_updates': round(num_updates, 1)
    }

def show_training_parameters(model_type, exchange, grade):
    """‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô"""
    params = get_training_params(model_type, exchange, grade)
    
    with st.expander("üîß Training Parameters", expanded=True):
        # Exchange Information
        st.markdown(f"""
        ### üìä Exchange Information
        - Exchange: {exchange.upper()}
        - Minimum Trade Amount: {params['min_trade_amount']} BTC
        - Trading Fee: {params['fee']*100}%
        - Maximum Leverage: {params['max_leverage']}x
        """)
        
        col1, col2 = st.columns(2)
        with col1:
            steps = st.number_input(
                "Training Steps",
                min_value=1000,
                value=params['steps'],
                step=1000,
                help="More steps = better training but takes longer"
            )
        with col2:
            save_interval = st.number_input(
                "Save Interval (steps)",
                min_value=1000,
                value=5000,
                step=1000,
                help="How often to save checkpoints during training"
            )
        
        # Advanced options
        if params['show_advanced']:
            if st.checkbox("üîç Show Advanced Options"):
                st.warning("""
                ‚ö†Ô∏è **‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô:** ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏à‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• 
                ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡∏Å‡πà‡∏≠‡∏ô
                """)
                
                st.markdown("### üéØ Model Parameters")
                col1, col2 = st.columns(2)
                with col1:
                    learning_rate = st.number_input(
                        "Learning Rate",
                        min_value=1e-6,
                        max_value=1e-2,
                        value=params['learning_rate'],
                        format="%.0e",
                        help="Model's learning rate"
                    )
                    n_steps = st.number_input(
                        "Steps per Update",
                        min_value=512,
                        max_value=4096,
                        value=params['n_steps'],
                        step=512,
                        help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô steps ‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó"
                    )
                    batch_size = st.number_input(
                        "Batch Size",
                        min_value=32,
                        max_value=512,
                        value=params['batch_size'],
                        step=32,
                        help="Training batch size"
                    )
                with col2:
                    n_epochs = st.number_input(
                        "Number of Epochs",
                        min_value=1,
                        max_value=20,
                        value=params['n_epochs'],
                        step=1,
                        help="‡∏à‡∏≥‡∏ô‡∏ß‡∏ô epochs ‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó"
                    )
                    gamma = st.number_input(
                        "Gamma (Discount Factor)",
                        min_value=0.8,
                        max_value=0.999,
                        value=params['gamma'],
                        step=0.001,
                        help="Discount factor for future rewards"
                    )
                    gae_lambda = st.number_input(
                        "GAE Lambda",
                        min_value=0.8,
                        max_value=0.999,
                        value=params['gae_lambda'],
                        step=0.001,
                        help="GAE parameter"
                    )
                
                st.markdown("### ‚öñÔ∏è Environment Parameters")
                col1, col2 = st.columns(2)
                with col1:
                    reward_scaling = st.slider(
                        "Reward Scaling",
                        min_value=1e-5,
                        max_value=1e-2,
                        value=1e-4,
                        format="%.0e",
                        help="‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á reward"
                    )
                    clip_range = st.slider(
                        "Clip Range",
                        min_value=0.1,
                        max_value=0.5,
                        value=params['clip_range'],
                        step=0.1,
                        help="PPO clip range"
                    )
                with col2:
                    ent_coef = st.slider(
                        "Entropy Coefficient",
                        min_value=0.0,
                        max_value=0.1,
                        value=params['ent_coef'],
                        step=0.001,
                        help="Entropy coefficient for exploration"
                    )
                    vf_coef = st.slider(
                        "Value Function Coefficient",
                        min_value=0.1,
                        max_value=1.0,
                        value=params['vf_coef'],
                        step=0.1,
                        help="Value function coefficient"
                    )
                
                print_verbosity = st.selectbox(
                    "Print Verbosity",
                    [1, 2],
                    index=1,
                    help="‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (2 = ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î)"
                )
                
                # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ
                estimated_time = calculate_estimated_time({
                    'steps': steps,
                    'n_steps': n_steps if 'n_steps' in locals() else params['n_steps'],
                    'batch_size': batch_size if 'batch_size' in locals() else params['batch_size'],
                    'n_epochs': n_epochs if 'n_epochs' in locals() else params['n_epochs']
                })
                
                st.info(f"""
                ‚è±Ô∏è ‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô:
                - CPU: {estimated_time['cpu_minutes']} ‡∏ô‡∏≤‡∏ó‡∏µ
                - GPU: {estimated_time['gpu_minutes']} ‡∏ô‡∏≤‡∏ó‡∏µ
                - ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó: {estimated_time['num_updates']} ‡∏£‡∏≠‡∏ö
                """)
    
    return {
        "steps": steps,
        "save_interval": save_interval,
        "learning_rate": learning_rate if 'learning_rate' in locals() else params['learning_rate'],
        "n_steps": n_steps if 'n_steps' in locals() else params['n_steps'],
        "batch_size": batch_size if 'batch_size' in locals() else params['batch_size'],
        "n_epochs": n_epochs if 'n_epochs' in locals() else params['n_epochs'],
        "gamma": gamma if 'gamma' in locals() else params['gamma'],
        "gae_lambda": gae_lambda if 'gae_lambda' in locals() else params['gae_lambda'],
        "clip_range": clip_range if 'clip_range' in locals() else params['clip_range'],
        "ent_coef": ent_coef if 'ent_coef' in locals() else params['ent_coef'],
        "vf_coef": vf_coef if 'vf_coef' in locals() else params['vf_coef'],
        "reward_scaling": reward_scaling if 'reward_scaling' in locals() else 1e-4,
        "print_verbosity": print_verbosity if 'print_verbosity' in locals() else 2
    }

def add_technical_indicators(df):
    """‡πÄ‡∏û‡∏¥‡πà‡∏° technical indicators ‡πÅ‡∏•‡∏∞ normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ inf/nan"""
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏≥‡πÄ‡∏ô‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    df = df.copy()
    
    print("‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Technical Indicators...")
    
    # 1. Moving Averages
    print("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Moving Averages...")
    df['sma_20'] = df.groupby('tic')['close'].transform(lambda x: x.rolling(window=20, min_periods=1).mean())
    df['ema_20'] = df.groupby('tic')['close'].transform(lambda x: x.ewm(span=20, adjust=False).mean())
    
    # 2. RSI (Relative Strength Index)
    print("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RSI...")
    def calculate_rsi(group):
        delta = group['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
        
        # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ 0
        rs = gain / (loss + 1e-10)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡πà‡∏≤‡πÄ‡∏•‡πá‡∏Å‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ 0
        rsi = 100 - (100 / (1 + rs))
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤ RSI ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0-100
        rsi = rsi.clip(0, 100)
        return rsi
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RSI ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° tic
    rsi_values = []
    for tic in df['tic'].unique():
        tic_data = df[df['tic'] == tic].copy()
        rsi = calculate_rsi(tic_data)
        rsi_values.extend(rsi.values)
    df['rsi_14'] = rsi_values
    
    # 3. MACD
    print("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì MACD...")
    def calculate_macd(group):
        exp1 = group['close'].ewm(span=12, adjust=False).mean()
        exp2 = group['close'].ewm(span=26, adjust=False).mean()
        macd = exp1 - exp2
        signal = macd.ewm(span=9, adjust=False).mean()
        hist = macd - signal
        return pd.DataFrame({
            'macd': macd,
            'macd_signal': signal,
            'macd_hist': hist
        })
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì MACD ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° tic
    macd_dfs = []
    for tic in df['tic'].unique():
        tic_data = df[df['tic'] == tic].copy()
        macd_result = calculate_macd(tic_data)
        macd_dfs.append(macd_result)
    
    macd_df = pd.concat(macd_dfs, ignore_index=True)
    df['macd'] = macd_df['macd'].values
    df['macd_signal'] = macd_df['macd_signal'].values
    df['macd_hist'] = macd_df['macd_hist'].values
    
    # 4. Bollinger Bands
    print("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Bollinger Bands...")
    df['bb_middle'] = df.groupby('tic')['close'].transform(lambda x: x.rolling(window=20, min_periods=1).mean())
    df['bb_std'] = df.groupby('tic')['close'].transform(lambda x: x.rolling(window=20, min_periods=1).std())
    
    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô std = 0
    df['bb_std'] = df['bb_std'].fillna(0)
    df['bb_std'] = df['bb_std'].replace(0, df['bb_std'].mean())
    
    df['bb_upper'] = df['bb_middle'] + (df['bb_std'] * 2)
    df['bb_lower'] = df['bb_middle'] - (df['bb_std'] * 2)
    
    # 5. Volume Indicators
    print("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Volume Indicators...")
    df['volume_sma_20'] = df.groupby('tic')['volume'].transform(lambda x: x.rolling(window=20, min_periods=1).mean())
    
    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ 0 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö volume_ratio
    df['volume_ratio'] = df['volume'] / (df['volume_sma_20'] + 1e-10)
    df['volume_ratio'] = df['volume_ratio'].clip(0, 100)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏™‡∏π‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
    
    print("‡πÄ‡∏£‡∏¥‡πà‡∏° Normalization...")
    
    # Normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤ - ‡πÉ‡∏ä‡πâ Min-Max scaling ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ñ‡πà‡∏≤‡∏•‡∏ö
    price_cols = ['open', 'high', 'low', 'close']
    for col in price_cols:
        print(f"Normalize {col}...")
        
        def minmax_normalize(x):
            # ‡πÉ‡∏ä‡πâ Min-Max scaling ‡πÅ‡∏ó‡∏ô Z-score ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ñ‡πà‡∏≤‡∏•‡∏ö
            min_val = x.min()
            max_val = x.max()
            
            if min_val == max_val:
                # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô‡∏´‡∏°‡∏î ‡πÉ‡∏´‡πâ return 0.5 (‡∏Å‡∏•‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á 0-1)
                return pd.Series(0.5, index=x.index)
            
            # Min-Max scaling ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0-1
            normalized = (x - min_val) / (max_val - min_val)
            return normalized
        
        df[col] = df.groupby('tic')[col].transform(minmax_normalize)
    
    # Normalize volume
    print("Normalize volume...")
    def safe_normalize_volume(x):
        mean_val = x.mean()
        std_val = x.std()
        if std_val == 0 or pd.isna(std_val):
            return pd.Series(0, index=x.index)
        return (x - mean_val) / std_val
    
    df['volume'] = df.groupby('tic')['volume'].transform(safe_normalize_volume)
    
    # Normalize technical indicators
    print("Normalize Technical Indicators...")
    indicator_cols = ['sma_20', 'ema_20', 'rsi_14', 'macd', 'macd_signal', 'macd_hist',
                     'bb_middle', 'bb_std', 'bb_upper', 'bb_lower', 'volume_sma_20', 'volume_ratio']
    
    for col in indicator_cols:
        if col in df.columns:
            print(f"Normalize {col}...")
            
            def safe_normalize(x):
                mean_val = x.mean()
                std_val = x.std()
                
                if pd.isna(mean_val) or pd.isna(std_val) or std_val == 0:
                    return pd.Series(0, index=x.index)
                
                normalized = (x - mean_val) / std_val
                
                # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                normalized = normalized.clip(-10, 10)
                return normalized
            
            df[col] = df.groupby('tic')[col].transform(safe_normalize)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤ inf, -inf, ‡πÅ‡∏•‡∏∞ nan
    print("‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤ inf/nan...")
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤ inf ‡πÅ‡∏•‡∏∞ -inf ‡∏î‡πâ‡∏ß‡∏¢ 0
    df = df.replace([np.inf, -np.inf], 0)
    
    # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤ nan ‡∏î‡πâ‡∏ß‡∏¢ 0
    df = df.fillna(0)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
    inf_count = df.isin([np.inf, -np.inf]).sum().sum()
    nan_count = df.isna().sum().sum()
    
    print(f"‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - inf: {inf_count}, nan: {nan_count}")
    
    if inf_count > 0 or nan_count > 0:
        print("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡∏û‡∏ö inf ‡∏´‡∏£‡∏∑‡∏≠ nan ‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç")
        # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
        for col in df.columns:
            if df[col].dtype in ['float64', 'float32']:
                df[col] = df[col].replace([np.inf, -np.inf], 0)
                df[col] = df[col].fillna(0)
    
    print("‚úÖ Technical Indicators ‡πÅ‡∏•‡∏∞ Normalization ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    return df


def safe_normalize_by_group(df, columns, group_col='tic'):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢"""
    for col in columns:
        if col in df.columns:
            def safe_normalize(x):
                if len(x) == 0:
                    return x
                    
                mean_val = x.mean()
                std_val = x.std()
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏õ‡∏Å‡∏ï‡∏¥
                if pd.isna(mean_val) or pd.isna(std_val) or std_val == 0:
                    return pd.Series(0, index=x.index)
                
                # Normalize
                normalized = (x - mean_val) / std_val
                
                # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏™‡∏∏‡∏î‡πÇ‡∏ï‡πà‡∏á
                normalized = normalized.clip(-5, 5)
                
                return normalized
            
            df[col] = df.groupby(group_col)[col].transform(safe_normalize)
    
    return df

def prepare_data_for_training(df):
    """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ 0 ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏•‡∏ö"""
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà FinRL ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        processed_df = pd.DataFrame()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        if 'timestamp' in df.columns:
            processed_df['date'] = pd.to_datetime(df['timestamp']).dt.strftime('%Y-%m-%d')
        elif 'date' in df.columns:
            processed_df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
        else:
            raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå timestamp ‡∏´‡∏£‡∏∑‡∏≠ date ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå symbol
        if 'tic' in df.columns:
            processed_df['tic'] = df['tic']
        elif 'symbol' in df.columns:
            processed_df['tic'] = df['symbol']
        else:
            raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå symbol ‡∏´‡∏£‡∏∑‡∏≠ tic ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        # ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏•‡∏∞ volume
        price_cols = ['open', 'high', 'low', 'close', 'volume']
        for col in price_cols:
            if col in df.columns:
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô float ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
                processed_df[col] = pd.to_numeric(df[col], errors='coerce')
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
                print(f"=== ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå {col} ===")
                print(f"‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î: {processed_df[col].min()}")
                print(f"‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {processed_df[col].max()}")
                print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô NaN: {processed_df[col].isna().sum()}")
                print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡πà‡∏≤ <= 0: {(processed_df[col] <= 0).sum()}")
                
                # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≤ NaN ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
                if processed_df[col].isna().any():
                    print(f"‡∏û‡∏ö NaN ‡πÉ‡∏ô {col}, ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢")
                    mean_values = processed_df.groupby('tic')[col].transform('mean')
                    processed_df[col] = processed_df[col].fillna(mean_values)
                
                # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤ ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ 0 ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏•‡∏ö
                if col != 'volume':  
                    zero_negative_mask = (processed_df[col] <= 0)
                    if zero_negative_mask.any():
                        print(f"‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ <= 0 ‡πÉ‡∏ô {col}: {zero_negative_mask.sum()} ‡πÅ‡∏ñ‡∏ß")
                        
                        # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
                        for tic in processed_df['tic'].unique():
                            tic_mask = processed_df['tic'] == tic
                            tic_data = processed_df[tic_mask].copy()
                            
                            # ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô tic ‡∏ô‡∏µ‡πâ
                            problem_mask = tic_mask & zero_negative_mask
                            
                            if problem_mask.any():
                                print(f"‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô {tic} ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {col}")
                                
                                # ‡πÉ‡∏ä‡πâ forward fill ‡πÅ‡∏•‡∏∞ backward fill
                                tic_series = processed_df.loc[tic_mask, col].copy()
                                tic_series = tic_series.replace(0, np.nan)  # ‡πÅ‡∏õ‡∏•‡∏á 0 ‡πÄ‡∏õ‡πá‡∏ô NaN
                                tic_series = tic_series.mask(tic_series <= 0, np.nan)  # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡πÄ‡∏õ‡πá‡∏ô NaN
                                
                                # Forward fill ‡πÅ‡∏•‡πâ‡∏ß backward fill
                                tic_series = tic_series.fillna(method='ffill')
                                tic_series = tic_series.fillna(method='bfill')
                                
                                # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏µ NaN ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                                if tic_series.isna().any():
                                    global_mean = processed_df[processed_df[col] > 0][col].mean()
                                    tic_series = tic_series.fillna(global_mean)
                                    print(f"‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ global: {global_mean}")
                                
                                # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏±‡∏ö
                                processed_df.loc[tic_mask, col] = tic_series.values
                        
                        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
                        remaining_problems = (processed_df[col] <= 0).sum()
                        if remaining_problems > 0:
                            print(f"‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô {col}: {remaining_problems} ‡πÅ‡∏ñ‡∏ß")
                            # ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                            global_mean = processed_df[processed_df[col] > 0][col].mean()
                            processed_df.loc[processed_df[col] <= 0, col] = global_mean
                            print(f"‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {global_mean}")
                        else:
                            print(f"‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç {col} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                            
                else:  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö volume
                    # Volume ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡πá‡∏ô 0 ‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏¥‡∏î‡∏•‡∏ö
                    negative_mask = (processed_df[col] < 0)
                    if negative_mask.any():
                        print(f"‡∏û‡∏ö volume ‡∏ï‡∏¥‡∏î‡∏•‡∏ö: {negative_mask.sum()} ‡πÅ‡∏ñ‡∏ß - ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢ 0")
                        processed_df.loc[negative_mask, col] = 0
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
                print(f"‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î: {processed_df[col].min()}, ‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î: {processed_df[col].max()}")
                print()
                        
            else:
                raise ValueError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå {col} ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ OHLC
        print("=== ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ OHLC ===")
        for tic in processed_df['tic'].unique():
            tic_mask = processed_df['tic'] == tic
            tic_data = processed_df[tic_mask].copy()
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ high >= max(open, close, low)
            max_price = tic_data[['open', 'close', 'low']].max(axis=1)
            high_issue_mask = (tic_data['high'] < max_price)
            if high_issue_mask.any():
                print(f"‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç high ‡πÉ‡∏ô {tic}: {high_issue_mask.sum()} ‡πÅ‡∏ñ‡∏ß")
                processed_df.loc[tic_mask & tic_data.index.isin(tic_data[high_issue_mask].index), 'high'] = max_price[high_issue_mask]
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ low <= min(open, close, high)
            min_price = tic_data[['open', 'close', 'high']].min(axis=1)
            low_issue_mask = (tic_data['low'] > min_price)
            if low_issue_mask.any():
                print(f"‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç low ‡πÉ‡∏ô {tic}: {low_issue_mask.sum()} ‡πÅ‡∏ñ‡∏ß")
                processed_df.loc[tic_mask & tic_data.index.isin(tic_data[low_issue_mask].index), 'low'] = min_price[low_issue_mask]
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ open, close ‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á high ‡πÅ‡∏•‡∏∞ low
            high_val = processed_df.loc[tic_mask, 'high']
            low_val = processed_df.loc[tic_mask, 'low']
            
            # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç open
            open_high_mask = (processed_df.loc[tic_mask, 'open'] > high_val)
            open_low_mask = (processed_df.loc[tic_mask, 'open'] < low_val)
            if open_high_mask.any() or open_low_mask.any():
                print(f"‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç open ‡πÉ‡∏ô {tic}: {(open_high_mask | open_low_mask).sum()} ‡πÅ‡∏ñ‡∏ß")
                # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á high ‡πÅ‡∏•‡∏∞ low
                processed_df.loc[tic_mask & (open_high_mask | open_low_mask), 'open'] = (high_val + low_val) / 2
            
            # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç close
            close_high_mask = (processed_df.loc[tic_mask, 'close'] > high_val)
            close_low_mask = (processed_df.loc[tic_mask, 'close'] < low_val)
            if close_high_mask.any() or close_low_mask.any():
                print(f"‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç close ‡πÉ‡∏ô {tic}: {(close_high_mask | close_low_mask).sum()} ‡πÅ‡∏ñ‡∏ß")
                processed_df.loc[tic_mask & (close_high_mask | close_low_mask), 'close'] = (high_val + low_val) / 2
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° technical indicators
        print("=== ‡πÄ‡∏û‡∏¥‡πà‡∏° Technical Indicators ===")
        processed_df = add_technical_indicators(processed_df)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        print("=== ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ===")
        data_ready, message = check_training_data(processed_df)
        if not data_ready:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°: {message}")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠ debug
            price_cols = ['open', 'high', 'low', 'close']
            for col in price_cols:
                problematic = processed_df[processed_df[col] <= 0]
                if len(problematic) > 0:
                    print(f"‚ùå ‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô {col}:")
                    print(problematic[['date', 'tic', col]].head())
            
            raise ValueError(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô: {message}")
        else:
            print(f"‚úÖ {message}")
        
        return processed_df
        
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}")
        raise ValueError(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}")


def check_training_data(df):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö normalized data"""
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        required_columns = ['date', 'tic', 'open', 'high', 'low', 'close', 'volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return False, f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: {', '.join(missing_columns)}"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤ NaN
        nan_counts = df[required_columns].isna().sum()
        if nan_counts.any():
            return False, f"‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ NaN ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {', '.join(nan_counts[nan_counts > 0].index)}"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤ inf
        inf_counts = df[required_columns].isin([np.inf, -np.inf]).sum()
        if inf_counts.any():
            return False, f"‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ inf ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: {', '.join(inf_counts[inf_counts > 0].index)}"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if len(df) < 100:
            return False, "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 100 ‡πÅ‡∏ñ‡∏ß)"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å normalize ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        price_cols = ['open', 'high', 'low', 'close']
        is_normalized = False
        
        for col in price_cols:
            # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 0-1 ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏•‡∏ö ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏ñ‡∏π‡∏Å normalize ‡πÅ‡∏•‡πâ‡∏ß
            if (df[col].min() >= 0 and df[col].max() <= 1) or (df[col] < 0).any():
                is_normalized = True
                break
        
        if is_normalized:
            print("‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô normalization ‡πÅ‡∏•‡πâ‡∏ß")
            # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà normalize ‡πÅ‡∏•‡πâ‡∏ß ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏Ñ‡πà‡∏Ñ‡πà‡∏≤ finite
            for col in price_cols:
                if not np.isfinite(df[col]).all():
                    return False, f"‡∏û‡∏ö‡∏Ñ‡πà‡∏≤ invalid ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå {col}"
        else:
            print("‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô normalization")
            # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤‡∏•‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏®‡∏π‡∏ô‡∏¢‡πå
            for col in price_cols:
                if (df[col] <= 0).any():
                    zero_or_negative = (df[col] <= 0)
                    problematic_rows = df[zero_or_negative]
                    print(f"‚ùå ‡∏û‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô {col}:")
                    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß: {zero_or_negative.sum()}")
                    print("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤:")
                    print(problematic_rows[['date', 'tic', col]].head())
                    return False, f"‡∏û‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤ 0 ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå {col}"
        
        return True, "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô"
        
    except Exception as e:
        print(f"‚ùå Error ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}")
        return False, f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {str(e)}"

def create_trading_env(df, initial_amount=INITIAL_AMOUNT, params=None):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á trading environment"""
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô train/test ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô 80/20
    train_size = int(len(df) * 0.8)
    train_df = df.iloc[:train_size].reset_index(drop=True)
    test_df = df.iloc[train_size:].reset_index(drop=True)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    for data in [train_df, test_df]:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå timestamp ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if 'timestamp' not in data.columns:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ timestamp ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå date ‡πÅ‡∏ó‡∏ô
            if 'date' in data.columns:
                data['timestamp'] = pd.to_datetime(data['date'])
            else:
                raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå timestamp ‡∏´‡∏£‡∏∑‡∏≠ date ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        
        # ‡πÅ‡∏õ‡∏•‡∏á timestamp ‡πÄ‡∏õ‡πá‡∏ô datetime
        data['timestamp'] = pd.to_datetime(data['timestamp'])
        data['date'] = data['timestamp'].dt.strftime('%Y-%m-%d')
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        data.sort_values(['date', 'tic'], inplace=True)
        data.reset_index(drop=True, inplace=True)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î indicators ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
    indicators = [
        'sma_20', 'ema_20', 'rsi_14', 
        'macd', 'macd_signal', 'macd_hist',
        'bb_middle', 'bb_std', 'bb_upper', 'bb_lower',
        'volume_sma_20', 'volume_ratio'
    ]
    
    # ‡πÉ‡∏ä‡πâ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å UI ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    reward_scaling = params['reward_scaling'] if params else 1e-4
    print_verbosity = params['print_verbosity'] if params else 2
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á environment ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö training
    env_kwargs = {
        "hmax": HMAX,
        "initial_amount": initial_amount,
        "num_stock_shares": [0] * len(df['tic'].unique()),
        "buy_cost_pct": [TRANSACTION_COST_PCT] * len(df['tic'].unique()),
        "sell_cost_pct": [TRANSACTION_COST_PCT] * len(df['tic'].unique()),
        "state_space": 1 + 2 * len(df['tic'].unique()) + len(df['tic'].unique()) * len(indicators),
        "stock_dim": len(df['tic'].unique()),
        "tech_indicator_list": indicators,
        "action_space": len(df['tic'].unique()),
        "reward_scaling": reward_scaling,
        "print_verbosity": print_verbosity
    }
    
    train_env = StockTradingEnv(df=train_df, **env_kwargs)
    test_env = StockTradingEnv(df=test_df, **env_kwargs)
    
    return train_env, test_env, train_df, test_df

def check_gpu_availability():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU"""
    gpu_info = {
        "available": False,
        "count": 0,
        "devices": [],
        "memory": []
    }
    
    if cuda_available():
        gpu_info["available"] = True
        gpu_info["count"] = cuda_device_count()
        
        for i in range(gpu_info["count"]):
            device_name = cuda_get_device_name(i)
            gpu_info["devices"].append(device_name)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ GPU
            try:
                memory_allocated = torch.cuda.memory_allocated(i) / 1024**2  # MB
                memory_reserved = torch.cuda.memory_reserved(i) / 1024**2    # MB
                gpu_info["memory"].append({
                    "allocated": round(memory_allocated, 2),
                    "reserved": round(memory_reserved, 2)
                })
            except:
                gpu_info["memory"].append({
                    "allocated": "N/A",
                    "reserved": "N/A"
                })
    
    return gpu_info

def show_gpu_info():
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GPU ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô UI"""
    gpu_info = check_gpu_availability()
    
    if gpu_info["available"]:
        st.success(f"‚úÖ GPU ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô: ‡∏û‡∏ö {gpu_info['count']} GPU")
        
        for i in range(gpu_info["count"]):
            with st.expander(f"GPU {i+1}: {gpu_info['devices'][i]}", expanded=True):
                memory = gpu_info["memory"][i]
                st.markdown(f"""
                - üéÆ ‡∏ä‡∏∑‡πà‡∏≠: {gpu_info['devices'][i]}
                - üíæ ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: {memory['allocated']} MB
                - üì¶ ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ó‡∏µ‡πà‡∏à‡∏≠‡∏á: {memory['reserved']} MB
                """)
    else:
        st.warning("""
        ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GPU ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ
        - ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏∞‡πÉ‡∏ä‡πâ CPU ‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡∏Å‡∏ß‡πà‡∏≤
        - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ GPU ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ steps ‡∏°‡∏≤‡∏Å
        """)

def check_gpu_readiness():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á GPU ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô"""
    try:
        gpu_info = check_gpu_availability()
        
        if not gpu_info["available"]:
            return {
                'ready': False,
                'message': "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GPU ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ",
                'details': "‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏à‡∏∞‡πÉ‡∏ä‡πâ CPU ‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡∏Å‡∏ß‡πà‡∏≤"
            }
            
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ GPU
        for i, memory in enumerate(gpu_info["memory"]):
            if isinstance(memory['allocated'], (int, float)) and memory['allocated'] > 0:
                return {
                    'ready': False,
                    'message': f"‚ö†Ô∏è GPU {i+1} ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà",
                    'details': f"‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: {memory['allocated']} MB"
                }
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö CUDA version
        cuda_version = torch.version.cuda
        if not cuda_version:
            return {
                'ready': False,
                'message': "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö CUDA version",
                'details': "‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô GPU"
            }
            
        return {
            'ready': True,
            'message': f"‚úÖ GPU ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô: {gpu_info['count']} GPU",
            'details': f"CUDA Version: {cuda_version}",
            'gpu_info': gpu_info
        }
    except Exception as e:
        return {
            'ready': False,
            'message': "‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö GPU",
            'details': str(e)
        }

def get_next_version_name(model_path):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"""
    try:
        # ‡πÅ‡∏¢‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•
        base_name = os.path.splitext(model_path)[0]
        ext = os.path.splitext(model_path)[1]
        
        # ‡∏´‡∏≤‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        version = 1
        while os.path.exists(f"{base_name}_v{version}{ext}"):
            version += 1
            
        return f"{base_name}_v{version}{ext}"
    except Exception as e:
        print(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô: {str(e)}")
        return None

def save_model_with_version(model, model_path):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô"""
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà
        new_model_path = get_next_version_name(model_path)
        if not new_model_path:
            return False, "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if not os.access(os.path.dirname(new_model_path), os.W_OK):
            return False, "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå"
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
        model.save(new_model_path)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏à‡∏£‡∏¥‡∏á
        if not os.path.exists(new_model_path):
            return False, "‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å"
        
        return True, new_model_path
    except Exception as e:
        return False, f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {str(e)}"

def train_model(env, model_type, params, total_timesteps, model_path=None):
    """‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á GPU
        gpu_status = check_gpu_readiness()
        
        if not gpu_status['ready']:
            st.warning(f"""
            {gpu_status['message']}
            {gpu_status['details']}
            
            ‚ö†Ô∏è **‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô:** ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πâ‡∏ß‡∏¢ steps ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50,000 ‡∏ö‡∏ô CPU ‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡∏°‡∏≤‡∏Å
            ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ:
            1. ‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô steps ‡∏•‡∏á
            2. ‡πÉ‡∏ä‡πâ GPU ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
            3. ‡πÅ‡∏ö‡πà‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≠‡∏ö
            """)
            if not st.checkbox("‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠"):
                return None
        else:
            st.success(f"""
            {gpu_status['message']}
            {gpu_status['details']}
            """)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if hasattr(env, 'df'):
            data_ready, message = check_training_data(env.df)
            if not data_ready:
                st.error(f"‚ùå {message}")
                return None
            st.success(f"‚úÖ {message}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á agent
        agent = DRLAgent(env=env)
        
        # ‡πÉ‡∏ä‡πâ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏à‡∏≤‡∏Å UI
        PPO_PARAMS = {
            'learning_rate': params['learning_rate'],
            'n_steps': params['n_steps'],
            'batch_size': params['batch_size'],
            'n_epochs': params['n_epochs'],
            'gamma': params['gamma'],
            'gae_lambda': params['gae_lambda'],
            'clip_range': params['clip_range'],
            'max_grad_norm': params['max_grad_norm'],
            'ent_coef': params['ent_coef'],
            'vf_coef': params['vf_coef'],
            'target_kl': params['target_kl'],
            'device': 'cuda' if gpu_status['ready'] else 'cpu'
        }
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ
        st.info(f"""
        üéØ ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô:
        - Learning Rate: {PPO_PARAMS['learning_rate']}
        - Steps per Update: {PPO_PARAMS['n_steps']}
        - Batch Size: {PPO_PARAMS['batch_size']}
        - Number of Epochs: {PPO_PARAMS['n_epochs']}
        - Gamma: {PPO_PARAMS['gamma']}
        - GAE Lambda: {PPO_PARAMS['gae_lambda']}
        - Clip Range: {PPO_PARAMS['clip_range']}
        - Max Grad Norm: {PPO_PARAMS['max_grad_norm']}
        - Entropy Coefficient: {PPO_PARAMS['ent_coef']}
        - Value Function Coefficient: {PPO_PARAMS['vf_coef']}
        - Target KL: {PPO_PARAMS['target_kl']}
        - ‡πÉ‡∏ä‡πâ GPU: {'‚úÖ' if gpu_status['ready'] else '‚ùå'}
        """)
        
        if model_path and os.path.exists(model_path):
            try:
                # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                st.info(f"üîÑ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏à‡∏≤‡∏Å {model_path}")
                model = PPO.load(model_path)
                
                # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå
                model.learning_rate = PPO_PARAMS['learning_rate']
                model.n_steps = PPO_PARAMS['n_steps']
                model.batch_size = PPO_PARAMS['batch_size']
                model.n_epochs = PPO_PARAMS['n_epochs']
                model.gamma = PPO_PARAMS['gamma']
                model.gae_lambda = PPO_PARAMS['gae_lambda']
                model.clip_range = PPO_PARAMS['clip_range']
                model.ent_coef = PPO_PARAMS['ent_coef']
                model.vf_coef = PPO_PARAMS['vf_coef']
                
                st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
            except Exception as e:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°: {str(e)}")
                st.info("üîÑ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡πÅ‡∏ó‡∏ô")
                model = agent.get_model("ppo", model_kwargs=PPO_PARAMS)
        else:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
            model = agent.get_model("ppo", model_kwargs=PPO_PARAMS)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
        trained_model = agent.train_model(
            model=model,
            tb_log_name=f"minimal_crypto_ppo{'_simple' if model_type == 'PPO (Simple)' else ''}",
            total_timesteps=total_timesteps
        )
        
        # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó progress bar
        progress_bar.progress(1.0)
        status_text.text(f"Training progress: 100% | Step: {total_timesteps}/{total_timesteps}")
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà
        if model_path:
            success, result = save_model_with_version(trained_model, model_path)
            if success:
                st.success(f"""
                ‚úÖ Training completed!
                - Model saved as {os.path.basename(result)}
                - Total steps: {total_timesteps}
                - Final learning rate: {trained_model.learning_rate}
                """)
            else:
                st.error(f"‚ùå {result}")
                return None
        else:
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
            try:
                trained_model.save("new_model.zip")
                st.success(f"""
                ‚úÖ Training completed!
                - Model saved as new_model.zip
                - Total steps: {total_timesteps}
                - Final learning rate: {trained_model.learning_rate}
                """)
            except Exception as e:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {str(e)}")
                return None
        
        return trained_model
        
    except Exception as e:
        st.error(f"""
        ‚ùå Error during model training:
        {str(e)}
        
        üîç ‡∏Ç‡πâ‡∏≠‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç:
        1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ GPU
        2. ‡∏•‡∏î batch size ‡∏´‡∏£‡∏∑‡∏≠ n_steps
        3. ‡∏•‡∏î learning rate
        4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
        """)
        return None

def show_training_progress(model_name, steps, save_interval):
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # Training loop simulation
    for i in range(5):  # TODO: Replace with actual training
        progress = (i + 1) * 20
        progress_bar.progress(progress)
        status_text.text(f"Training progress: {progress}% | Step: {(i+1)*steps//5}/{steps}")
        if (i + 1) * steps//5 % save_interval == 0:
            st.info(f"üíæ Saved checkpoint at step {(i+1)*steps//5}")
    
    st.success(f"‚úÖ Training completed! Model saved as {model_name}")
    
    # Show next steps
    st.info("""
    üëâ **‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ:**
    1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤ Evaluate ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•
    2. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
    3. ‡∏´‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏û‡∏≠ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ
    """)

def generate_agent_name(symbol, model_type):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠ agent ‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î"""
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå / ‡πÄ‡∏õ‡πá‡∏ô _ ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏Å‡∏∏‡∏•‡πÄ‡∏á‡∏¥‡∏ô
    symbol = symbol.replace('/', '_')
    # ‡∏™‡∏∏‡πà‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™‡∏à‡∏≤‡∏Å Lineage 2
    random_class = random.choice(LINEAGE2_CLASSES)
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠ agent
    return f"{symbol}-{model_type}-{random_class}"

def get_latest_version(model_name):
    """‡∏´‡∏≤‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà‡πÅ‡∏•‡πâ‡∏ß"""
    try:
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô
        existing_files = [f for f in os.listdir(MODEL_DIR) 
                         if f.startswith(f"{model_name}_v") and f.endswith('.zip')]
        
        if not existing_files:
            return 0
        
        # ‡∏î‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
        versions = []
        for file in existing_files:
            try:
                version = int(file.split('_v')[1].split('.')[0])
                versions.append(version)
            except:
                continue
        
        return max(versions) if versions else 0
    except:
        return 0

def get_next_version_name(model_name):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"""
    current_version = get_latest_version(model_name)
    return f"{model_name}_v{current_version + 1}"

def prepare_training_data(df, params):
    """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô"""
    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    processed_df = prepare_data_for_training(df)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á trading environment
    train_env, test_env, train_df, test_df = create_trading_env(processed_df, params=params)
    
    return train_env, test_env, train_df, test_df

def evaluate_model(model, test_env, initial_amount=INITIAL_AMOUNT):
    """‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    try:
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
        df_account_value, df_actions = DRLAgent.DRL_prediction(
            model=model,
            environment=test_env
        )
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        final_value = df_account_value['account_value'].iloc[-1]
        total_return = (final_value - initial_amount) / initial_amount * 100
        
        return {
            'success': True,
            'account_value': df_account_value,
            'actions': df_actions,
            'final_value': final_value,
            'total_return': total_return
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

def save_model(model, model_path, version=None):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    try:
        if version is not None:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà
            model_name = os.path.basename(model_path)
            next_version_name = get_next_version_name(model_name)
            save_path = os.path.join(MODEL_DIR, next_version_name)
        else:
            save_path = model_path
            
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
        model.save(save_path)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
        train_info = {
            'model_path': save_path,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'version': version if version is not None else 0
        }
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå JSON
        info_path = save_path.replace('.zip', '_info.json')
        with open(info_path, 'w') as f:
            json.dump(train_info, f, indent=4)
            
        return {
            'success': True,
            'path': save_path,
            'version': version if version is not None else 0
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

def train_new_agent(df, model_type, params, exchange):
    """‡πÄ‡∏ó‡∏£‡∏ô agent ‡πÉ‡∏´‡∏°‡πà"""
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠ agent ‡πÉ‡∏´‡∏°‡πà
        symbol = df['symbol'].unique()[0] if 'symbol' in df.columns else "BTC_USDT"
        agent_name = generate_agent_name(symbol, model_type)
        model_name = f"minimal_crypto_{agent_name}"
        
        if model_name.replace("minimal_crypto_", "") in [f.replace("minimal_crypto_", "") for f in os.listdir(MODEL_DIR) 
                      if f.startswith("minimal_crypto_")] if os.path.exists(MODEL_DIR) else []:
            st.warning(f"‚ö†Ô∏è Model {model_type} for {exchange.upper()} already exists. Training will create a backup.")
        
        st.info(f"üéÆ ‡∏™‡∏£‡πâ‡∏≤‡∏á Agent ‡∏ä‡∏∑‡πà‡∏≠: {agent_name}")
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        train_env, test_env, train_df, test_df = prepare_training_data(df, params)
        
        # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
        with st.spinner("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•..."):
            model = train_model(train_env, model_type, params, params["steps"])
            
            if model is not None:
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
                save_result = save_model(model, os.path.join(MODEL_DIR, model_name))
                if save_result['success']:
                    st.success(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏ó‡∏µ‡πà: {save_result['path']}")
                    
                    # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
                    eval_result = evaluate_model(model, test_env)
                    if eval_result['success']:
                        st.success(f"""
                        üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:
                        - üí∞ ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: ${INITIAL_AMOUNT:,.2f}
                        - üíµ ‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î: ${eval_result['final_value']:,.2f}
                        - üìà ‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô: {eval_result['total_return']:.2f}%
                        """)
                    else:
                        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•: {eval_result['error']}")
                else:
                    st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {save_result['error']}")
            
            show_training_progress(model_name, params["steps"], params["save_interval"])
            
        return {
            'success': True,
            'model_name': model_name
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

def continue_training(df, model_to_continue, model_type, params):
    """‡πÄ‡∏ó‡∏£‡∏ô‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°"""
    try:
        model_name = f"minimal_crypto_{model_to_continue}"
        save_result = {'success': False}  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        train_env, test_env, train_df, test_df = prepare_training_data(df, params)
        
        # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
        with st.spinner("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•..."):
            # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°
            original_model_path = os.path.join(MODEL_DIR, model_name)
            model = train_model(train_env, model_type, params, params["steps"], model_path=original_model_path)
            
            if model is not None:
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà
                save_result = save_model(model, original_model_path, version=True)
                if save_result['success']:
                    st.success(f"""
                    ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:
                    - üìÅ ‡πÑ‡∏ü‡∏•‡πå: {save_result['path']}
                    - üî¢ ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô: v{save_result['version']}
                    """)
                    
                    # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
                    eval_result = evaluate_model(model, test_env)
                    if eval_result['success']:
                        st.success(f"""
                        üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö:
                        - üí∞ ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: ${INITIAL_AMOUNT:,.2f}
                        - üíµ ‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î: ${eval_result['final_value']:,.2f}
                        - üìà ‡∏ú‡∏•‡∏ï‡∏≠‡∏ö‡πÅ‡∏ó‡∏ô: {eval_result['total_return']:.2f}%
                        """)
                    else:
                        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•: {eval_result['error']}")
                else:
                    st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•: {save_result['error']}")
            
            show_training_progress(save_result['path'] if save_result['success'] else model_name, 
                                 params["steps"], params["save_interval"])
            
        return {
            'success': True,
            'model_name': model_name,
            'version': save_result.get('version', 0) if save_result['success'] else 0
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

def train_agent_ui():
    """UI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô agent"""
    st.header("üéØ Train RL Agent")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• GPU
    show_gpu_info()
    
    # Check existing models
    existing_models = [f.replace("minimal_crypto_", "") for f in os.listdir(MODEL_DIR) 
                      if f.startswith("minimal_crypto_")] if os.path.exists(MODEL_DIR) else []
    
    # Training mode selection
    train_mode = st.radio(
        "Training Mode",
        ["Create Agent", "Continue Training"],
        help="Choose whether to create a new agent or continue training an existing one"
    )
    
    # Exchange selection
    exchange = st.selectbox(
        "Select Exchange",
        ["binance", "bybit", "okx"],
        help="Select the exchange to train the agent for"
    )

    # Grade selection
    grade = st.selectbox(
        "Training Grade",
        ["N", "D", "C", "B", "A", "S"],
        help="""Select training grade:
        N = Basic test (minimal parameters)
        D = Development grade
        C = Standard grade
        B = Advanced grade
        A = Professional grade (50,000 steps)
        S = Master grade (100,000 steps)"""
    )

    # Data file selection
    data_files = [f for f in os.listdir(DATA_DIR) if f.endswith('.csv')] if os.path.exists(DATA_DIR) else []
    if not data_files:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô")
        return

    selected_data_file = st.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô",
        data_files,
        help="‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô"
    )

    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    if selected_data_file:
        file_path = os.path.join(DATA_DIR, selected_data_file)
        try:
            df = pd.read_csv(file_path)
            st.info(f"""
            üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:
            - üìÑ ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå: {selected_data_file}
            - üìÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(df):,} ‡πÅ‡∏ñ‡∏ß
            - üí± ‡∏™‡∏Å‡∏∏‡∏•‡πÄ‡∏á‡∏¥‡∏ô: {', '.join(df['symbol'].unique()) if 'symbol' in df.columns else 'N/A'}
            - ‚è±Ô∏è ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤: {df['timestamp'].min() if 'timestamp' in df.columns else 'N/A'} ‡∏ñ‡∏∂‡∏á {df['timestamp'].max() if 'timestamp' in df.columns else 'N/A'}
            """)
        except Exception as e:
            st.error(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå: {str(e)}")
            return
    
    if train_mode == "Continue Training":
        if not existing_models:
            st.warning("‚ö†Ô∏è No existing models found. Please create a new agent first.")
            return
            
        # Model selection for continuing training
        model_to_continue = st.selectbox(
            "Select Model to Continue Training",
            existing_models,
            help="Choose an existing model to continue training"
        )
        
        # Show existing model info
        model_path = os.path.join(MODEL_DIR, f"minimal_crypto_{model_to_continue}")
        model_info = get_model_info(model_path)
        if model_info:
            st.info(f"üìù Last trained: {model_info['last_modified']} | Size: {model_info['size']}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        current_version = get_latest_version(f"minimal_crypto_{model_to_continue}")
        st.info(f"üìå ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô: v{current_version}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        next_version_name = get_next_version_name(f"minimal_crypto_{model_to_continue}")
        st.success(f"üíæ ‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô: {next_version_name}")
        
        # Use the same type as the existing model
        model_type = "PPO (Simple)" if "simple" in model_to_continue else "PPO"
        st.write(f"Model Type: {model_type}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
        st.info("""
        üí° **‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ parameters ‡πÄ‡∏î‡∏¥‡∏° 
        ‡∏´‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏û‡∏≠‡πÉ‡∏à ‡∏Ñ‡πà‡∏≠‡∏¢‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        """)
        
    else:  # Create Agent
        # Model type selection
        model_type = st.selectbox(
            "Model Type",
            ["PPO", "PPO (Simple)"],
            help="PPO (Simple) uses fewer parameters and may train faster"
        )
    
    # Get training parameters
    params = show_training_parameters(model_type, exchange, grade)
    
    # Training button
    if train_mode == "Continue Training":
        start_button = st.button("üöÄ Continue Training")
        if start_button:
            result = continue_training(df, model_to_continue, model_type, params)
            if not result['success']:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô: {result['error']}")
    else:
        start_button = st.button("üöÄ Create Agent")
        if start_button:
            result = train_new_agent(df, model_type, params, exchange)
            if not result['success']:
                st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô: {result['error']}")
