import streamlit as st

# st.set_page_config ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å‡∏™‡∏∏‡∏î
st.set_page_config(
    page_title="Data Prepare",
    page_icon="üîß",
    layout="wide"
)

import pandas as pd
import numpy as np
import os
import sys
from pathlib import Path
from sklearn.preprocessing import StandardScaler, MinMaxScaler
import warnings
warnings.filterwarnings('ignore')

# Try to import TA-Lib, fall back to manual calculations if not available
try:
    import talib as ta
    TALIB_AVAILABLE = True
    st.success("‚úÖ TA-Lib ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Advanced Indicators)")
except ImportError:
    TALIB_AVAILABLE = False
    st.warning("‚ö†Ô∏è TA-Lib ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - ‡πÉ‡∏ä‡πâ indicators ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô")
    st.info("üí° ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á TA-Lib ‡∏î‡πâ‡∏ß‡∏¢: `conda install ta-lib -c conda-forge`")

# Add project root to Python path
root_path = Path(__file__).parent.parent.parent
sys.path.append(str(root_path))

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î directories
DATA_DIR = os.path.join(root_path, "data")
PREPARED_DATA_DIR = os.path.join(DATA_DIR, "data_prepare")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
if not os.path.exists(PREPARED_DATA_DIR):
    os.makedirs(PREPARED_DATA_DIR)

def find_data_files():
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CSV ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    data_files = []
    
    if not os.path.exists(DATA_DIR):
        return data_files
    
    for file in os.listdir(DATA_DIR):
        if file.endswith('.csv'):
            file_path = os.path.join(DATA_DIR, file)
            try:
                file_size = os.path.getsize(file_path) / (1024*1024)  # MB
                data_files.append({
                    'name': file,
                    'path': file_path,
                    'size_mb': file_size
                })
            except:
                continue
    
    return sorted(data_files, key=lambda x: x['size_mb'], reverse=True)

def load_data(file_path):
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå"""
    try:
        df = pd.read_csv(file_path)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'])
        elif 'date' in df.columns:
            df['timestamp'] = pd.to_datetime(df['date'])
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        required_cols = ['timestamp', 'open', 'high', 'low', 'close', 'volume']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            st.error(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: {missing_cols}")
            return None
            
        return df
        
    except Exception as e:
        st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ: {str(e)}")
        return None

def add_technical_indicators(df):
    """‡πÄ‡∏û‡∏¥‡πà‡∏° Technical Indicators"""
    st.info("üîß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Technical Indicators...")
    
    df = df.copy()
    progress_bar = st.progress(0)
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏° symbol ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if 'symbol' in df.columns:
        symbols = df['symbol'].unique()
        total_symbols = len(symbols)
        
        # ‡πÉ‡∏ä‡πâ list ‡πÄ‡∏Å‡πá‡∏ö dataframes ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç in-place
        symbol_dfs = []
        
        for i, symbol in enumerate(symbols):
            mask = df['symbol'] == symbol
            symbol_data = df[mask].copy().sort_values('timestamp').reset_index(drop=True)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì indicators ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ symbol
            with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì indicators ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {symbol}..."):
                symbol_data = calculate_indicators_for_symbol(symbol_data)
            symbol_dfs.append(symbol_data)
            
            progress_bar.progress((i + 1) / total_symbols)
        
        # ‡∏£‡∏ß‡∏° dataframes ‡∏Å‡∏•‡∏±‡∏ö
        df = pd.concat(symbol_dfs, ignore_index=True)
        df = df.sort_values(['symbol', 'timestamp']).reset_index(drop=True)
    else:
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ symbol ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏•‡∏¢
        df = df.sort_values('timestamp').reset_index(drop=True)
        df = calculate_indicators_for_symbol(df)
        progress_bar.progress(1.0)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ indicators ‡∏ñ‡∏π‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏•‡πâ‡∏ß
    exclude_cols = ['timestamp', 'date', 'symbol', 'tic', 'timeframe', 'open', 'high', 'low', 'close', 'volume']
    indicators = [col for col in df.columns if col not in exclude_cols]
    
    if indicators:
        st.success(f"‚úÖ Technical Indicators ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡πÄ‡∏û‡∏¥‡πà‡∏° {len(indicators)} indicators")
    else:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ indicators ‡∏ñ‡∏π‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°")
    
    return df

def calculate_indicators_for_symbol(data):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì indicators ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 1 symbol"""
    data = data.copy()
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
    if len(data) < 50:  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠
        st.warning(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì indicators (‡∏°‡∏µ {len(data)} ‡πÅ‡∏ñ‡∏ß)")
        return data
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô numeric ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
    close = pd.to_numeric(data['close'], errors='coerce').values
    high = pd.to_numeric(data['high'], errors='coerce').values
    low = pd.to_numeric(data['low'], errors='coerce').values
    volume = pd.to_numeric(data['volume'], errors='coerce').values
    open_price = pd.to_numeric(data['open'], errors='coerce').values
    
    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤ NaN ‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á
    close = np.nan_to_num(close)
    high = np.nan_to_num(high)
    low = np.nan_to_num(low)
    volume = np.nan_to_num(volume)
    open_price = np.nan_to_num(open_price)
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    original_cols = len(data.columns)
    
    try:
        if TALIB_AVAILABLE:
            # ‡πÉ‡∏ä‡πâ TA-Lib
            data = calculate_talib_indicators(data, close, high, low, volume, open_price)
        else:
            # ‡πÉ‡∏ä‡πâ manual calculation
            data = calculate_manual_indicators(data, close, high, low, volume, open_price)
            
    except Exception as e:
        st.error(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì indicators ‡πÑ‡∏î‡πâ: {str(e)}")
        st.write(f"Error details: {type(e).__name__}")
        import traceback
        st.code(traceback.format_exc())
        
        # ‡∏ñ‡πâ‡∏≤ TA-Lib ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÉ‡∏ä‡πâ manual calculation
        try:
            st.warning("üîÑ ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ manual calculation...")
            data = calculate_manual_indicators(data, close, high, low, volume, open_price)
            st.success("‚úÖ Manual calculation ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        except Exception as e2:
            st.error(f"‚ö†Ô∏è Manual calculation ‡∏Å‡πá‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {str(e2)}")
            st.code(traceback.format_exc())
    
    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤ NaN ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≤‡∏á‡πÜ
    numeric_cols = data.select_dtypes(include=[np.number]).columns
    try:
        # ‡πÉ‡∏ä‡πâ method ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pandas ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà
        data[numeric_cols] = data[numeric_cols].ffill().bfill().fillna(0)
    except:
        # fallback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö pandas ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏Å‡πà‡∏≤
        try:
            data[numeric_cols] = data[numeric_cols].fillna(method='ffill').fillna(method='bfill').fillna(0)
        except:
            # ‡∏ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà fillna(0)
            data[numeric_cols] = data[numeric_cols].fillna(0)
    
    return data

def calculate_talib_indicators(data, close, high, low, volume, open_price):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì indicators ‡∏î‡πâ‡∏ß‡∏¢ TA-Lib"""
    # 1. Moving Averages
    data['sma_5'] = ta.SMA(close, timeperiod=5)
    data['sma_10'] = ta.SMA(close, timeperiod=10)
    data['sma_20'] = ta.SMA(close, timeperiod=20)
    data['sma_50'] = ta.SMA(close, timeperiod=50)
    data['ema_12'] = ta.EMA(close, timeperiod=12)
    data['ema_26'] = ta.EMA(close, timeperiod=26)
    data['ema_20'] = ta.EMA(close, timeperiod=20)
    
    # 2. Momentum Indicators
    data['rsi_14'] = ta.RSI(close, timeperiod=14)
    data['rsi_21'] = ta.RSI(close, timeperiod=21)
    
    # 3. MACD
    macd, macd_signal, macd_hist = ta.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)
    data['macd'] = macd
    data['macd_signal'] = macd_signal
    data['macd_hist'] = macd_hist
    
    # 4. Bollinger Bands
    bb_upper, bb_middle, bb_lower = ta.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)
    data['bb_upper'] = bb_upper
    data['bb_middle'] = bb_middle
    data['bb_lower'] = bb_lower
    data['bb_width'] = bb_upper - bb_lower
    data['bb_position'] = (close - bb_lower) / (bb_upper - bb_lower)
    
    # 5. Volume Indicators
    data['volume_sma_20'] = ta.SMA(volume.astype(float), timeperiod=20)
    data['volume_ratio'] = volume / data['volume_sma_20']
    data['ad'] = ta.AD(high, low, close, volume.astype(float))
    data['obv'] = ta.OBV(close, volume.astype(float))
    
    # 6. Volatility Indicators
    data['atr'] = ta.ATR(high, low, close, timeperiod=14)
    data['natr'] = ta.NATR(high, low, close, timeperiod=14)
    
    # 7. Stochastic
    slowk, slowd = ta.STOCH(high, low, close, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)
    data['stoch_k'] = slowk
    data['stoch_d'] = slowd
    
    # 8. Williams %R
    data['willr'] = ta.WILLR(high, low, close, timeperiod=14)
    
    # 9. CCI
    data['cci'] = ta.CCI(high, low, close, timeperiod=14)
    
    # 10. ADX
    data['adx'] = ta.ADX(high, low, close, timeperiod=14)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° Price Features
    data = add_price_features(data, close, high, low, open_price)
    
    return data

def calculate_manual_indicators(data, close, high, low, volume, open_price):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì indicators ‡πÅ‡∏ö‡∏ö manual (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ TA-Lib)"""
    close_series = pd.Series(close)
    high_series = pd.Series(high)
    low_series = pd.Series(low)
    volume_series = pd.Series(volume)
    
    # 1. Moving Averages
    data['sma_5'] = close_series.rolling(window=5).mean()
    data['sma_10'] = close_series.rolling(window=10).mean()
    data['sma_20'] = close_series.rolling(window=20).mean()
    data['sma_50'] = close_series.rolling(window=50).mean()
    
    # EMA calculation
    data['ema_12'] = close_series.ewm(span=12).mean()
    data['ema_26'] = close_series.ewm(span=26).mean()
    data['ema_20'] = close_series.ewm(span=20).mean()
    
    # 2. RSI
    data['rsi_14'] = calculate_rsi(close_series, 14)
    data['rsi_21'] = calculate_rsi(close_series, 21)
    
    # 3. MACD
    macd = data['ema_12'] - data['ema_26']
    macd_signal = macd.ewm(span=9).mean()
    data['macd'] = macd
    data['macd_signal'] = macd_signal
    data['macd_hist'] = macd - macd_signal
    
    # 4. Bollinger Bands
    bb_middle = close_series.rolling(window=20).mean()
    bb_std = close_series.rolling(window=20).std()
    data['bb_upper'] = bb_middle + (bb_std * 2)
    data['bb_middle'] = bb_middle
    data['bb_lower'] = bb_middle - (bb_std * 2)
    data['bb_width'] = data['bb_upper'] - data['bb_lower']
    data['bb_position'] = (close_series - data['bb_lower']) / (data['bb_upper'] - data['bb_lower'])
    
    # 5. Volume Indicators
    data['volume_sma_20'] = volume_series.rolling(window=20).mean()
    data['volume_ratio'] = volume_series / data['volume_sma_20']
    
    # OBV manual calculation
    price_change = close_series.diff()
    obv = []
    obv_value = 0
    for i in range(len(volume_series)):
        if i == 0:
            obv_value = volume_series.iloc[i]
        elif price_change.iloc[i] > 0:
            obv_value += volume_series.iloc[i]
        elif price_change.iloc[i] < 0:
            obv_value -= volume_series.iloc[i]
        obv.append(obv_value)
    data['obv'] = obv
    
    # A/D Line manual calculation
    money_flow_multiplier = ((close_series - low_series) - (high_series - close_series)) / (high_series - low_series)
    money_flow_multiplier = money_flow_multiplier.fillna(0)
    money_flow_volume = money_flow_multiplier * volume_series
    data['ad'] = money_flow_volume.cumsum()
    
    # 6. ATR
    tr1 = high_series - low_series
    tr2 = abs(high_series - close_series.shift(1))
    tr3 = abs(low_series - close_series.shift(1))
    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    data['atr'] = tr.rolling(window=14).mean()
    data['natr'] = (data['atr'] / close_series) * 100
    
    # 7. Stochastic
    lowest_low = low_series.rolling(window=5).min()
    highest_high = high_series.rolling(window=5).max()
    k_percent = 100 * ((close_series - lowest_low) / (highest_high - lowest_low))
    data['stoch_k'] = k_percent.rolling(window=3).mean()
    data['stoch_d'] = data['stoch_k'].rolling(window=3).mean()
    
    # 8. Williams %R
    data['willr'] = -100 * ((highest_high - close_series) / (highest_high - lowest_low))
    
    # 9. CCI
    tp = (high_series + low_series + close_series) / 3
    sma_tp = tp.rolling(window=14).mean()
    mad = tp.rolling(window=14).apply(lambda x: np.mean(np.abs(x - x.mean())))
    data['cci'] = (tp - sma_tp) / (0.015 * mad)
    
    # 10. ADX (simplified version)
    # Calculate True Range first (already done above in ATR section)
    dm_plus = np.maximum(high_series.diff(), 0)
    dm_minus = np.maximum(-low_series.diff(), 0)
    
    # Smooth the DM values
    dm_plus_smooth = dm_plus.rolling(window=14).mean()
    dm_minus_smooth = dm_minus.rolling(window=14).mean()
    
    # Calculate DI+ and DI-
    di_plus = 100 * (dm_plus_smooth / data['atr'])
    di_minus = 100 * (dm_minus_smooth / data['atr'])
    
    # Calculate DX
    dx = 100 * abs(di_plus - di_minus) / (di_plus + di_minus)
    
    # Calculate ADX (smoothed DX)
    data['adx'] = dx.rolling(window=14).mean()
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° Price Features
    data = add_price_features(data, close, high, low, open_price)
    
    return data

def calculate_rsi(close_series, period):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì RSI"""
    delta = close_series.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

def add_price_features(data, close, high, low, open_price):
    """‡πÄ‡∏û‡∏¥‡πà‡∏° Price Features"""
    close_series = pd.Series(close)
    
    # Price Features
    data['price_change'] = (close - open_price) / open_price
    data['price_range'] = (high - low) / close
    data['gap'] = (open_price - close_series.shift(1)) / close_series.shift(1)
    
    # Returns ‡πÅ‡∏•‡∏∞ Volatility
    data['returns'] = close_series.pct_change()
    data['volatility'] = data['returns'].rolling(window=20).std()
    data['log_returns'] = np.log(close_series / close_series.shift(1))
    
    # Support/Resistance
    data['resistance'] = close_series.rolling(window=20).max()
    data['support'] = close_series.rolling(window=20).min()
    data['distance_to_resistance'] = (data['resistance'] - close_series) / close_series
    data['distance_to_support'] = (close_series - data['support']) / close_series
    
    return data

def normalize_data(df, method='standard'):
    """Normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    st.info(f"üìä ‡∏Å‡∏≥‡∏•‡∏±‡∏á Normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ: {method}")
    
    df = df.copy()
    
    # ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á normalize
    exclude_cols = ['timestamp', 'date', 'symbol', 'tic', 'timeframe']
    numeric_cols = [col for col in df.columns if col not in exclude_cols and df[col].dtype in ['float64', 'int64']]
    
    if method == 'standard':
        scaler = StandardScaler()
    elif method == 'minmax':
        scaler = MinMaxScaler()
    elif method == 'robust':
        from sklearn.preprocessing import RobustScaler
        scaler = RobustScaler()
    else:
        st.error("‚ö†Ô∏è ‡∏ß‡∏¥‡∏ò‡∏µ normalize ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
        return df
    
    # Normalize ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° symbol ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    if 'symbol' in df.columns:
        for symbol in df['symbol'].unique():
            mask = df['symbol'] == symbol
            df.loc[mask, numeric_cols] = scaler.fit_transform(df.loc[mask, numeric_cols])
    else:
        df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
    
    st.success("‚úÖ Normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
    return df

def prepare_for_environment(df):
    """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Environment"""
    st.info("üèóÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Trading Environment...")
    
    df = df.copy()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FinRL
    if 'date' not in df.columns:
        df['date'] = df['timestamp'].dt.strftime('%Y-%m-%d')
    
    if 'tic' not in df.columns and 'symbol' in df.columns:
        df['tic'] = df['symbol']
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞ symbol
    df = df.sort_values(['date', 'tic']).reset_index(drop=True)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    df = df.replace([np.inf, -np.inf], 0)
    df = df.fillna(0)
    
    st.success("‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Environment ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
    return df

def show_data_statistics(df):
    """‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    st.subheader("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß", f"{len(df):,}")
    with col2:
        st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå", len(df.columns))
    with col3:
        if 'symbol' in df.columns or 'tic' in df.columns:
            symbol_col = 'symbol' if 'symbol' in df.columns else 'tic'
            st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏Å‡∏∏‡∏•‡πÄ‡∏á‡∏¥‡∏ô", df[symbol_col].nunique())
    with col4:
        missing_count = df.isnull().sum().sum()
        st.metric("‡∏Ñ‡πà‡∏≤ Missing", missing_count)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    st.subheader("üëÄ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏•‡πâ‡∏ß")
    st.dataframe(df.head(10), use_container_width=True)
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠ indicators
    exclude_cols = ['timestamp', 'date', 'symbol', 'tic', 'timeframe', 'open', 'high', 'low', 'close', 'volume']
    indicators = [col for col in df.columns if col not in exclude_cols]
    
    if indicators:
        st.subheader("üìà Technical Indicators ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°")
        st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô indicators: {len(indicators)}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô columns
        cols = st.columns(4)
        for i, indicator in enumerate(indicators):
            with cols[i % 4]:
                st.write(f"‚Ä¢ {indicator}")

# Main UI
def data_prepare_ui():
    """UI ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    st.header("üîß Data Prepare")
    st.markdown("### ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô AI Agent")
    
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    data_files = find_data_files()
    
    if not data_files:
        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ Data Loader ‡∏Å‡πà‡∏≠‡∏ô")
        return
    
    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå
    st.subheader("üìÅ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    selected_file = st.selectbox(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°",
        options=data_files,
        format_func=lambda x: f"{x['name']} ({x['size_mb']:.2f} MB)"
    )
    
    if not selected_file:
        return
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
    st.subheader("‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    col1, col2 = st.columns(2)
    
    with col1:
        add_indicators = st.checkbox("‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° Technical Indicators", value=True)
        normalize_enabled = st.checkbox("‚úÖ Normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", value=True)
        
        if normalize_enabled:
            normalize_method = st.selectbox(
                "‡∏ß‡∏¥‡∏ò‡∏µ Normalization",
                ["standard", "minmax", "robust"],
                index=0,
                help="Standard: z-score, MinMax: 0-1, Robust: median-based"
            )
    
    with col2:
        prepare_env = st.checkbox("‚úÖ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Environment", value=True)
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        base_name = selected_file['name'].replace('.csv', '')
        output_filename = st.text_input(
            "‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå",
            value=f"prepared_{base_name}.csv",
            help="‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô data/data_prepare/"
        )
    
    # ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
    if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", type="primary"):
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        with st.spinner("üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
            df = load_data(selected_file['path'])
        
        if df is None:
            return
        
        st.success(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df):,} ‡πÅ‡∏ñ‡∏ß")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
        with st.expander("üëÄ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö"):
            st.dataframe(df.head(), use_container_width=True)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° Technical Indicators
        if add_indicators:
            df = add_technical_indicators(df)
        
        # Normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if normalize_enabled:
            df = normalize_data(df, normalize_method)
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Environment
        if prepare_env:
            df = prepare_for_environment(df)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        show_data_statistics(df)
        
        # Debug: ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        st.write("üîç Debug - ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:")
        st.write(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df.columns)}")
        st.write("‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå:", list(df.columns))
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå
        output_path = os.path.join(PREPARED_DATA_DIR, output_filename)
        
        try:
            df.to_csv(output_path, index=False)
            st.success(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {output_path}")
            
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ü‡∏•‡πå
            file_size = os.path.getsize(output_path) / (1024*1024)  # MB
            st.info(f"üìÑ ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå: {file_size:.2f} MB")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡πâ‡∏ß
            saved_df = pd.read_csv(output_path)
            st.write(f"üîç ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏°‡∏µ {len(saved_df.columns)} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå")
            st.write("‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å:", list(saved_df.columns))
            
            # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
            csv_data = df.to_csv(index=False)
            st.download_button(
                label="üíæ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå",
                data=csv_data,
                file_name=output_filename,
                mime="text/csv"
            )
            
        except Exception as e:
            st.error(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ: {str(e)}")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏•‡πâ‡∏ß
    st.markdown("---")
    st.subheader("üìö ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏•‡πâ‡∏ß")
    
    if os.path.exists(PREPARED_DATA_DIR):
        prepared_files = [f for f in os.listdir(PREPARED_DATA_DIR) if f.endswith('.csv')]
        
        if prepared_files:
            for file in prepared_files:
                file_path = os.path.join(PREPARED_DATA_DIR, file)
                file_size = os.path.getsize(file_path) / (1024*1024)  # MB
                
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.write(f"üìÑ {file}")
                with col2:
                    st.write(f"{file_size:.2f} MB")
                with col3:
                    if st.button("üóëÔ∏è", key=f"delete_prepared_{file}"):
                        try:
                            os.remove(file_path)
                            st.success(f"‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå {file} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
                            st.rerun()
                        except Exception as e:
                            st.error(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ: {str(e)}")
        else:
            st.info("üìÑ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÅ‡∏•‡πâ‡∏ß")

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ UI
data_prepare_ui() 